#!/usr/bin/env python3
"""
888-888-88 é‡åŒ–äº¤æ˜“ç³»ç»Ÿç”Ÿäº§çº§ä»£ç åˆ†æå·¥å…·
Production-Grade Code Analysis Tool
"""

import os
import ast
import json
import subprocess
from pathlib import Path
from typing import Dict, List, Tuple, Any
from datetime import datetime
import re

class ProductionAnalyzer:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "project_name": "888-888-88 é‡åŒ–äº¤æ˜“ç³»ç»Ÿ",
            "analysis_version": "1.0.0",
            "overall_score": 0.0,
            "categories": {},
            "issues": [],
            "recommendations": [],
            "statistics": {}
        }
        
    def analyze_code_quality(self) -> Dict[str, Any]:
        """åˆ†æä»£ç è´¨é‡"""
        print("ğŸ” åˆ†æä»£ç è´¨é‡...")
        
        python_files = list(self.project_root.rglob("*.py"))
        total_files = len(python_files)
        total_lines = 0
        documented_functions = 0
        total_functions = 0
        documented_classes = 0
        total_classes = 0
        error_handling_coverage = 0
        total_methods = 0
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    lines = content.split('\n')
                    total_lines += len(lines)
                    
                    # è§£æAST
                    try:
                        tree = ast.parse(content)
                        
                        for node in ast.walk(tree):
                            if isinstance(node, ast.FunctionDef):
                                total_functions += 1
                                if ast.get_docstring(node):
                                    documented_functions += 1
                                    
                                # æ£€æŸ¥é”™è¯¯å¤„ç†
                                for child in ast.walk(node):
                                    if isinstance(child, ast.Try):
                                        error_handling_coverage += 1
                                        break
                                        
                            elif isinstance(node, ast.ClassDef):
                                total_classes += 1
                                if ast.get_docstring(node):
                                    documented_classes += 1
                                    
                                # ç»Ÿè®¡ç±»æ–¹æ³•
                                for item in node.body:
                                    if isinstance(item, ast.FunctionDef):
                                        total_methods += 1
                                        
                    except SyntaxError as e:
                        self.results["issues"].append({
                            "type": "syntax_error",
                            "file": str(py_file),
                            "message": f"è¯­æ³•é”™è¯¯: {e}",
                            "severity": "critical"
                        })
                        
            except Exception as e:
                self.results["issues"].append({
                    "type": "file_error",
                    "file": str(py_file),
                    "message": f"æ–‡ä»¶è¯»å–é”™è¯¯: {e}",
                    "severity": "medium"
                })
        
        # è®¡ç®—è¦†ç›–ç‡
        doc_coverage = (documented_functions / total_functions * 100) if total_functions > 0 else 0
        class_doc_coverage = (documented_classes / total_classes * 100) if total_classes > 0 else 0
        error_coverage = (error_handling_coverage / total_functions * 100) if total_functions > 0 else 0
        
        quality_score = (doc_coverage + class_doc_coverage + error_coverage) / 3
        
        return {
            "score": quality_score,
            "total_files": total_files,
            "total_lines": total_lines,
            "total_functions": total_functions,
            "documented_functions": documented_functions,
            "function_doc_coverage": doc_coverage,
            "total_classes": total_classes,
            "documented_classes": documented_classes,
            "class_doc_coverage": class_doc_coverage,
            "error_handling_coverage": error_coverage,
            "total_methods": total_methods
        }
    
    def analyze_ai_components(self) -> Dict[str, Any]:
        """åˆ†æAIç»„ä»¶"""
        print("ğŸ¤– åˆ†æAIç»„ä»¶...")
        
        ai_patterns = [
            r'class.*Model.*:',
            r'class.*Engine.*:',
            r'class.*Predictor.*:',
            r'class.*Trader.*:',
            r'def.*predict.*\(',
            r'def.*train.*\(',
            r'def.*fit.*\(',
            r'import.*tensorflow.*',
            r'import.*torch.*',
            r'import.*sklearn.*',
            r'from.*ai.*import',
        ]
        
        ai_files = []
        ai_models = []
        ai_engines = []
        ai_predictors = []
        ai_traders = []
        
        for py_file in self.project_root.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«AIç›¸å…³ä»£ç 
                    is_ai_file = False
                    for pattern in ai_patterns:
                        if re.search(pattern, content, re.IGNORECASE):
                            is_ai_file = True
                            break
                    
                    if is_ai_file:
                        ai_files.append(str(py_file))
                        
                        # åˆ†ç±»AIç»„ä»¶
                        if re.search(r'class.*Model.*:', content):
                            ai_models.extend(re.findall(r'class\s+(\w*Model\w*)\s*\(', content))
                        if re.search(r'class.*Engine.*:', content):
                            ai_engines.extend(re.findall(r'class\s+(\w*Engine\w*)\s*\(', content))
                        if re.search(r'class.*Predictor.*:', content):
                            ai_predictors.extend(re.findall(r'class\s+(\w*Predictor\w*)\s*\(', content))
                        if re.search(r'class.*Trader.*:', content):
                            ai_traders.extend(re.findall(r'class\s+(\w*Trader\w*)\s*\(', content))
                            
            except Exception as e:
                continue
        
        total_ai_components = len(ai_models) + len(ai_engines) + len(ai_predictors) + len(ai_traders)
        ai_score = min(100, total_ai_components * 2)  # æ¯ä¸ªç»„ä»¶2åˆ†ï¼Œæœ€é«˜100åˆ†
        
        return {
            "score": ai_score,
            "ai_files": len(ai_files),
            "total_components": total_ai_components,
            "ai_models": len(ai_models),
            "ai_engines": len(ai_engines),
            "ai_predictors": len(ai_predictors),
            "ai_traders": len(ai_traders),
            "model_list": ai_models[:10],  # æ˜¾ç¤ºå‰10ä¸ª
            "engine_list": ai_engines,
            "predictor_list": ai_predictors,
            "trader_list": ai_traders
        }
    
    def analyze_trading_features(self) -> Dict[str, Any]:
        """åˆ†æäº¤æ˜“åŠŸèƒ½"""
        print("ğŸ’¹ åˆ†æäº¤æ˜“åŠŸèƒ½...")
        
        trading_patterns = [
            r'def.*place_order.*\(',
            r'def.*cancel_order.*\(',
            r'def.*get_positions.*\(',
            r'def.*get_balance.*\(',
            r'def.*execute_trade.*\(',
            r'class.*Exchange.*:',
            r'class.*Trading.*:',
            r'sandbox.*=.*False',
            r'testnet.*=.*False',
        ]
        
        trading_features = []
        real_trading_indicators = 0
        
        for py_file in self.project_root.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                    for pattern in trading_patterns:
                        matches = re.findall(pattern, content, re.IGNORECASE)
                        if matches:
                            trading_features.extend(matches)
                            
                    # æ£€æŸ¥å®ç›˜äº¤æ˜“æŒ‡æ ‡
                    if re.search(r'sandbox.*=.*False', content, re.IGNORECASE):
                        real_trading_indicators += 1
                    if re.search(r'testnet.*=.*False', content, re.IGNORECASE):
                        real_trading_indicators += 1
                        
            except Exception as e:
                continue
        
        trading_score = min(100, len(set(trading_features)) * 10 + real_trading_indicators * 5)
        
        return {
            "score": trading_score,
            "trading_features": len(set(trading_features)),
            "real_trading_indicators": real_trading_indicators,
            "feature_list": list(set(trading_features))[:10]
        }
    
    def analyze_performance(self) -> Dict[str, Any]:
        """åˆ†ææ€§èƒ½æŒ‡æ ‡"""
        print("âš¡ åˆ†ææ€§èƒ½æŒ‡æ ‡...")
        
        try:
            # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®ï¼ˆå®é™…åº”è¯¥ä»ç›‘æ§ç³»ç»Ÿè·å–ï¼‰
            import psutil
            
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            # GPUä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            gpu_info = "N/A"
            try:
                import GPUtil
                gpus = GPUtil.getGPUs()
                if gpus:
                    gpu = gpus[0]
                    gpu_info = f"{gpu.name} ({gpu.memoryUsed}MB/{gpu.memoryTotal}MB)"
            except:
                pass
            
            performance_score = 100 - cpu_percent  # ç®€å•çš„æ€§èƒ½è¯„åˆ†
            
            return {
                "score": performance_score,
                "cpu_usage": cpu_percent,
                "memory_usage": memory.percent,
                "disk_usage": disk.percent,
                "gpu_info": gpu_info,
                "available_memory_gb": memory.available / (1024**3),
                "total_memory_gb": memory.total / (1024**3)
            }
            
        except Exception as e:
            return {
                "score": 50,
                "error": str(e),
                "cpu_usage": "N/A",
                "memory_usage": "N/A",
                "disk_usage": "N/A"
            }
    
    def analyze_security(self) -> Dict[str, Any]:
        """åˆ†æå®‰å…¨æ€§"""
        print("ğŸ”’ åˆ†æå®‰å…¨æ€§...")
        
        security_issues = []
        security_score = 100
        
        # æ£€æŸ¥ç¡¬ç¼–ç å¯†é’¥
        sensitive_patterns = [
            r'api_key\s*=\s*["\'][^"\']+["\']',
            r'secret\s*=\s*["\'][^"\']+["\']',
            r'password\s*=\s*["\'][^"\']+["\']',
            r'token\s*=\s*["\'][^"\']+["\']',
        ]
        
        for py_file in self.project_root.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                    for pattern in sensitive_patterns:
                        matches = re.findall(pattern, content, re.IGNORECASE)
                        if matches:
                            security_issues.append({
                                "type": "hardcoded_secret",
                                "file": str(py_file),
                                "pattern": pattern,
                                "severity": "high"
                            })
                            security_score -= 10
                            
            except Exception:
                continue
        
        # æ£€æŸ¥ç¯å¢ƒå˜é‡ä½¿ç”¨
        env_usage = 0
        for py_file in self.project_root.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'os.getenv' in content or 'os.environ' in content:
                        env_usage += 1
            except Exception:
                continue
        
        if env_usage > 0:
            security_score += 10  # ä½¿ç”¨ç¯å¢ƒå˜é‡æ˜¯å¥½çš„åšæ³•
        
        return {
            "score": max(0, security_score),
            "security_issues": len(security_issues),
            "env_usage_files": env_usage,
            "issues": security_issues
        }
    
    def analyze_testing(self) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•è¦†ç›–ç‡"""
        print("ğŸ§ª åˆ†ææµ‹è¯•è¦†ç›–ç‡...")
        
        test_files = list(self.project_root.rglob("test_*.py")) + \
                    list(self.project_root.rglob("*_test.py")) + \
                    list(self.project_root.rglob("tests/*.py"))
        
        total_test_files = len(test_files)
        total_py_files = len(list(self.project_root.rglob("*.py")))
        
        test_coverage = (total_test_files / total_py_files * 100) if total_py_files > 0 else 0
        
        # åˆ†ææµ‹è¯•ç±»å‹
        unit_tests = 0
        integration_tests = 0
        
        for test_file in test_files:
            try:
                with open(test_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'unittest' in content or 'pytest' in content:
                        unit_tests += 1
                    if 'integration' in str(test_file).lower():
                        integration_tests += 1
            except Exception:
                continue
        
        testing_score = min(100, test_coverage * 2)
        
        return {
            "score": testing_score,
            "test_files": total_test_files,
            "test_coverage": test_coverage,
            "unit_tests": unit_tests,
            "integration_tests": integration_tests
        }
    
    def check_production_readiness(self) -> Dict[str, Any]:
        """æ£€æŸ¥ç”Ÿäº§å°±ç»ªæ€§"""
        print("ğŸš€ æ£€æŸ¥ç”Ÿäº§å°±ç»ªæ€§...")
        
        readiness_checks = {
            "config_management": False,
            "logging_system": False,
            "error_handling": False,
            "monitoring": False,
            "database_connection": False,
            "api_documentation": False,
            "deployment_config": False,
            "environment_separation": False
        }
        
        # æ£€æŸ¥é…ç½®ç®¡ç†
        config_files = list(self.project_root.rglob("config*.py")) + \
                      list(self.project_root.rglob("settings*.py")) + \
                      list(self.project_root.rglob("*.yaml")) + \
                      list(self.project_root.rglob("*.json"))
        
        if config_files:
            readiness_checks["config_management"] = True
        
        # æ£€æŸ¥æ—¥å¿—ç³»ç»Ÿ
        for py_file in self.project_root.rglob("*.py"):
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'logging' in content or 'logger' in content:
                        readiness_checks["logging_system"] = True
                        break
            except Exception:
                continue
        
        # æ£€æŸ¥å…¶ä»–æŒ‡æ ‡...
        readiness_score = sum(readiness_checks.values()) / len(readiness_checks) * 100
        
        return {
            "score": readiness_score,
            "checks": readiness_checks,
            "config_files": len(config_files)
        }
    
    def generate_recommendations(self):
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        # åŸºäºåˆ†æç»“æœç”Ÿæˆå»ºè®®
        code_quality = self.results["categories"].get("code_quality", {})
        if code_quality.get("function_doc_coverage", 0) < 80:
            recommendations.append({
                "category": "ä»£ç è´¨é‡",
                "priority": "é«˜",
                "description": "å‡½æ•°æ–‡æ¡£è¦†ç›–ç‡ä¸è¶³80%ï¼Œå»ºè®®å¢åŠ å‡½æ•°æ–‡æ¡£å­—ç¬¦ä¸²",
                "action": "ä¸ºæ‰€æœ‰å…¬å…±å‡½æ•°æ·»åŠ è¯¦ç»†çš„æ–‡æ¡£å­—ç¬¦ä¸²"
            })
        
        if code_quality.get("error_handling_coverage", 0) < 70:
            recommendations.append({
                "category": "é”™è¯¯å¤„ç†",
                "priority": "é«˜",
                "description": "é”™è¯¯å¤„ç†è¦†ç›–ç‡ä¸è¶³70%ï¼Œå»ºè®®å¢åŠ å¼‚å¸¸å¤„ç†",
                "action": "ä¸ºå…³é”®å‡½æ•°æ·»åŠ try-excepté”™è¯¯å¤„ç†"
            })
        
        testing = self.results["categories"].get("testing", {})
        if testing.get("test_coverage", 0) < 50:
            recommendations.append({
                "category": "æµ‹è¯•è¦†ç›–",
                "priority": "ä¸­",
                "description": "æµ‹è¯•è¦†ç›–ç‡ä¸è¶³50%ï¼Œå»ºè®®å¢åŠ å•å…ƒæµ‹è¯•",
                "action": "ä¸ºæ ¸å¿ƒåŠŸèƒ½æ¨¡å—ç¼–å†™å•å…ƒæµ‹è¯•"
            })
        
        security = self.results["categories"].get("security", {})
        if security.get("security_issues", 0) > 0:
            recommendations.append({
                "category": "å®‰å…¨æ€§",
                "priority": "é«˜",
                "description": f"å‘ç°{security['security_issues']}ä¸ªå®‰å…¨é—®é¢˜",
                "action": "ä¿®å¤ç¡¬ç¼–ç å¯†é’¥ï¼Œä½¿ç”¨ç¯å¢ƒå˜é‡ç®¡ç†æ•æ„Ÿä¿¡æ¯"
            })
        
        self.results["recommendations"] = recommendations
    
    def run_analysis(self) -> Dict[str, Any]:
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸ¯ å¼€å§‹888-888-88é‡åŒ–äº¤æ˜“ç³»ç»Ÿç”Ÿäº§çº§åˆ†æ...")
        print("=" * 60)
        
        # æ‰§è¡Œå„é¡¹åˆ†æ
        self.results["categories"]["code_quality"] = self.analyze_code_quality()
        self.results["categories"]["ai_components"] = self.analyze_ai_components()
        self.results["categories"]["trading_features"] = self.analyze_trading_features()
        self.results["categories"]["performance"] = self.analyze_performance()
        self.results["categories"]["security"] = self.analyze_security()
        self.results["categories"]["testing"] = self.analyze_testing()
        self.results["categories"]["production_readiness"] = self.check_production_readiness()
        
        # è®¡ç®—æ€»åˆ†
        scores = [cat["score"] for cat in self.results["categories"].values()]
        self.results["overall_score"] = sum(scores) / len(scores)
        
        # ç”Ÿæˆå»ºè®®
        self.generate_recommendations()
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.results["statistics"] = {
            "total_python_files": self.results["categories"]["code_quality"]["total_files"],
            "total_lines_of_code": self.results["categories"]["code_quality"]["total_lines"],
            "total_ai_components": self.results["categories"]["ai_components"]["total_components"],
            "analysis_duration": "å®Œæˆ",
            "grade": self.get_grade(self.results["overall_score"])
        }
        
        return self.results
    
    def get_grade(self, score: float) -> str:
        """è·å–ç­‰çº§è¯„å®š"""
        if score >= 90:
            return "A+ (ç”Ÿäº§å°±ç»ª)"
        elif score >= 80:
            return "A (æ¥è¿‘ç”Ÿäº§çº§)"
        elif score >= 70:
            return "B+ (é¢„ç”Ÿäº§çº§)"
        elif score >= 60:
            return "B (å¼€å‘çº§)"
        elif score >= 50:
            return "C (åŸå‹çº§)"
        else:
            return "D (éœ€è¦é‡æ„)"
    
    def save_report(self, filename: str = "production_analysis_report.json"):
        """ä¿å­˜åˆ†ææŠ¥å‘Š"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ“Š åˆ†ææŠ¥å‘Šå·²ä¿å­˜: {filename}")
    
    def print_summary(self):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“Š 888-888-88 é‡åŒ–äº¤æ˜“ç³»ç»Ÿç”Ÿäº§çº§åˆ†ææŠ¥å‘Š")
        print("=" * 60)
        
        print(f"ğŸ¯ æ€»ä½“è¯„åˆ†: {self.results['overall_score']:.1f}/100")
        print(f"ğŸ† ç³»ç»Ÿç­‰çº§: {self.results['statistics']['grade']}")
        print(f"ğŸ“ ä»£ç æ–‡ä»¶: {self.results['statistics']['total_python_files']} ä¸ª")
        print(f"ğŸ“ ä»£ç è¡Œæ•°: {self.results['statistics']['total_lines_of_code']:,} è¡Œ")
        print(f"ğŸ¤– AIç»„ä»¶: {self.results['statistics']['total_ai_components']} ä¸ª")
        
        print("\nğŸ“ˆ å„é¡¹è¯„åˆ†:")
        for category, data in self.results["categories"].items():
            score = data["score"]
            status = "âœ…" if score >= 80 else "âš ï¸" if score >= 60 else "âŒ"
            print(f"  {status} {category.replace('_', ' ').title()}: {score:.1f}/100")
        
        print(f"\nğŸ” å‘ç°é—®é¢˜: {len(self.results['issues'])} ä¸ª")
        print(f"ğŸ’¡ æ”¹è¿›å»ºè®®: {len(self.results['recommendations'])} æ¡")
        
        if self.results["recommendations"]:
            print("\nğŸš€ ä¸»è¦æ”¹è¿›å»ºè®®:")
            for i, rec in enumerate(self.results["recommendations"][:3], 1):
                print(f"  {i}. [{rec['priority']}] {rec['description']}")

if __name__ == "__main__":
    analyzer = ProductionAnalyzer()
    results = analyzer.run_analysis()
    analyzer.print_summary()
    analyzer.save_report()
