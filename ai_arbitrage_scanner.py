#!/usr/bin/env python3
"""
ğŸ¤– AIå¥—åˆ©æ‰«æå™¨ - ç¬¬äºŒæ­¥æ‰©å±•ï¼šæœºå™¨å­¦ä¹ å¥—åˆ©å‘ç°
AI Arbitrage Scanner - Step 2 Extension: ML-Powered Arbitrage Discovery

ç”Ÿäº§çº§åŠŸèƒ½ï¼š
- GPUåŠ é€Ÿçš„æœºå™¨å­¦ä¹ æ¨¡å‹ (GTX 3060 12GBä¼˜åŒ–)
- æ·±åº¦å­¦ä¹ ä»·æ ¼é¢„æµ‹
- æ™ºèƒ½å¥—åˆ©æœºä¼šè¯†åˆ«
- å®æ—¶å¸‚åœºæƒ…ç»ªåˆ†æ
- å¤šç»´åº¦ç‰¹å¾å·¥ç¨‹
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import asyncio
import aiohttp
import time
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.ensemble import RandomForestRegressor, IsolationForest
from sklearn.metrics import mean_squared_error, accuracy_score
import ta  # Technical Analysis library
import warnings
warnings.filterwarnings('ignore')

# é…ç½®GPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸš€ Using device: {device}")

@dataclass
class MarketData:
    """å¸‚åœºæ•°æ®ç»“æ„"""
    symbol: str
    exchange: str
    timestamp: float
    open: float
    high: float
    low: float
    close: float
    volume: float
    
@dataclass
class PredictionResult:
    """é¢„æµ‹ç»“æœ"""
    symbol: str
    exchange: str
    predicted_price: float
    confidence: float
    direction: str  # 'up', 'down', 'neutral'
    timestamp: float

class LSTMPricePredictor(nn.Module):
    """LSTMä»·æ ¼é¢„æµ‹æ¨¡å‹"""
    
    def __init__(self, input_size: int, hidden_size: int = 128, num_layers: int = 2, dropout: float = 0.2):
        super(LSTMPricePredictor, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout,
            batch_first=True
        )
        
        self.attention = nn.MultiheadAttention(
            embed_dim=hidden_size,
            num_heads=8,
            dropout=dropout
        )
        
        self.fc_layers = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 2, hidden_size // 4),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 4, 1)
        )
        
    def forward(self, x):
        # LSTMå±‚
        lstm_out, (hidden, cell) = self.lstm(x)
        
        # æ³¨æ„åŠ›æœºåˆ¶
        attn_out, _ = self.attention(lstm_out, lstm_out, lstm_out)
        
        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        final_out = attn_out[:, -1, :]
        
        # å…¨è¿æ¥å±‚
        prediction = self.fc_layers(final_out)
        
        return prediction

class FeatureEngineer:
    """ç‰¹å¾å·¥ç¨‹å™¨"""
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.price_scaler = MinMaxScaler()
        self.logger = logging.getLogger("FeatureEngineer")
        
    def create_technical_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºæŠ€æœ¯æŒ‡æ ‡ç‰¹å¾"""
        try:
            # åŸºç¡€ä»·æ ¼ç‰¹å¾
            df['returns'] = df['close'].pct_change()
            df['log_returns'] = np.log(df['close'] / df['close'].shift(1))
            df['price_change'] = df['close'] - df['open']
            df['price_range'] = df['high'] - df['low']
            df['volume_change'] = df['volume'].pct_change()
            
            # ç§»åŠ¨å¹³å‡çº¿
            for period in [5, 10, 20, 50]:
                df[f'sma_{period}'] = ta.trend.sma_indicator(df['close'], window=period)
                df[f'ema_{period}'] = ta.trend.ema_indicator(df['close'], window=period)
            
            # å¸ƒæ—å¸¦
            bb = ta.volatility.BollingerBands(df['close'])
            df['bb_upper'] = bb.bollinger_hband()
            df['bb_middle'] = bb.bollinger_mavg()
            df['bb_lower'] = bb.bollinger_lband()
            df['bb_width'] = df['bb_upper'] - df['bb_lower']
            df['bb_position'] = (df['close'] - df['bb_lower']) / df['bb_width']
            
            # RSI
            df['rsi'] = ta.momentum.rsi(df['close'])
            
            # MACD
            macd = ta.trend.MACD(df['close'])
            df['macd'] = macd.macd()
            df['macd_signal'] = macd.macd_signal()
            df['macd_histogram'] = macd.macd_diff()
            
            # éšæœºæŒ‡æ ‡
            stoch = ta.momentum.StochasticOscillator(df['high'], df['low'], df['close'])
            df['stoch_k'] = stoch.stoch()
            df['stoch_d'] = stoch.stoch_signal()
            
            # å¨å»‰æŒ‡æ ‡
            df['williams_r'] = ta.momentum.williams_r(df['high'], df['low'], df['close'])
            
            # å¹³å‡çœŸå®èŒƒå›´
            df['atr'] = ta.volatility.average_true_range(df['high'], df['low'], df['close'])
            
            # æˆäº¤é‡æŒ‡æ ‡
            df['volume_sma'] = ta.volume.volume_sma(df['close'], df['volume'])
            df['volume_ratio'] = df['volume'] / df['volume_sma']
            
            # ä»·æ ¼åŠ¨é‡
            for period in [1, 3, 5, 10]:
                df[f'momentum_{period}'] = df['close'] / df['close'].shift(period) - 1
            
            # æ³¢åŠ¨ç‡
            for period in [5, 10, 20]:
                df[f'volatility_{period}'] = df['returns'].rolling(period).std()
            
            # æ”¯æ’‘é˜»åŠ›ä½
            df['resistance'] = df['high'].rolling(20).max()
            df['support'] = df['low'].rolling(20).min()
            df['resistance_distance'] = (df['resistance'] - df['close']) / df['close']
            df['support_distance'] = (df['close'] - df['support']) / df['close']
            
            return df
            
        except Exception as e:
            self.logger.error(f"Error creating technical features: {e}")
            return df
    
    def create_market_microstructure_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """åˆ›å»ºå¸‚åœºå¾®è§‚ç»“æ„ç‰¹å¾"""
        try:
            # ä»·æ ¼è·³è·ƒæ£€æµ‹
            df['price_jump'] = np.abs(df['returns']) > df['returns'].rolling(20).std() * 3
            
            # æˆäº¤é‡å¼‚å¸¸æ£€æµ‹
            volume_mean = df['volume'].rolling(20).mean()
            volume_std = df['volume'].rolling(20).std()
            df['volume_anomaly'] = np.abs(df['volume'] - volume_mean) > volume_std * 2
            
            # ä¹°å–å‹åŠ›æŒ‡æ ‡
            df['buying_pressure'] = np.where(df['close'] > df['open'], df['volume'], 0)
            df['selling_pressure'] = np.where(df['close'] < df['open'], df['volume'], 0)
            df['pressure_ratio'] = df['buying_pressure'] / (df['selling_pressure'] + 1e-8)
            
            # ä»·æ ¼æ•ˆç‡æŒ‡æ ‡
            df['price_efficiency'] = np.abs(df['close'] - df['open']) / df['price_range']
            
            return df
            
        except Exception as e:
            self.logger.error(f"Error creating microstructure features: {e}")
            return df
    
    def prepare_sequences(self, df: pd.DataFrame, sequence_length: int = 60) -> Tuple[np.ndarray, np.ndarray]:
        """å‡†å¤‡åºåˆ—æ•°æ®"""
        # é€‰æ‹©ç‰¹å¾åˆ—
        feature_columns = [col for col in df.columns if col not in ['timestamp', 'symbol', 'exchange']]
        
        # å¡«å……ç¼ºå¤±å€¼
        df[feature_columns] = df[feature_columns].fillna(method='ffill').fillna(0)
        
        # æ ‡å‡†åŒ–ç‰¹å¾
        features_scaled = self.scaler.fit_transform(df[feature_columns])
        
        # åˆ›å»ºåºåˆ—
        X, y = [], []
        for i in range(sequence_length, len(features_scaled)):
            X.append(features_scaled[i-sequence_length:i])
            y.append(df['close'].iloc[i])
        
        return np.array(X), np.array(y)

class AIArbitrageScanner:
    """AIå¥—åˆ©æ‰«æå™¨"""
    
    def __init__(self, model_config: Dict[str, Any]):
        self.model_config = model_config
        self.models = {}  # æ¯ä¸ªäº¤æ˜“å¯¹ä¸€ä¸ªæ¨¡å‹
        self.feature_engineer = FeatureEngineer()
        self.anomaly_detector = IsolationForest(contamination=0.1, random_state=42)
        self.logger = logging.getLogger("AIArbitrageScanner")
        
        # æ•°æ®å­˜å‚¨
        self.market_data = {}
        self.predictions = {}
        
    async def initialize_models(self, symbols: List[str], exchanges: List[str]):
        """åˆå§‹åŒ–æ¨¡å‹"""
        self.logger.info("Initializing AI models...")
        
        for symbol in symbols:
            for exchange in exchanges:
                key = f"{symbol}_{exchange}"
                
                # åˆ›å»ºLSTMæ¨¡å‹
                model = LSTMPricePredictor(
                    input_size=self.model_config.get('input_size', 50),
                    hidden_size=self.model_config.get('hidden_size', 128),
                    num_layers=self.model_config.get('num_layers', 2),
                    dropout=self.model_config.get('dropout', 0.2)
                ).to(device)
                
                self.models[key] = {
                    'model': model,
                    'optimizer': optim.Adam(model.parameters(), lr=0.001),
                    'criterion': nn.MSELoss(),
                    'trained': False
                }
        
        self.logger.info(f"Initialized {len(self.models)} AI models")
    
    async def collect_training_data(self, symbol: str, exchange: str, days: int = 30) -> pd.DataFrame:
        """æ”¶é›†è®­ç»ƒæ•°æ®"""
        try:
            # è¿™é‡Œåº”è¯¥è¿æ¥åˆ°å®é™…çš„æ•°æ®æº
            # ä¸ºæ¼”ç¤ºç›®çš„ï¼Œç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
            end_time = datetime.now()
            start_time = end_time - timedelta(days=days)
            
            # ç”Ÿæˆæ¨¡æ‹ŸKçº¿æ•°æ®
            timestamps = pd.date_range(start_time, end_time, freq='1min')
            n_points = len(timestamps)
            
            # æ¨¡æ‹Ÿä»·æ ¼èµ°åŠ¿
            base_price = 50000 if 'BTC' in symbol else 3000
            price_changes = np.random.normal(0, 0.001, n_points).cumsum()
            prices = base_price * (1 + price_changes)
            
            df = pd.DataFrame({
                'timestamp': timestamps,
                'symbol': symbol,
                'exchange': exchange,
                'open': prices * (1 + np.random.normal(0, 0.0001, n_points)),
                'high': prices * (1 + np.abs(np.random.normal(0, 0.002, n_points))),
                'low': prices * (1 - np.abs(np.random.normal(0, 0.002, n_points))),
                'close': prices,
                'volume': np.random.exponential(1000, n_points)
            })
            
            return df
            
        except Exception as e:
            self.logger.error(f"Error collecting training data: {e}")
            return pd.DataFrame()
    
    async def train_model(self, symbol: str, exchange: str):
        """è®­ç»ƒæ¨¡å‹"""
        try:
            key = f"{symbol}_{exchange}"
            if key not in self.models:
                return
            
            self.logger.info(f"Training model for {key}...")
            
            # æ”¶é›†è®­ç»ƒæ•°æ®
            df = await self.collect_training_data(symbol, exchange)
            if df.empty:
                return
            
            # ç‰¹å¾å·¥ç¨‹
            df = self.feature_engineer.create_technical_features(df)
            df = self.feature_engineer.create_market_microstructure_features(df)
            
            # å‡†å¤‡åºåˆ—æ•°æ®
            X, y = self.feature_engineer.prepare_sequences(df)
            
            if len(X) == 0:
                return
            
            # è½¬æ¢ä¸ºPyTorchå¼ é‡
            X_tensor = torch.FloatTensor(X).to(device)
            y_tensor = torch.FloatTensor(y).to(device)
            
            # åˆ›å»ºæ•°æ®åŠ è½½å™¨
            dataset = TensorDataset(X_tensor, y_tensor)
            dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
            
            # è®­ç»ƒæ¨¡å‹
            model_info = self.models[key]
            model = model_info['model']
            optimizer = model_info['optimizer']
            criterion = model_info['criterion']
            
            model.train()
            epochs = self.model_config.get('epochs', 50)
            
            for epoch in range(epochs):
                total_loss = 0
                for batch_X, batch_y in dataloader:
                    optimizer.zero_grad()
                    
                    predictions = model(batch_X).squeeze()
                    loss = criterion(predictions, batch_y)
                    
                    loss.backward()
                    optimizer.step()
                    
                    total_loss += loss.item()
                
                if epoch % 10 == 0:
                    avg_loss = total_loss / len(dataloader)
                    self.logger.info(f"Epoch {epoch}, Loss: {avg_loss:.6f}")
            
            model_info['trained'] = True
            self.logger.info(f"Model training completed for {key}")
            
        except Exception as e:
            self.logger.error(f"Error training model for {symbol}_{exchange}: {e}")
    
    async def predict_price(self, symbol: str, exchange: str, current_data: pd.DataFrame) -> Optional[PredictionResult]:
        """é¢„æµ‹ä»·æ ¼"""
        try:
            key = f"{symbol}_{exchange}"
            if key not in self.models or not self.models[key]['trained']:
                return None
            
            # ç‰¹å¾å·¥ç¨‹
            df = current_data.copy()
            df = self.feature_engineer.create_technical_features(df)
            df = self.feature_engineer.create_market_microstructure_features(df)
            
            # å‡†å¤‡è¾“å…¥æ•°æ®
            sequence_length = 60
            if len(df) < sequence_length:
                return None
            
            feature_columns = [col for col in df.columns if col not in ['timestamp', 'symbol', 'exchange']]
            df[feature_columns] = df[feature_columns].fillna(method='ffill').fillna(0)
            
            # æ ‡å‡†åŒ–
            features_scaled = self.feature_engineer.scaler.transform(df[feature_columns])
            
            # åˆ›å»ºè¾“å…¥åºåˆ—
            X = features_scaled[-sequence_length:].reshape(1, sequence_length, -1)
            X_tensor = torch.FloatTensor(X).to(device)
            
            # é¢„æµ‹
            model = self.models[key]['model']
            model.eval()
            
            with torch.no_grad():
                prediction = model(X_tensor).cpu().numpy()[0][0]
            
            # è®¡ç®—ç½®ä¿¡åº¦
            current_price = df['close'].iloc[-1]
            price_change = (prediction - current_price) / current_price
            confidence = min(1.0, np.abs(price_change) * 100)  # ç®€åŒ–çš„ç½®ä¿¡åº¦è®¡ç®—
            
            # ç¡®å®šæ–¹å‘
            if price_change > 0.001:
                direction = 'up'
            elif price_change < -0.001:
                direction = 'down'
            else:
                direction = 'neutral'
            
            return PredictionResult(
                symbol=symbol,
                exchange=exchange,
                predicted_price=prediction,
                confidence=confidence,
                direction=direction,
                timestamp=time.time()
            )
            
        except Exception as e:
            self.logger.error(f"Error predicting price for {symbol}_{exchange}: {e}")
            return None
    
    async def scan_ai_arbitrage_opportunities(self, symbols: List[str], exchanges: List[str]) -> List[Dict[str, Any]]:
        """æ‰«æAIå¥—åˆ©æœºä¼š"""
        opportunities = []
        
        try:
            # è·å–æ‰€æœ‰é¢„æµ‹
            predictions = {}
            for symbol in symbols:
                for exchange in exchanges:
                    # è·å–å½“å‰å¸‚åœºæ•°æ®ï¼ˆè¿™é‡Œåº”è¯¥è¿æ¥åˆ°å®é™…æ•°æ®æºï¼‰
                    current_data = await self.collect_training_data(symbol, exchange, days=1)
                    
                    if not current_data.empty:
                        prediction = await self.predict_price(symbol, exchange, current_data)
                        if prediction:
                            key = f"{symbol}_{exchange}"
                            predictions[key] = prediction
            
            # å¯»æ‰¾å¥—åˆ©æœºä¼š
            for symbol in symbols:
                symbol_predictions = {k: v for k, v in predictions.items() if k.startswith(symbol)}
                
                if len(symbol_predictions) < 2:
                    continue
                
                # æ¯”è¾ƒä¸åŒäº¤æ˜“æ‰€çš„é¢„æµ‹ä»·æ ¼
                pred_list = list(symbol_predictions.values())
                for i, pred1 in enumerate(pred_list):
                    for j, pred2 in enumerate(pred_list[i+1:], i+1):
                        price_diff = pred2.predicted_price - pred1.predicted_price
                        profit_rate = abs(price_diff) / min(pred1.predicted_price, pred2.predicted_price)
                        
                        if profit_rate > 0.002:  # 0.2% æœ€å°åˆ©æ¶¦ç‡
                            # ç¡®å®šä¹°å–æ–¹å‘
                            if pred1.predicted_price < pred2.predicted_price:
                                buy_exchange = pred1.exchange
                                sell_exchange = pred2.exchange
                                buy_price = pred1.predicted_price
                                sell_price = pred2.predicted_price
                            else:
                                buy_exchange = pred2.exchange
                                sell_exchange = pred1.exchange
                                buy_price = pred2.predicted_price
                                sell_price = pred1.predicted_price
                            
                            # è®¡ç®—ç»¼åˆç½®ä¿¡åº¦
                            combined_confidence = (pred1.confidence + pred2.confidence) / 2
                            
                            opportunity = {
                                'type': 'ai_arbitrage',
                                'symbol': symbol,
                                'buy_exchange': buy_exchange,
                                'sell_exchange': sell_exchange,
                                'buy_price': buy_price,
                                'sell_price': sell_price,
                                'profit_rate': profit_rate,
                                'confidence': combined_confidence,
                                'timestamp': time.time(),
                                'ai_prediction': True
                            }
                            
                            opportunities.append(opportunity)
            
            # æŒ‰ç½®ä¿¡åº¦å’Œåˆ©æ¶¦ç‡æ’åº
            opportunities.sort(key=lambda x: x['confidence'] * x['profit_rate'], reverse=True)
            
        except Exception as e:
            self.logger.error(f"Error scanning AI arbitrage opportunities: {e}")
        
        return opportunities
    
    async def detect_market_anomalies(self, market_data: Dict[str, pd.DataFrame]) -> List[Dict[str, Any]]:
        """æ£€æµ‹å¸‚åœºå¼‚å¸¸"""
        anomalies = []
        
        try:
            for key, df in market_data.items():
                if df.empty:
                    continue
                
                # ç‰¹å¾å·¥ç¨‹
                df = self.feature_engineer.create_technical_features(df)
                
                # é€‰æ‹©ç‰¹å¾
                feature_columns = ['returns', 'volume_change', 'rsi', 'bb_position', 'atr']
                features = df[feature_columns].fillna(0).values
                
                if len(features) < 10:
                    continue
                
                # å¼‚å¸¸æ£€æµ‹
                anomaly_scores = self.anomaly_detector.fit_predict(features)
                
                # æ‰¾å‡ºå¼‚å¸¸ç‚¹
                anomaly_indices = np.where(anomaly_scores == -1)[0]
                
                for idx in anomaly_indices[-5:]:  # åªå–æœ€è¿‘çš„5ä¸ªå¼‚å¸¸ç‚¹
                    anomaly = {
                        'symbol': key.split('_')[0],
                        'exchange': key.split('_')[1],
                        'timestamp': df.iloc[idx]['timestamp'] if 'timestamp' in df.columns else time.time(),
                        'anomaly_type': 'market_anomaly',
                        'severity': 'high',
                        'features': {
                            'returns': df.iloc[idx]['returns'],
                            'volume_change': df.iloc[idx]['volume_change'],
                            'rsi': df.iloc[idx]['rsi']
                        }
                    }
                    anomalies.append(anomaly)
            
        except Exception as e:
            self.logger.error(f"Error detecting market anomalies: {e}")
        
        return anomalies

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– å¯åŠ¨AIå¥—åˆ©æ‰«æå™¨...")
    
    # é…ç½®
    model_config = {
        'input_size': 50,
        'hidden_size': 128,
        'num_layers': 2,
        'dropout': 0.2,
        'epochs': 50
    }
    
    symbols = ['BTCUSDT', 'ETHUSDT']
    exchanges = ['binance', 'okx']
    
    # åˆå§‹åŒ–AIæ‰«æå™¨
    scanner = AIArbitrageScanner(model_config)
    await scanner.initialize_models(symbols, exchanges)
    
    # è®­ç»ƒæ¨¡å‹
    for symbol in symbols:
        for exchange in exchanges:
            await scanner.train_model(symbol, exchange)
    
    # æ‰«æå¥—åˆ©æœºä¼š
    opportunities = await scanner.scan_ai_arbitrage_opportunities(symbols, exchanges)
    
    print(f"ğŸ¯ å‘ç° {len(opportunities)} ä¸ªAIå¥—åˆ©æœºä¼š:")
    for opp in opportunities[:5]:
        print(f"  {opp['symbol']}: {opp['buy_exchange']} -> {opp['sell_exchange']}")
        print(f"    åˆ©æ¶¦ç‡: {opp['profit_rate']:.4f}, ç½®ä¿¡åº¦: {opp['confidence']:.2f}")

if __name__ == "__main__":
    asyncio.run(main())
