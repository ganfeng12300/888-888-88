#!/usr/bin/env python3
"""
ğŸš€ GPUåŠ é€Ÿå™¨ - ç”Ÿäº§çº§GPUè®¡ç®—ä¼˜åŒ–
GPU Accelerator - Production-Grade GPU Computing Optimization

ç”Ÿäº§çº§ç‰¹æ€§ï¼š
- CUDA/OpenCL GPUè®¡ç®—åŠ é€Ÿ
- å†…å­˜æ± ç®¡ç†å’Œä¼˜åŒ–
- æ‰¹å¤„ç†å’Œå¹¶è¡Œè®¡ç®—
- GPUèµ„æºç›‘æ§
- è‡ªåŠ¨å›é€€CPUè®¡ç®—
"""

import numpy as np
import threading
import time
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass
from collections import deque
import logging
import json

# GPUè®¡ç®—åº“å¯¼å…¥
try:
    import cupy as cp
    CUPY_AVAILABLE = True
except ImportError:
    CUPY_AVAILABLE = False
    cp = None

try:
    import pyopencl as cl
    OPENCL_AVAILABLE = True
except ImportError:
    OPENCL_AVAILABLE = False
    cl = None

try:
    import numba
    from numba import cuda, jit
    NUMBA_AVAILABLE = True
except ImportError:
    NUMBA_AVAILABLE = False
    numba = None
    cuda = None
    jit = None

from ..monitoring.unified_logging_system import UnifiedLogger

@dataclass
class GPUInfo:
    """GPUä¿¡æ¯æ•°æ®ç»“æ„"""
    device_id: int
    name: str
    memory_total: int
    memory_free: int
    memory_used: int
    compute_capability: str
    multiprocessor_count: int
    max_threads_per_block: int
    max_block_dim: Tuple[int, int, int]
    max_grid_dim: Tuple[int, int, int]

@dataclass
class ComputeTask:
    """è®¡ç®—ä»»åŠ¡æ•°æ®ç»“æ„"""
    task_id: str
    function_name: str
    data: Any
    parameters: Dict[str, Any]
    priority: int = 1
    created_at: datetime = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    result: Any = None
    error: Optional[str] = None

class GPUMemoryPool:
    """GPUå†…å­˜æ± ç®¡ç†å™¨"""
    
    def __init__(self, device_id: int = 0):
        self.logger = UnifiedLogger("GPUMemoryPool")
        self.device_id = device_id
        self.allocated_blocks = {}
        self.free_blocks = {}
        self.total_allocated = 0
        self.peak_usage = 0
        self._lock = threading.Lock()
        
        if CUPY_AVAILABLE:
            self.mempool = cp.get_default_memory_pool()
            self.pinned_mempool = cp.get_default_pinned_memory_pool()
    
    def allocate(self, size: int, dtype=np.float32) -> Optional[Any]:
        """åˆ†é…GPUå†…å­˜"""
        try:
            with self._lock:
                if CUPY_AVAILABLE:
                    # ä½¿ç”¨CuPyå†…å­˜æ± 
                    array = cp.empty(size, dtype=dtype)
                    block_id = id(array)
                    self.allocated_blocks[block_id] = {
                        'array': array,
                        'size': size,
                        'dtype': dtype,
                        'allocated_at': datetime.now()
                    }
                    self.total_allocated += array.nbytes
                    self.peak_usage = max(self.peak_usage, self.total_allocated)
                    return array
                else:
                    # å›é€€åˆ°CPUå†…å­˜
                    array = np.empty(size, dtype=dtype)
                    return array
                    
        except Exception as e:
            self.logger.error(f"GPUå†…å­˜åˆ†é…å¤±è´¥: {e}")
            # å›é€€åˆ°CPUå†…å­˜
            return np.empty(size, dtype=dtype)
    
    def deallocate(self, array: Any):
        """é‡Šæ”¾GPUå†…å­˜"""
        try:
            with self._lock:
                if CUPY_AVAILABLE and hasattr(array, '__array_interface__'):
                    block_id = id(array)
                    if block_id in self.allocated_blocks:
                        block_info = self.allocated_blocks[block_id]
                        self.total_allocated -= block_info['array'].nbytes
                        del self.allocated_blocks[block_id]
                        del array
                        
        except Exception as e:
            self.logger.error(f"GPUå†…å­˜é‡Šæ”¾å¤±è´¥: {e}")
    
    def get_memory_info(self) -> Dict:
        """è·å–å†…å­˜ä½¿ç”¨ä¿¡æ¯"""
        try:
            if CUPY_AVAILABLE:
                mempool_info = self.mempool.get_limit()
                used_bytes = self.mempool.used_bytes()
                total_bytes = self.mempool.total_bytes()
                
                return {
                    'device_id': self.device_id,
                    'total_allocated': self.total_allocated,
                    'peak_usage': self.peak_usage,
                    'active_blocks': len(self.allocated_blocks),
                    'mempool_used': used_bytes,
                    'mempool_total': total_bytes,
                    'mempool_limit': mempool_info
                }
            else:
                return {
                    'device_id': self.device_id,
                    'gpu_available': False,
                    'using_cpu_fallback': True
                }
                
        except Exception as e:
            self.logger.error(f"è·å–å†…å­˜ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def cleanup(self):
        """æ¸…ç†å†…å­˜æ± """
        try:
            with self._lock:
                if CUPY_AVAILABLE:
                    self.mempool.free_all_blocks()
                    self.pinned_mempool.free_all_blocks()
                
                self.allocated_blocks.clear()
                self.total_allocated = 0
                
            self.logger.info("GPUå†…å­˜æ± å·²æ¸…ç†")
            
        except Exception as e:
            self.logger.error(f"æ¸…ç†å†…å­˜æ± å¤±è´¥: {e}")

class CUDAAccelerator:
    """CUDAåŠ é€Ÿå™¨"""
    
    def __init__(self, device_id: int = 0):
        self.logger = UnifiedLogger("CUDAAccelerator")
        self.device_id = device_id
        self.available = CUPY_AVAILABLE
        self.memory_pool = GPUMemoryPool(device_id) if self.available else None
        
        if self.available:
            try:
                cp.cuda.Device(device_id).use()
                self.logger.info(f"CUDAè®¾å¤‡ {device_id} åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"CUDAè®¾å¤‡åˆå§‹åŒ–å¤±è´¥: {e}")
                self.available = False
    
    def get_device_info(self) -> Optional[GPUInfo]:
        """è·å–GPUè®¾å¤‡ä¿¡æ¯"""
        if not self.available:
            return None
        
        try:
            device = cp.cuda.Device(self.device_id)
            attrs = device.attributes
            
            return GPUInfo(
                device_id=self.device_id,
                name=device.name.decode('utf-8'),
                memory_total=device.mem_info[1],
                memory_free=device.mem_info[0],
                memory_used=device.mem_info[1] - device.mem_info[0],
                compute_capability=f"{attrs['ComputeCapabilityMajor']}.{attrs['ComputeCapabilityMinor']}",
                multiprocessor_count=attrs['MultiProcessorCount'],
                max_threads_per_block=attrs['MaxThreadsPerBlock'],
                max_block_dim=(
                    attrs['MaxBlockDimX'],
                    attrs['MaxBlockDimY'],
                    attrs['MaxBlockDimZ']
                ),
                max_grid_dim=(
                    attrs['MaxGridDimX'],
                    attrs['MaxGridDimY'],
                    attrs['MaxGridDimZ']
                )
            )
            
        except Exception as e:
            self.logger.error(f"è·å–GPUè®¾å¤‡ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    def matrix_multiply(self, a: np.ndarray, b: np.ndarray) -> np.ndarray:
        """GPUçŸ©é˜µä¹˜æ³•"""
        try:
            if not self.available:
                return np.dot(a, b)
            
            # è½¬æ¢åˆ°GPU
            gpu_a = cp.asarray(a)
            gpu_b = cp.asarray(b)
            
            # GPUçŸ©é˜µä¹˜æ³•
            gpu_result = cp.dot(gpu_a, gpu_b)
            
            # è½¬æ¢å›CPU
            result = cp.asnumpy(gpu_result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"GPUçŸ©é˜µä¹˜æ³•å¤±è´¥: {e}")
            # å›é€€åˆ°CPUè®¡ç®—
            return np.dot(a, b)
    
    def element_wise_operations(self, a: np.ndarray, b: np.ndarray, operation: str) -> np.ndarray:
        """GPUå…ƒç´ çº§è¿ç®—"""
        try:
            if not self.available:
                return self._cpu_element_wise(a, b, operation)
            
            # è½¬æ¢åˆ°GPU
            gpu_a = cp.asarray(a)
            gpu_b = cp.asarray(b)
            
            # GPUå…ƒç´ çº§è¿ç®—
            if operation == 'add':
                gpu_result = gpu_a + gpu_b
            elif operation == 'subtract':
                gpu_result = gpu_a - gpu_b
            elif operation == 'multiply':
                gpu_result = gpu_a * gpu_b
            elif operation == 'divide':
                gpu_result = gpu_a / gpu_b
            elif operation == 'power':
                gpu_result = cp.power(gpu_a, gpu_b)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„è¿ç®—: {operation}")
            
            # è½¬æ¢å›CPU
            result = cp.asnumpy(gpu_result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"GPUå…ƒç´ çº§è¿ç®—å¤±è´¥: {e}")
            # å›é€€åˆ°CPUè®¡ç®—
            return self._cpu_element_wise(a, b, operation)
    
    def _cpu_element_wise(self, a: np.ndarray, b: np.ndarray, operation: str) -> np.ndarray:
        """CPUå…ƒç´ çº§è¿ç®—å›é€€"""
        if operation == 'add':
            return a + b
        elif operation == 'subtract':
            return a - b
        elif operation == 'multiply':
            return a * b
        elif operation == 'divide':
            return a / b
        elif operation == 'power':
            return np.power(a, b)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¿ç®—: {operation}")
    
    def reduce_operations(self, data: np.ndarray, operation: str, axis: Optional[int] = None) -> Union[np.ndarray, float]:
        """GPUå½’çº¦è¿ç®—"""
        try:
            if not self.available:
                return self._cpu_reduce(data, operation, axis)
            
            # è½¬æ¢åˆ°GPU
            gpu_data = cp.asarray(data)
            
            # GPUå½’çº¦è¿ç®—
            if operation == 'sum':
                gpu_result = cp.sum(gpu_data, axis=axis)
            elif operation == 'mean':
                gpu_result = cp.mean(gpu_data, axis=axis)
            elif operation == 'max':
                gpu_result = cp.max(gpu_data, axis=axis)
            elif operation == 'min':
                gpu_result = cp.min(gpu_data, axis=axis)
            elif operation == 'std':
                gpu_result = cp.std(gpu_data, axis=axis)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å½’çº¦è¿ç®—: {operation}")
            
            # è½¬æ¢å›CPU
            if hasattr(gpu_result, 'ndim') and gpu_result.ndim > 0:
                result = cp.asnumpy(gpu_result)
            else:
                result = float(gpu_result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"GPUå½’çº¦è¿ç®—å¤±è´¥: {e}")
            # å›é€€åˆ°CPUè®¡ç®—
            return self._cpu_reduce(data, operation, axis)
    
    def _cpu_reduce(self, data: np.ndarray, operation: str, axis: Optional[int] = None) -> Union[np.ndarray, float]:
        """CPUå½’çº¦è¿ç®—å›é€€"""
        if operation == 'sum':
            return np.sum(data, axis=axis)
        elif operation == 'mean':
            return np.mean(data, axis=axis)
        elif operation == 'max':
            return np.max(data, axis=axis)
        elif operation == 'min':
            return np.min(data, axis=axis)
        elif operation == 'std':
            return np.std(data, axis=axis)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å½’çº¦è¿ç®—: {operation}")
    
    def fft_transform(self, data: np.ndarray, inverse: bool = False) -> np.ndarray:
        """GPUå¿«é€Ÿå‚…é‡Œå¶å˜æ¢"""
        try:
            if not self.available:
                return np.fft.ifft(data) if inverse else np.fft.fft(data)
            
            # è½¬æ¢åˆ°GPU
            gpu_data = cp.asarray(data)
            
            # GPU FFT
            if inverse:
                gpu_result = cp.fft.ifft(gpu_data)
            else:
                gpu_result = cp.fft.fft(gpu_data)
            
            # è½¬æ¢å›CPU
            result = cp.asnumpy(gpu_result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"GPU FFTå¤±è´¥: {e}")
            # å›é€€åˆ°CPUè®¡ç®—
            return np.fft.ifft(data) if inverse else np.fft.fft(data)

class NumbaAccelerator:
    """Numba JITåŠ é€Ÿå™¨"""
    
    def __init__(self):
        self.logger = UnifiedLogger("NumbaAccelerator")
        self.available = NUMBA_AVAILABLE and cuda is not None
        self.compiled_functions = {}
        
        if self.available:
            try:
                # æ£€æŸ¥CUDAè®¾å¤‡
                cuda.detect()
                self.logger.info("Numba CUDAåŠ é€Ÿå™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"Numba CUDAåˆå§‹åŒ–å¤±è´¥: {e}")
                self.available = False
    
    def compile_function(self, func: callable, signature: str = None) -> callable:
        """ç¼–è¯‘å‡½æ•°ä¸ºGPUå†…æ ¸"""
        try:
            if not self.available:
                return jit(nopython=True)(func) if NUMBA_AVAILABLE else func
            
            func_name = func.__name__
            if func_name not in self.compiled_functions:
                if signature:
                    compiled_func = cuda.jit(signature)(func)
                else:
                    compiled_func = cuda.jit(func)
                
                self.compiled_functions[func_name] = compiled_func
                self.logger.info(f"å‡½æ•° {func_name} ç¼–è¯‘ä¸ºGPUå†…æ ¸æˆåŠŸ")
            
            return self.compiled_functions[func_name]
            
        except Exception as e:
            self.logger.error(f"ç¼–è¯‘GPUå†…æ ¸å¤±è´¥: {e}")
            # å›é€€åˆ°CPU JIT
            return jit(nopython=True)(func) if NUMBA_AVAILABLE else func
    
    def parallel_compute(self, data: np.ndarray, func: callable, *args, **kwargs) -> np.ndarray:
        """å¹¶è¡Œè®¡ç®—"""
        try:
            if not self.available:
                return self._cpu_parallel_compute(data, func, *args, **kwargs)
            
            # åˆ†é…GPUå†…å­˜
            gpu_data = cuda.to_device(data)
            gpu_result = cuda.device_array_like(data)
            
            # é…ç½®çº¿ç¨‹å—å’Œç½‘æ ¼
            threads_per_block = 256
            blocks_per_grid = (data.size + threads_per_block - 1) // threads_per_block
            
            # ç¼–è¯‘å¹¶æ‰§è¡ŒGPUå†…æ ¸
            compiled_func = self.compile_function(func)
            compiled_func[blocks_per_grid, threads_per_block](gpu_data, gpu_result, *args, **kwargs)
            
            # åŒæ­¥å¹¶å¤åˆ¶ç»“æœ
            cuda.synchronize()
            result = gpu_result.copy_to_host()
            
            return result
            
        except Exception as e:
            self.logger.error(f"GPUå¹¶è¡Œè®¡ç®—å¤±è´¥: {e}")
            # å›é€€åˆ°CPUè®¡ç®—
            return self._cpu_parallel_compute(data, func, *args, **kwargs)
    
    def _cpu_parallel_compute(self, data: np.ndarray, func: callable, *args, **kwargs) -> np.ndarray:
        """CPUå¹¶è¡Œè®¡ç®—å›é€€"""
        try:
            if NUMBA_AVAILABLE:
                # ä½¿ç”¨Numba CPUå¹¶è¡Œ
                compiled_func = jit(nopython=True, parallel=True)(func)
                return compiled_func(data, *args, **kwargs)
            else:
                # æ™®é€šè®¡ç®—
                return func(data, *args, **kwargs)
                
        except Exception as e:
            self.logger.error(f"CPUå¹¶è¡Œè®¡ç®—å¤±è´¥: {e}")
            return func(data, *args, **kwargs)

class GPUTaskScheduler:
    """GPUä»»åŠ¡è°ƒåº¦å™¨"""
    
    def __init__(self, max_concurrent_tasks: int = 4):
        self.logger = UnifiedLogger("GPUTaskScheduler")
        self.max_concurrent_tasks = max_concurrent_tasks
        self.task_queue = deque()
        self.running_tasks = {}
        self.completed_tasks = deque(maxlen=1000)
        self._running = False
        self._scheduler_thread = None
        self._lock = threading.Lock()
        
        # åˆå§‹åŒ–åŠ é€Ÿå™¨
        self.cuda_accelerator = CUDAAccelerator()
        self.numba_accelerator = NumbaAccelerator()
    
    def start(self):
        """å¯åŠ¨ä»»åŠ¡è°ƒåº¦å™¨"""
        if self._running:
            return
        
        self._running = True
        self._scheduler_thread = threading.Thread(target=self._scheduler_loop, daemon=True)
        self._scheduler_thread.start()
        
        self.logger.info("GPUä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢ä»»åŠ¡è°ƒåº¦å™¨"""
        self._running = False
        if self._scheduler_thread:
            self._scheduler_thread.join(timeout=5)
        
        self.logger.info("GPUä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")
    
    def submit_task(self, function_name: str, data: Any, parameters: Dict[str, Any] = None, priority: int = 1) -> str:
        """æäº¤è®¡ç®—ä»»åŠ¡"""
        task = ComputeTask(
            task_id=f"{function_name}_{int(time.time() * 1000000)}",
            function_name=function_name,
            data=data,
            parameters=parameters or {},
            priority=priority,
            created_at=datetime.now()
        )
        
        with self._lock:
            # æŒ‰ä¼˜å…ˆçº§æ’å…¥ä»»åŠ¡é˜Ÿåˆ—
            inserted = False
            for i, existing_task in enumerate(self.task_queue):
                if task.priority > existing_task.priority:
                    self.task_queue.insert(i, task)
                    inserted = True
                    break
            
            if not inserted:
                self.task_queue.append(task)
        
        self.logger.info(f"ä»»åŠ¡å·²æäº¤: {task.task_id}")
        return task.task_id
    
    def get_task_result(self, task_id: str) -> Optional[ComputeTask]:
        """è·å–ä»»åŠ¡ç»“æœ"""
        # æ£€æŸ¥è¿è¡Œä¸­çš„ä»»åŠ¡
        if task_id in self.running_tasks:
            return self.running_tasks[task_id]
        
        # æ£€æŸ¥å·²å®Œæˆçš„ä»»åŠ¡
        for task in self.completed_tasks:
            if task.task_id == task_id:
                return task
        
        return None
    
    def _scheduler_loop(self):
        """è°ƒåº¦å™¨ä¸»å¾ªç¯"""
        while self._running:
            try:
                # æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
                self._cleanup_completed_tasks()
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„æ‰§è¡Œæ§½ä½
                if len(self.running_tasks) < self.max_concurrent_tasks:
                    with self._lock:
                        if self.task_queue:
                            task = self.task_queue.popleft()
                            self.running_tasks[task.task_id] = task
                            
                            # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œä»»åŠ¡
                            task_thread = threading.Thread(
                                target=self._execute_task,
                                args=(task,),
                                daemon=True
                            )
                            task_thread.start()
                
                time.sleep(0.1)  # çŸ­æš‚ä¼‘çœ 
                
            except Exception as e:
                self.logger.error(f"è°ƒåº¦å™¨å¾ªç¯å¼‚å¸¸: {e}")
                time.sleep(1)
    
    def _execute_task(self, task: ComputeTask):
        """æ‰§è¡Œè®¡ç®—ä»»åŠ¡"""
        try:
            task.started_at = datetime.now()
            
            # æ ¹æ®å‡½æ•°åé€‰æ‹©æ‰§è¡Œæ–¹æ³•
            if task.function_name == 'matrix_multiply':
                result = self._execute_matrix_multiply(task)
            elif task.function_name == 'element_wise':
                result = self._execute_element_wise(task)
            elif task.function_name == 'reduce':
                result = self._execute_reduce(task)
            elif task.function_name == 'fft':
                result = self._execute_fft(task)
            elif task.function_name == 'parallel_compute':
                result = self._execute_parallel_compute(task)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„å‡½æ•°: {task.function_name}")
            
            task.result = result
            task.completed_at = datetime.now()
            
            self.logger.info(f"ä»»åŠ¡å®Œæˆ: {task.task_id}")
            
        except Exception as e:
            task.error = str(e)
            task.completed_at = datetime.now()
            self.logger.error(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥ {task.task_id}: {e}")
        
        finally:
            # ç§»åŠ¨åˆ°å·²å®Œæˆä»»åŠ¡åˆ—è¡¨
            with self._lock:
                if task.task_id in self.running_tasks:
                    del self.running_tasks[task.task_id]
                self.completed_tasks.append(task)
    
    def _execute_matrix_multiply(self, task: ComputeTask) -> np.ndarray:
        """æ‰§è¡ŒçŸ©é˜µä¹˜æ³•ä»»åŠ¡"""
        data = task.data
        if isinstance(data, dict) and 'a' in data and 'b' in data:
            return self.cuda_accelerator.matrix_multiply(data['a'], data['b'])
        else:
            raise ValueError("çŸ©é˜µä¹˜æ³•éœ€è¦åŒ…å«'a'å’Œ'b'çš„æ•°æ®å­—å…¸")
    
    def _execute_element_wise(self, task: ComputeTask) -> np.ndarray:
        """æ‰§è¡Œå…ƒç´ çº§è¿ç®—ä»»åŠ¡"""
        data = task.data
        operation = task.parameters.get('operation', 'add')
        
        if isinstance(data, dict) and 'a' in data and 'b' in data:
            return self.cuda_accelerator.element_wise_operations(data['a'], data['b'], operation)
        else:
            raise ValueError("å…ƒç´ çº§è¿ç®—éœ€è¦åŒ…å«'a'å’Œ'b'çš„æ•°æ®å­—å…¸")
    
    def _execute_reduce(self, task: ComputeTask) -> Union[np.ndarray, float]:
        """æ‰§è¡Œå½’çº¦è¿ç®—ä»»åŠ¡"""
        data = task.data
        operation = task.parameters.get('operation', 'sum')
        axis = task.parameters.get('axis', None)
        
        return self.cuda_accelerator.reduce_operations(data, operation, axis)
    
    def _execute_fft(self, task: ComputeTask) -> np.ndarray:
        """æ‰§è¡ŒFFTä»»åŠ¡"""
        data = task.data
        inverse = task.parameters.get('inverse', False)
        
        return self.cuda_accelerator.fft_transform(data, inverse)
    
    def _execute_parallel_compute(self, task: ComputeTask) -> np.ndarray:
        """æ‰§è¡Œå¹¶è¡Œè®¡ç®—ä»»åŠ¡"""
        data = task.data
        func = task.parameters.get('function')
        args = task.parameters.get('args', ())
        kwargs = task.parameters.get('kwargs', {})
        
        if func is None:
            raise ValueError("å¹¶è¡Œè®¡ç®—éœ€è¦æŒ‡å®šå‡½æ•°")
        
        return self.numba_accelerator.parallel_compute(data, func, *args, **kwargs)
    
    def _cleanup_completed_tasks(self):
        """æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡"""
        # ä¿ç•™æœ€è¿‘1å°æ—¶çš„ä»»åŠ¡
        cutoff_time = datetime.now() - timedelta(hours=1)
        
        with self._lock:
            # è¿‡æ»¤å·²å®Œæˆä»»åŠ¡
            filtered_tasks = deque()
            for task in self.completed_tasks:
                if task.completed_at and task.completed_at >= cutoff_time:
                    filtered_tasks.append(task)
            
            self.completed_tasks = filtered_tasks
    
    def get_scheduler_status(self) -> Dict:
        """è·å–è°ƒåº¦å™¨çŠ¶æ€"""
        return {
            'running': self._running,
            'queued_tasks': len(self.task_queue),
            'running_tasks': len(self.running_tasks),
            'completed_tasks': len(self.completed_tasks),
            'max_concurrent_tasks': self.max_concurrent_tasks,
            'cuda_available': self.cuda_accelerator.available,
            'numba_available': self.numba_accelerator.available
        }

class GPUAccelerator:
    """GPUåŠ é€Ÿå™¨ä¸»ç±»"""
    
    def __init__(self, device_id: int = 0, max_concurrent_tasks: int = 4):
        self.logger = UnifiedLogger("GPUAccelerator")
        self.device_id = device_id
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.cuda_accelerator = CUDAAccelerator(device_id)
        self.numba_accelerator = NumbaAccelerator()
        self.task_scheduler = GPUTaskScheduler(max_concurrent_tasks)
        
        # å¯åŠ¨è°ƒåº¦å™¨
        self.task_scheduler.start()
        
        self.logger.info("GPUåŠ é€Ÿå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def get_system_info(self) -> Dict:
        """è·å–GPUç³»ç»Ÿä¿¡æ¯"""
        info = {
            'cuda_available': CUPY_AVAILABLE,
            'opencl_available': OPENCL_AVAILABLE,
            'numba_available': NUMBA_AVAILABLE,
            'device_id': self.device_id
        }
        
        # è·å–GPUè®¾å¤‡ä¿¡æ¯
        gpu_info = self.cuda_accelerator.get_device_info()
        if gpu_info:
            info['gpu_info'] = gpu_info.__dict__
        
        # è·å–å†…å­˜ä¿¡æ¯
        if self.cuda_accelerator.memory_pool:
            info['memory_info'] = self.cuda_accelerator.memory_pool.get_memory_info()
        
        # è·å–è°ƒåº¦å™¨çŠ¶æ€
        info['scheduler_status'] = self.task_scheduler.get_scheduler_status()
        
        return info
    
    def submit_computation(self, function_name: str, data: Any, parameters: Dict[str, Any] = None, priority: int = 1) -> str:
        """æäº¤GPUè®¡ç®—ä»»åŠ¡"""
        return self.task_scheduler.submit_task(function_name, data, parameters, priority)
    
    def get_result(self, task_id: str) -> Optional[ComputeTask]:
        """è·å–è®¡ç®—ç»“æœ"""
        return self.task_scheduler.get_task_result(task_id)
    
    def wait_for_result(self, task_id: str, timeout: float = 30.0) -> Optional[Any]:
        """ç­‰å¾…è®¡ç®—ç»“æœ"""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            task = self.get_result(task_id)
            if task and task.completed_at:
                if task.error:
                    raise RuntimeError(f"ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {task.error}")
                return task.result
            
            time.sleep(0.1)
        
        raise TimeoutError(f"ä»»åŠ¡ {task_id} è¶…æ—¶")
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        try:
            self.task_scheduler.stop()
            
            if self.cuda_accelerator.memory_pool:
                self.cuda_accelerator.memory_pool.cleanup()
            
            self.logger.info("GPUåŠ é€Ÿå™¨èµ„æºå·²æ¸…ç†")
            
        except Exception as e:
            self.logger.error(f"æ¸…ç†GPUèµ„æºå¤±è´¥: {e}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºGPUåŠ é€Ÿå™¨
    gpu_accelerator = GPUAccelerator()
    
    try:
        # è·å–ç³»ç»Ÿä¿¡æ¯
        system_info = gpu_accelerator.get_system_info()
        print("GPUç³»ç»Ÿä¿¡æ¯:", json.dumps(system_info, indent=2, default=str, ensure_ascii=False))
        
        # æµ‹è¯•çŸ©é˜µä¹˜æ³•
        a = np.random.rand(1000, 1000).astype(np.float32)
        b = np.random.rand(1000, 1000).astype(np.float32)
        
        task_id = gpu_accelerator.submit_computation(
            'matrix_multiply',
            {'a': a, 'b': b},
            priority=1
        )
        
        print(f"æäº¤çŸ©é˜µä¹˜æ³•ä»»åŠ¡: {task_id}")
        
        # ç­‰å¾…ç»“æœ
        result = gpu_accelerator.wait_for_result(task_id, timeout=30)
        print(f"çŸ©é˜µä¹˜æ³•ç»“æœå½¢çŠ¶: {result.shape}")
        
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
    
    finally:
        gpu_accelerator.cleanup()
