"""
ğŸ“Š æƒ…æ„Ÿåˆ†ææ¨¡å— - ç”Ÿäº§çº§å®ç›˜äº¤æ˜“å¸‚åœºæƒ…æ„Ÿåˆ†æç³»ç»Ÿ
åŸºäºå¤šæºæ•°æ®çš„å¸‚åœºæƒ…æ„Ÿåˆ†æï¼ŒåŒ…å«æ–°é—»ã€ç¤¾äº¤åª’ä½“ã€æŠ€æœ¯æŒ‡æ ‡æƒ…æ„Ÿ
æ”¯æŒå®æ—¶æƒ…æ„Ÿç›‘æ§ã€æƒ…æ„ŸæŒ‡æ•°è®¡ç®—ã€æƒ…æ„Ÿé©±åŠ¨äº¤æ˜“ä¿¡å·ç”Ÿæˆ
"""
import asyncio
import re
import json
import time
import threading
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import warnings
warnings.filterwarnings('ignore')

try:
    import numpy as np
    import pandas as pd
    from textblob import TextBlob
    import nltk
    from nltk.sentiment import SentimentIntensityAnalyzer
    from nltk.corpus import stopwords
    from nltk.tokenize import word_tokenize
    from nltk.stem import WordNetLemmatizer
    NLTK_AVAILABLE = True
except ImportError:
    NLTK_AVAILABLE = False
    print("NLTK not available, some sentiment analysis features will be limited")

try:
    import requests
    from bs4 import BeautifulSoup
    WEB_SCRAPING_AVAILABLE = True
except ImportError:
    WEB_SCRAPING_AVAILABLE = False
    print("Web scraping libraries not available")

from loguru import logger

class SentimentType(Enum):
    """æƒ…æ„Ÿç±»å‹"""
    VERY_NEGATIVE = "very_negative"  # æåº¦è´Ÿé¢
    NEGATIVE = "negative"  # è´Ÿé¢
    NEUTRAL = "neutral"  # ä¸­æ€§
    POSITIVE = "positive"  # æ­£é¢
    VERY_POSITIVE = "very_positive"  # æåº¦æ­£é¢

class DataSource(Enum):
    """æ•°æ®æºç±»å‹"""
    NEWS = "news"  # æ–°é—»
    SOCIAL_MEDIA = "social_media"  # ç¤¾äº¤åª’ä½“
    TECHNICAL = "technical"  # æŠ€æœ¯æŒ‡æ ‡
    FUNDAMENTAL = "fundamental"  # åŸºæœ¬é¢
    MARKET_DATA = "market_data"  # å¸‚åœºæ•°æ®

@dataclass
class SentimentData:
    """æƒ…æ„Ÿæ•°æ®"""
    text: str  # åŸå§‹æ–‡æœ¬
    sentiment_score: float  # æƒ…æ„Ÿå¾—åˆ† (-1åˆ°1)
    sentiment_type: SentimentType  # æƒ…æ„Ÿç±»å‹
    confidence: float  # ç½®ä¿¡åº¦
    source: DataSource  # æ•°æ®æº
    symbol: str  # ç›¸å…³äº¤æ˜“å¯¹
    timestamp: float  # æ—¶é—´æˆ³
    metadata: Dict[str, Any] = field(default_factory=dict)  # å…ƒæ•°æ®

@dataclass
class SentimentIndex:
    """æƒ…æ„ŸæŒ‡æ•°"""
    symbol: str  # äº¤æ˜“å¯¹
    overall_sentiment: float  # æ€»ä½“æƒ…æ„Ÿ (-1åˆ°1)
    sentiment_type: SentimentType  # æƒ…æ„Ÿç±»å‹
    confidence: float  # ç½®ä¿¡åº¦
    news_sentiment: float  # æ–°é—»æƒ…æ„Ÿ
    social_sentiment: float  # ç¤¾äº¤æƒ…æ„Ÿ
    technical_sentiment: float  # æŠ€æœ¯æƒ…æ„Ÿ
    volume_weighted_sentiment: float  # æˆäº¤é‡åŠ æƒæƒ…æ„Ÿ
    sentiment_momentum: float  # æƒ…æ„ŸåŠ¨é‡
    sentiment_volatility: float  # æƒ…æ„Ÿæ³¢åŠ¨ç‡
    data_count: int  # æ•°æ®ç‚¹æ•°é‡
    timestamp: float  # æ—¶é—´æˆ³

class TextPreprocessor:
    """æ–‡æœ¬é¢„å¤„ç†å™¨"""
    
    def __init__(self):
        self.lemmatizer = None
        self.stop_words = set()
        
        if NLTK_AVAILABLE:
            try:
                # ä¸‹è½½å¿…è¦çš„NLTKæ•°æ®
                nltk.download('punkt', quiet=True)
                nltk.download('stopwords', quiet=True)
                nltk.download('wordnet', quiet=True)
                nltk.download('vader_lexicon', quiet=True)
                
                self.lemmatizer = WordNetLemmatizer()
                self.stop_words = set(stopwords.words('english'))
            except Exception as e:
                logger.warning(f"NLTKåˆå§‹åŒ–å¤±è´¥: {e}")
        
        # é‡‘èç›¸å…³å…³é”®è¯
        self.financial_keywords = {
            'positive': ['bull', 'bullish', 'rise', 'up', 'gain', 'profit', 'buy', 'long', 
                        'moon', 'pump', 'surge', 'rally', 'breakout', 'support'],
            'negative': ['bear', 'bearish', 'fall', 'down', 'loss', 'sell', 'short', 
                        'crash', 'dump', 'drop', 'decline', 'resistance', 'breakdown']
        }
        
        logger.info("æ–‡æœ¬é¢„å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def preprocess_text(self, text: str) -> str:
        """é¢„å¤„ç†æ–‡æœ¬"""
        try:
            # è½¬æ¢ä¸ºå°å†™
            text = text.lower()
            
            # ç§»é™¤URL
            text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
            
            # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™å­—æ¯ã€æ•°å­—å’Œç©ºæ ¼
            text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
            
            # ç§»é™¤å¤šä½™ç©ºæ ¼
            text = re.sub(r'\s+', ' ', text).strip()
            
            if NLTK_AVAILABLE and self.lemmatizer:
                # åˆ†è¯
                tokens = word_tokenize(text)
                
                # ç§»é™¤åœç”¨è¯å’Œè¯å½¢è¿˜åŸ
                tokens = [self.lemmatizer.lemmatize(token) 
                         for token in tokens 
                         if token not in self.stop_words and len(token) > 2]
                
                text = ' '.join(tokens)
            
            return text
        
        except Exception as e:
            logger.error(f"æ–‡æœ¬é¢„å¤„ç†å¤±è´¥: {e}")
            return text

class SentimentAnalyzer:
    """æƒ…æ„Ÿåˆ†æå™¨"""
    
    def __init__(self):
        self.preprocessor = TextPreprocessor()
        self.vader_analyzer = None
        
        if NLTK_AVAILABLE:
            try:
                self.vader_analyzer = SentimentIntensityAnalyzer()
            except Exception as e:
                logger.warning(f"VADERåˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # é‡‘èæƒ…æ„Ÿè¯å…¸
        self.financial_sentiment_dict = self._build_financial_sentiment_dict()
        
        logger.info("æƒ…æ„Ÿåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _build_financial_sentiment_dict(self) -> Dict[str, float]:
        """æ„å»ºé‡‘èæƒ…æ„Ÿè¯å…¸"""
        sentiment_dict = {}
        
        # æ­£é¢è¯æ±‡
        positive_words = [
            'bull', 'bullish', 'rise', 'up', 'gain', 'profit', 'buy', 'long',
            'moon', 'pump', 'surge', 'rally', 'breakout', 'support', 'strong',
            'growth', 'increase', 'uptrend', 'momentum', 'breakthrough'
        ]
        
        # è´Ÿé¢è¯æ±‡
        negative_words = [
            'bear', 'bearish', 'fall', 'down', 'loss', 'sell', 'short',
            'crash', 'dump', 'drop', 'decline', 'resistance', 'breakdown',
            'weak', 'decrease', 'downtrend', 'correction', 'collapse'
        ]
        
        # åˆ†é…æƒ…æ„Ÿå¾—åˆ†
        for word in positive_words:
            sentiment_dict[word] = 0.8
        
        for word in negative_words:
            sentiment_dict[word] = -0.8
        
        return sentiment_dict
    
    def analyze_text_sentiment(self, text: str) -> Tuple[float, float]:
        """åˆ†ææ–‡æœ¬æƒ…æ„Ÿ"""
        try:
            # é¢„å¤„ç†æ–‡æœ¬
            processed_text = self.preprocessor.preprocess_text(text)
            
            sentiment_scores = []
            confidences = []
            
            # TextBlobåˆ†æ
            try:
                blob = TextBlob(text)
                textblob_score = blob.sentiment.polarity
                sentiment_scores.append(textblob_score)
                confidences.append(0.7)
            except Exception as e:
                logger.debug(f"TextBlobåˆ†æå¤±è´¥: {e}")
            
            # VADERåˆ†æ
            if self.vader_analyzer:
                try:
                    vader_scores = self.vader_analyzer.polarity_scores(text)
                    vader_score = vader_scores['compound']
                    sentiment_scores.append(vader_score)
                    confidences.append(0.8)
                except Exception as e:
                    logger.debug(f"VADERåˆ†æå¤±è´¥: {e}")
            
            # é‡‘èè¯å…¸åˆ†æ
            financial_score = self._analyze_financial_sentiment(processed_text)
            if financial_score != 0:
                sentiment_scores.append(financial_score)
                confidences.append(0.9)
            
            # è®¡ç®—åŠ æƒå¹³å‡
            if sentiment_scores:
                weighted_sentiment = np.average(sentiment_scores, weights=confidences)
                avg_confidence = np.mean(confidences)
            else:
                weighted_sentiment = 0.0
                avg_confidence = 0.0
            
            return weighted_sentiment, avg_confidence
        
        except Exception as e:
            logger.error(f"æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return 0.0, 0.0
    
    def _analyze_financial_sentiment(self, text: str) -> float:
        """åˆ†æé‡‘èæƒ…æ„Ÿ"""
        words = text.split()
        sentiment_sum = 0.0
        word_count = 0
        
        for word in words:
            if word in self.financial_sentiment_dict:
                sentiment_sum += self.financial_sentiment_dict[word]
                word_count += 1
        
        if word_count > 0:
            return sentiment_sum / word_count
        
        return 0.0
    
    def classify_sentiment(self, sentiment_score: float) -> SentimentType:
        """åˆ†ç±»æƒ…æ„Ÿç±»å‹"""
        if sentiment_score <= -0.6:
            return SentimentType.VERY_NEGATIVE
        elif sentiment_score <= -0.2:
            return SentimentType.NEGATIVE
        elif sentiment_score < 0.2:
            return SentimentType.NEUTRAL
        elif sentiment_score < 0.6:
            return SentimentType.POSITIVE
        else:
            return SentimentType.VERY_POSITIVE

class NewsCollector:
    """æ–°é—»æ”¶é›†å™¨"""
    
    def __init__(self):
        self.news_sources = [
            'https://cointelegraph.com',
            'https://coindesk.com',
            'https://decrypt.co',
            'https://bitcoinist.com'
        ]
        
        # è¯·æ±‚å¤´
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        logger.info("æ–°é—»æ”¶é›†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def collect_news(self, symbol: str, limit: int = 50) -> List[Dict[str, Any]]:
        """æ”¶é›†æ–°é—»"""
        if not WEB_SCRAPING_AVAILABLE:
            logger.warning("ç½‘é¡µæŠ“å–åŠŸèƒ½ä¸å¯ç”¨")
            return []
        
        news_articles = []
        
        try:
            # æ¨¡æ‹Ÿæ–°é—»æ•°æ® (å®é™…åº”ç”¨ä¸­åº”è¯¥ä»çœŸå®APIè·å–)
            sample_news = [
                {
                    'title': f'{symbol} shows strong bullish momentum',
                    'content': f'{symbol} price has been rising steadily with strong volume support',
                    'source': 'CoinTelegraph',
                    'timestamp': time.time() - 3600,
                    'url': 'https://example.com/news1'
                },
                {
                    'title': f'{symbol} faces resistance at key level',
                    'content': f'{symbol} is struggling to break above the resistance level',
                    'source': 'CoinDesk',
                    'timestamp': time.time() - 7200,
                    'url': 'https://example.com/news2'
                },
                {
                    'title': f'Market analysis: {symbol} outlook positive',
                    'content': f'Technical analysis suggests {symbol} has potential for further gains',
                    'source': 'Decrypt',
                    'timestamp': time.time() - 10800,
                    'url': 'https://example.com/news3'
                }
            ]
            
            news_articles.extend(sample_news[:limit])
            
            logger.info(f"æ”¶é›†åˆ° {len(news_articles)} æ¡æ–°é—»")
            
        except Exception as e:
            logger.error(f"æ–°é—»æ”¶é›†å¤±è´¥: {e}")
        
        return news_articles

class SocialMediaCollector:
    """ç¤¾äº¤åª’ä½“æ”¶é›†å™¨"""
    
    def __init__(self):
        # ç¤¾äº¤åª’ä½“å¹³å°é…ç½®
        self.platforms = ['twitter', 'reddit', 'telegram']
        
        logger.info("ç¤¾äº¤åª’ä½“æ”¶é›†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def collect_social_data(self, symbol: str, limit: int = 100) -> List[Dict[str, Any]]:
        """æ”¶é›†ç¤¾äº¤åª’ä½“æ•°æ®"""
        social_posts = []
        
        try:
            # æ¨¡æ‹Ÿç¤¾äº¤åª’ä½“æ•°æ® (å®é™…åº”ç”¨ä¸­åº”è¯¥ä»çœŸå®APIè·å–)
            sample_posts = [
                {
                    'text': f'{symbol} to the moon! ğŸš€ Strong buy signal',
                    'platform': 'twitter',
                    'author': 'crypto_trader_1',
                    'likes': 150,
                    'retweets': 45,
                    'timestamp': time.time() - 1800
                },
                {
                    'text': f'Bearish on {symbol}, expecting a pullback',
                    'platform': 'reddit',
                    'author': 'market_analyst',
                    'upvotes': 23,
                    'comments': 12,
                    'timestamp': time.time() - 3600
                },
                {
                    'text': f'{symbol} looking strong, good entry point',
                    'platform': 'telegram',
                    'author': 'trading_group',
                    'views': 500,
                    'timestamp': time.time() - 5400
                }
            ]
            
            # ç”Ÿæˆæ›´å¤šæ ·æœ¬æ•°æ®
            for i in range(min(limit, 20)):
                post = sample_posts[i % len(sample_posts)].copy()
                post['timestamp'] = time.time() - (i * 300)  # æ¯5åˆ†é’Ÿä¸€æ¡
                social_posts.append(post)
            
            logger.info(f"æ”¶é›†åˆ° {len(social_posts)} æ¡ç¤¾äº¤åª’ä½“æ•°æ®")
            
        except Exception as e:
            logger.error(f"ç¤¾äº¤åª’ä½“æ•°æ®æ”¶é›†å¤±è´¥: {e}")
        
        return social_posts

class TechnicalSentimentAnalyzer:
    """æŠ€æœ¯æŒ‡æ ‡æƒ…æ„Ÿåˆ†æå™¨"""
    
    def __init__(self):
        logger.info("æŠ€æœ¯æŒ‡æ ‡æƒ…æ„Ÿåˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def analyze_technical_sentiment(self, market_data: pd.DataFrame) -> float:
        """åˆ†ææŠ€æœ¯æŒ‡æ ‡æƒ…æ„Ÿ"""
        try:
            if len(market_data) < 20:
                return 0.0
            
            sentiment_scores = []
            
            # RSIæƒ…æ„Ÿ
            rsi_sentiment = self._analyze_rsi_sentiment(market_data)
            sentiment_scores.append(rsi_sentiment)
            
            # MACDæƒ…æ„Ÿ
            macd_sentiment = self._analyze_macd_sentiment(market_data)
            sentiment_scores.append(macd_sentiment)
            
            # ç§»åŠ¨å¹³å‡æƒ…æ„Ÿ
            ma_sentiment = self._analyze_ma_sentiment(market_data)
            sentiment_scores.append(ma_sentiment)
            
            # æˆäº¤é‡æƒ…æ„Ÿ
            volume_sentiment = self._analyze_volume_sentiment(market_data)
            sentiment_scores.append(volume_sentiment)
            
            # è®¡ç®—å¹³å‡æƒ…æ„Ÿ
            avg_sentiment = np.mean(sentiment_scores)
            
            return np.clip(avg_sentiment, -1.0, 1.0)
        
        except Exception as e:
            logger.error(f"æŠ€æœ¯æŒ‡æ ‡æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return 0.0
    
    def _analyze_rsi_sentiment(self, data: pd.DataFrame) -> float:
        """åˆ†æRSIæƒ…æ„Ÿ"""
        try:
            # è®¡ç®—RSI
            delta = data['close'].diff()
            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
            rs = gain / loss
            rsi = 100 - (100 / (1 + rs))
            
            current_rsi = rsi.iloc[-1]
            
            # RSIæƒ…æ„Ÿæ˜ å°„
            if current_rsi > 70:
                return -0.5  # è¶…ä¹°ï¼Œè´Ÿé¢æƒ…æ„Ÿ
            elif current_rsi < 30:
                return 0.5   # è¶…å–ï¼Œæ­£é¢æƒ…æ„Ÿ
            else:
                return (50 - current_rsi) / 100  # ä¸­æ€§åŒºåŸŸ
        
        except Exception as e:
            logger.debug(f"RSIæƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return 0.0
    
    def _analyze_macd_sentiment(self, data: pd.DataFrame) -> float:
        """åˆ†æMACDæƒ…æ„Ÿ"""
        try:
            # è®¡ç®—MACD
            ema12 = data['close'].ewm(span=12).mean()
            ema26 = data['close'].ewm(span=26).mean()
            macd = ema12 - ema26
            signal = macd.ewm(span=9).mean()
            histogram = macd - signal
            
            current_histogram = histogram.iloc[-1]
            prev_histogram = histogram.iloc[-2]
            
            # MACDæƒ…æ„Ÿ
            if current_histogram > 0 and current_histogram > prev_histogram:
                return 0.6  # æ­£é¢åŠ¨é‡
            elif current_histogram < 0 and current_histogram < prev_histogram:
                return -0.6  # è´Ÿé¢åŠ¨é‡
            else:
                return current_histogram / abs(current_histogram) * 0.3 if current_histogram != 0 else 0
        
        except Exception as e:
            logger.debug(f"MACDæƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return 0.0
    
    def _analyze_ma_sentiment(self, data: pd.DataFrame) -> float:
        """åˆ†æç§»åŠ¨å¹³å‡æƒ…æ„Ÿ"""
        try:
            # è®¡ç®—ç§»åŠ¨å¹³å‡
            ma5 = data['close'].rolling(window=5).mean()
            ma20 = data['close'].rolling(window=20).mean()
            
            current_price = data['close'].iloc[-1]
            current_ma5 = ma5.iloc[-1]
            current_ma20 = ma20.iloc[-1]
            
            # ç§»åŠ¨å¹³å‡æƒ…æ„Ÿ
            sentiment = 0.0
            
            if current_price > current_ma5 > current_ma20:
                sentiment += 0.5  # å¼ºåŠ¿ä¸Šæ¶¨
            elif current_price < current_ma5 < current_ma20:
                sentiment -= 0.5  # å¼ºåŠ¿ä¸‹è·Œ
            
            # ä»·æ ¼ç›¸å¯¹äºMA20çš„ä½ç½®
            ma20_sentiment = (current_price - current_ma20) / current_ma20
            sentiment += np.clip(ma20_sentiment, -0.5, 0.5)
            
            return sentiment
        
        except Exception as e:
            logger.debug(f"ç§»åŠ¨å¹³å‡æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return 0.0
    
    def _analyze_volume_sentiment(self, data: pd.DataFrame) -> float:
        """åˆ†ææˆäº¤é‡æƒ…æ„Ÿ"""
        try:
            # è®¡ç®—æˆäº¤é‡ç§»åŠ¨å¹³å‡
            volume_ma = data['volume'].rolling(window=20).mean()
            current_volume = data['volume'].iloc[-1]
            avg_volume = volume_ma.iloc[-1]
            
            # ä»·æ ¼å˜åŒ–
            price_change = (data['close'].iloc[-1] - data['close'].iloc[-2]) / data['close'].iloc[-2]
            
            # æˆäº¤é‡æƒ…æ„Ÿ
            volume_ratio = current_volume / avg_volume if avg_volume > 0 else 1
            
            if volume_ratio > 1.5 and price_change > 0:
                return 0.4  # æ”¾é‡ä¸Šæ¶¨
            elif volume_ratio > 1.5 and price_change < 0:
                return -0.4  # æ”¾é‡ä¸‹è·Œ
            else:
                return 0.0  # æ­£å¸¸æˆäº¤é‡
        
        except Exception as e:
            logger.debug(f"æˆäº¤é‡æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return 0.0

class SentimentAggregator:
    """æƒ…æ„Ÿèšåˆå™¨"""
    
    def __init__(self):
        self.sentiment_analyzer = SentimentAnalyzer()
        self.news_collector = NewsCollector()
        self.social_collector = SocialMediaCollector()
        self.technical_analyzer = TechnicalSentimentAnalyzer()
        
        # æƒ…æ„Ÿå†å²æ•°æ®
        self.sentiment_history: Dict[str, List[SentimentData]] = {}
        self.sentiment_indices: Dict[str, List[SentimentIndex]] = {}
        
        # æƒé‡é…ç½®
        self.source_weights = {
            DataSource.NEWS: 0.3,
            DataSource.SOCIAL_MEDIA: 0.2,
            DataSource.TECHNICAL: 0.4,
            DataSource.MARKET_DATA: 0.1
        }
        
        logger.info("æƒ…æ„Ÿèšåˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def analyze_symbol_sentiment(self, symbol: str, market_data: pd.DataFrame = None) -> SentimentIndex:
        """åˆ†æäº¤æ˜“å¯¹æƒ…æ„Ÿ"""
        try:
            sentiment_data_list = []
            
            # æ”¶é›†æ–°é—»æƒ…æ„Ÿ
            news_articles = await self.news_collector.collect_news(symbol, limit=20)
            for article in news_articles:
                sentiment_score, confidence = self.sentiment_analyzer.analyze_text_sentiment(
                    article['title'] + ' ' + article['content']
                )
                
                sentiment_data = SentimentData(
                    text=article['title'],
                    sentiment_score=sentiment_score,
                    sentiment_type=self.sentiment_analyzer.classify_sentiment(sentiment_score),
                    confidence=confidence,
                    source=DataSource.NEWS,
                    symbol=symbol,
                    timestamp=article['timestamp'],
                    metadata=article
                )
                sentiment_data_list.append(sentiment_data)
            
            # æ”¶é›†ç¤¾äº¤åª’ä½“æƒ…æ„Ÿ
            social_posts = await self.social_collector.collect_social_data(symbol, limit=50)
            for post in social_posts:
                sentiment_score, confidence = self.sentiment_analyzer.analyze_text_sentiment(post['text'])
                
                sentiment_data = SentimentData(
                    text=post['text'],
                    sentiment_score=sentiment_score,
                    sentiment_type=self.sentiment_analyzer.classify_sentiment(sentiment_score),
                    confidence=confidence,
                    source=DataSource.SOCIAL_MEDIA,
                    symbol=symbol,
                    timestamp=post['timestamp'],
                    metadata=post
                )
                sentiment_data_list.append(sentiment_data)
            
            # åˆ†ææŠ€æœ¯æŒ‡æ ‡æƒ…æ„Ÿ
            technical_sentiment = 0.0
            if market_data is not None and len(market_data) > 0:
                technical_sentiment = self.technical_analyzer.analyze_technical_sentiment(market_data)
                
                technical_data = SentimentData(
                    text="Technical Analysis",
                    sentiment_score=technical_sentiment,
                    sentiment_type=self.sentiment_analyzer.classify_sentiment(technical_sentiment),
                    confidence=0.8,
                    source=DataSource.TECHNICAL,
                    symbol=symbol,
                    timestamp=time.time(),
                    metadata={'technical_sentiment': technical_sentiment}
                )
                sentiment_data_list.append(technical_data)
            
            # å­˜å‚¨æƒ…æ„Ÿæ•°æ®
            if symbol not in self.sentiment_history:
                self.sentiment_history[symbol] = []
            
            self.sentiment_history[symbol].extend(sentiment_data_list)
            
            # ä¿æŒå†å²æ•°æ®åœ¨åˆç†èŒƒå›´å†…
            if len(self.sentiment_history[symbol]) > 1000:
                self.sentiment_history[symbol] = self.sentiment_history[symbol][-1000:]
            
            # è®¡ç®—ç»¼åˆæƒ…æ„ŸæŒ‡æ•°
            sentiment_index = self._calculate_sentiment_index(symbol, sentiment_data_list, technical_sentiment)
            
            # å­˜å‚¨æƒ…æ„ŸæŒ‡æ•°
            if symbol not in self.sentiment_indices:
                self.sentiment_indices[symbol] = []
            
            self.sentiment_indices[symbol].append(sentiment_index)
            
            # ä¿æŒæŒ‡æ•°å†å²åœ¨åˆç†èŒƒå›´å†…
            if len(self.sentiment_indices[symbol]) > 100:
                self.sentiment_indices[symbol] = self.sentiment_indices[symbol][-100:]
            
            logger.info(f"å®Œæˆ{symbol}æƒ…æ„Ÿåˆ†æ - æ€»ä½“æƒ…æ„Ÿ: {sentiment_index.overall_sentiment:.3f}")
            
            return sentiment_index
        
        except Exception as e:
            logger.error(f"æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
            return self._create_neutral_sentiment_index(symbol)
    
    def _calculate_sentiment_index(self, symbol: str, sentiment_data_list: List[SentimentData], 
                                 technical_sentiment: float) -> SentimentIndex:
        """è®¡ç®—æƒ…æ„ŸæŒ‡æ•°"""
        try:
            if not sentiment_data_list:
                return self._create_neutral_sentiment_index(symbol)
            
            # æŒ‰æ•°æ®æºåˆ†ç»„
            source_sentiments = {source: [] for source in DataSource}
            
            for data in sentiment_data_list:
                source_sentiments[data.source].append(data.sentiment_score)
            
            # è®¡ç®—å„æ•°æ®æºå¹³å‡æƒ…æ„Ÿ
            news_sentiment = np.mean(source_sentiments[DataSource.NEWS]) if source_sentiments[DataSource.NEWS] else 0.0
            social_sentiment = np.mean(source_sentiments[DataSource.SOCIAL_MEDIA]) if source_sentiments[DataSource.SOCIAL_MEDIA] else 0.0
            
            # è®¡ç®—åŠ æƒæ€»ä½“æƒ…æ„Ÿ
            weighted_sentiments = []
            weights = []
            
            if source_sentiments[DataSource.NEWS]:
                weighted_sentiments.append(news_sentiment)
                weights.append(self.source_weights[DataSource.NEWS])
            
            if source_sentiments[DataSource.SOCIAL_MEDIA]:
                weighted_sentiments.append(social_sentiment)
                weights.append(self.source_weights[DataSource.SOCIAL_MEDIA])
            
            if technical_sentiment != 0:
                weighted_sentiments.append(technical_sentiment)
                weights.append(self.source_weights[DataSource.TECHNICAL])
            
            if weighted_sentiments:
                overall_sentiment = np.average(weighted_sentiments, weights=weights)
            else:
                overall_sentiment = 0.0
            
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence = min(len(sentiment_data_list) / 50.0, 1.0)  # åŸºäºæ•°æ®é‡çš„ç½®ä¿¡åº¦
            
            # è®¡ç®—æˆäº¤é‡åŠ æƒæƒ…æ„Ÿ (ç®€åŒ–å®ç°)
            volume_weighted_sentiment = overall_sentiment  # å®é™…åº”ç”¨ä¸­åº”è¯¥åŸºäºæˆäº¤é‡åŠ æƒ
            
            # è®¡ç®—æƒ…æ„ŸåŠ¨é‡
            sentiment_momentum = self._calculate_sentiment_momentum(symbol)
            
            # è®¡ç®—æƒ…æ„Ÿæ³¢åŠ¨ç‡
            sentiment_volatility = self._calculate_sentiment_volatility(symbol)
            
            # åˆ›å»ºæƒ…æ„ŸæŒ‡æ•°
            sentiment_index = SentimentIndex(
                symbol=symbol,
                overall_sentiment=overall_sentiment,
                sentiment_type=self.sentiment_analyzer.classify_sentiment(overall_sentiment),
                confidence=confidence,
                news_sentiment=news_sentiment,
                social_sentiment=social_sentiment,
                technical_sentiment=technical_sentiment,
                volume_weighted_sentiment=volume_weighted_sentiment,
                sentiment_momentum=sentiment_momentum,
                sentiment_volatility=sentiment_volatility,
                data_count=len(sentiment_data_list),
                timestamp=time.time()
            )
            
            return sentiment_index
        
        except Exception as e:
            logger.error(f"è®¡ç®—æƒ…æ„ŸæŒ‡æ•°å¤±è´¥: {e}")
            return self._create_neutral_sentiment_index(symbol)
    
    def _calculate_sentiment_momentum(self, symbol: str) -> float:
        """è®¡ç®—æƒ…æ„ŸåŠ¨é‡"""
        try:
            if symbol not in self.sentiment_indices or len(self.sentiment_indices[symbol]) < 2:
                return 0.0
            
            recent_indices = self.sentiment_indices[symbol][-5:]  # æœ€è¿‘5ä¸ªæŒ‡æ•°
            
            if len(recent_indices) < 2:
                return 0.0
            
            # è®¡ç®—æƒ…æ„Ÿå˜åŒ–ç‡
            sentiment_changes = []
            for i in range(1, len(recent_indices)):
                change = recent_indices[i].overall_sentiment - recent_indices[i-1].overall_sentiment
                sentiment_changes.append(change)
            
            momentum = np.mean(sentiment_changes)
            return np.clip(momentum, -1.0, 1.0)
        
        except Exception as e:
            logger.debug(f"è®¡ç®—æƒ…æ„ŸåŠ¨é‡å¤±è´¥: {e}")
            return 0.0
    
    def _calculate_sentiment_volatility(self, symbol: str) -> float:
        """è®¡ç®—æƒ…æ„Ÿæ³¢åŠ¨ç‡"""
        try:
            if symbol not in self.sentiment_indices or len(self.sentiment_indices[symbol]) < 5:
                return 0.0
            
            recent_indices = self.sentiment_indices[symbol][-20:]  # æœ€è¿‘20ä¸ªæŒ‡æ•°
            sentiments = [idx.overall_sentiment for idx in recent_indices]
            
            volatility = np.std(sentiments)
            return min(volatility, 1.0)  # é™åˆ¶åœ¨0-1èŒƒå›´å†…
        
        except Exception as e:
            logger.debug(f"è®¡ç®—æƒ…æ„Ÿæ³¢åŠ¨ç‡å¤±è´¥: {e}")
            return 0.0
    
    def _create_neutral_sentiment_index(self, symbol: str) -> SentimentIndex:
        """åˆ›å»ºä¸­æ€§æƒ…æ„ŸæŒ‡æ•°"""
        return SentimentIndex(
            symbol=symbol,
            overall_sentiment=0.0,
            sentiment_type=SentimentType.NEUTRAL,
            confidence=0.0,
            news_sentiment=0.0,
            social_sentiment=0.0,
            technical_sentiment=0.0,
            volume_weighted_sentiment=0.0,
            sentiment_momentum=0.0,
            sentiment_volatility=0.0,
            data_count=0,
            timestamp=time.time()
        )
    
    def get_sentiment_history(self, symbol: str, limit: int = 50) -> List[SentimentData]:
        """è·å–æƒ…æ„Ÿå†å²"""
        if symbol not in self.sentiment_history:
            return []
        
        return self.sentiment_history[symbol][-limit:]
    
    def get_sentiment_index_history(self, symbol: str, limit: int = 20) -> List[SentimentIndex]:
        """è·å–æƒ…æ„ŸæŒ‡æ•°å†å²"""
        if symbol not in self.sentiment_indices:
            return []
        
        return self.sentiment_indices[symbol][-limit:]
    
    def generate_sentiment_signals(self, symbol: str) -> Dict[str, Any]:
        """ç”Ÿæˆæƒ…æ„Ÿäº¤æ˜“ä¿¡å·"""
        try:
            if symbol not in self.sentiment_indices or not self.sentiment_indices[symbol]:
                return {'signal': 'HOLD', 'strength': 0.0, 'reason': 'æ— æƒ…æ„Ÿæ•°æ®'}
            
            current_index = self.sentiment_indices[symbol][-1]
            
            # ä¿¡å·ç”Ÿæˆé€»è¾‘
            signal = 'HOLD'
            strength = 0.0
            reasons = []
            
            # åŸºäºæ€»ä½“æƒ…æ„Ÿ
            if current_index.overall_sentiment > 0.4:
                signal = 'BUY'
                strength += abs(current_index.overall_sentiment) * 0.4
                reasons.append(f'æ­£é¢æƒ…æ„Ÿ ({current_index.overall_sentiment:.2f})')
            elif current_index.overall_sentiment < -0.4:
                signal = 'SELL'
                strength += abs(current_index.overall_sentiment) * 0.4
                reasons.append(f'è´Ÿé¢æƒ…æ„Ÿ ({current_index.overall_sentiment:.2f})')
            
            # åŸºäºæƒ…æ„ŸåŠ¨é‡
            if abs(current_index.sentiment_momentum) > 0.2:
                if current_index.sentiment_momentum > 0:
                    if signal != 'SELL':
                        signal = 'BUY'
                    strength += abs(current_index.sentiment_momentum) * 0.3
                    reasons.append(f'æƒ…æ„ŸåŠ¨é‡å‘ä¸Š ({current_index.sentiment_momentum:.2f})')
                else:
                    if signal != 'BUY':
                        signal = 'SELL'
                    strength += abs(current_index.sentiment_momentum) * 0.3
                    reasons.append(f'æƒ…æ„ŸåŠ¨é‡å‘ä¸‹ ({current_index.sentiment_momentum:.2f})')
            
            # åŸºäºæŠ€æœ¯æƒ…æ„Ÿ
            if abs(current_index.technical_sentiment) > 0.3:
                if current_index.technical_sentiment > 0:
                    if signal != 'SELL':
                        signal = 'BUY'
                    strength += abs(current_index.technical_sentiment) * 0.3
                    reasons.append(f'æŠ€æœ¯é¢æ­£é¢ ({current_index.technical_sentiment:.2f})')
                else:
                    if signal != 'BUY':
                        signal = 'SELL'
                    strength += abs(current_index.technical_sentiment) * 0.3
                    reasons.append(f'æŠ€æœ¯é¢è´Ÿé¢ ({current_index.technical_sentiment:.2f})')
            
            # ç½®ä¿¡åº¦è°ƒæ•´
            strength *= current_index.confidence
            
            # é™åˆ¶å¼ºåº¦èŒƒå›´
            strength = min(strength, 1.0)
            
            return {
                'signal': signal,
                'strength': strength,
                'confidence': current_index.confidence,
                'reasons': reasons,
                'sentiment_index': current_index,
                'timestamp': time.time()
            }
        
        except Exception as e:
            logger.error(f"ç”Ÿæˆæƒ…æ„Ÿä¿¡å·å¤±è´¥: {e}")
            return {'signal': 'HOLD', 'strength': 0.0, 'reason': 'ä¿¡å·ç”Ÿæˆå¤±è´¥'}

class SentimentMonitor:
    """æƒ…æ„Ÿç›‘æ§å™¨"""
    
    def __init__(self, update_interval: int = 300):  # 5åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡
        self.aggregator = SentimentAggregator()
        self.update_interval = update_interval
        self.monitored_symbols = set()
        self.running = False
        self.monitor_task = None
        
        logger.info("æƒ…æ„Ÿç›‘æ§å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def add_symbol(self, symbol: str):
        """æ·»åŠ ç›‘æ§äº¤æ˜“å¯¹"""
        self.monitored_symbols.add(symbol)
        logger.info(f"æ·»åŠ æƒ…æ„Ÿç›‘æ§: {symbol}")
    
    def remove_symbol(self, symbol: str):
        """ç§»é™¤ç›‘æ§äº¤æ˜“å¯¹"""
        self.monitored_symbols.discard(symbol)
        logger.info(f"ç§»é™¤æƒ…æ„Ÿç›‘æ§: {symbol}")
    
    async def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self.running:
            return
        
        self.running = True
        self.monitor_task = asyncio.create_task(self._monitor_loop())
        logger.info("æƒ…æ„Ÿç›‘æ§å™¨å·²å¯åŠ¨")
    
    async def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.running = False
        if self.monitor_task:
            self.monitor_task.cancel()
            try:
                await self.monitor_task
            except asyncio.CancelledError:
                pass
        
        logger.info("æƒ…æ„Ÿç›‘æ§å™¨å·²åœæ­¢")
    
    async def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.running:
            try:
                for symbol in self.monitored_symbols:
                    # åˆ†ææƒ…æ„Ÿ
                    sentiment_index = await self.aggregator.analyze_symbol_sentiment(symbol)
                    
                    # ç”Ÿæˆä¿¡å·
                    signals = self.aggregator.generate_sentiment_signals(symbol)
                    
                    # è®°å½•é‡è¦ä¿¡å·
                    if signals['strength'] > 0.6:
                        logger.info(f"å¼ºæƒ…æ„Ÿä¿¡å· - {symbol}: {signals['signal']} "
                                  f"(å¼ºåº¦: {signals['strength']:.2f}, ç½®ä¿¡åº¦: {signals['confidence']:.2f})")
                
                await asyncio.sleep(self.update_interval)
            
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"æƒ…æ„Ÿç›‘æ§å¾ªç¯é”™è¯¯: {e}")
                await asyncio.sleep(60)  # é”™è¯¯åç­‰å¾…1åˆ†é’Ÿ
    
    async def get_current_sentiment(self, symbol: str, market_data: pd.DataFrame = None) -> SentimentIndex:
        """è·å–å½“å‰æƒ…æ„Ÿ"""
        return await self.aggregator.analyze_symbol_sentiment(symbol, market_data)
    
    def get_sentiment_signals(self, symbol: str) -> Dict[str, Any]:
        """è·å–æƒ…æ„Ÿä¿¡å·"""
        return self.aggregator.generate_sentiment_signals(symbol)

# å…¨å±€æƒ…æ„Ÿç›‘æ§å™¨å®ä¾‹
sentiment_monitor = SentimentMonitor()


def initialize_sentiment_analysis():
    """åˆå§‹åŒ–æƒ…æ„Ÿåˆ†æç³»ç»Ÿ"""
    # è¿”å›å…¨å±€æƒ…æ„Ÿç›‘æ§å™¨å®ä¾‹
    global sentiment_monitor
    logger.success("âœ… æƒ…æ„Ÿåˆ†æç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    return sentiment_monitor
