#!/usr/bin/env python3
"""
ğŸ§  é›†æˆå­¦ä¹ åè°ƒAI - Level 5æ™ºèƒ½ä½“
Integration Learning Coordinator - Level 5 Agent

è´Ÿè´£åè°ƒå¤šä¸ªAIæ¨¡å‹çš„å†³ç­–ï¼Œå®ç°é›†æˆå­¦ä¹ å’Œæ¨¡å‹èåˆ
ä¸“ä¸ºç”Ÿäº§çº§å®ç›˜äº¤æ˜“è®¾è®¡ï¼Œæ”¯æŒåŠ¨æ€æƒé‡è°ƒæ•´å’Œæ€§èƒ½ä¼˜åŒ–
"""

import asyncio
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import json
from dataclasses import dataclass
from loguru import logger
import threading
import time
from concurrent.futures import ThreadPoolExecutor
from sklearn.ensemble import VotingRegressor, BaggingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.neural_network import MLPRegressor
import joblib
import warnings
warnings.filterwarnings('ignore')


@dataclass
class ModelPrediction:
    """æ¨¡å‹é¢„æµ‹ç»“æœ"""
    model_id: str
    model_name: str
    prediction: float
    confidence: float
    feature_importance: Dict[str, float]
    execution_time_ms: float
    timestamp: datetime


@dataclass
class CoordinationDecision:
    """åè°ƒå†³ç­–ç»“æœ"""
    signal: float           # -1åˆ°1ä¹‹é—´çš„ä¿¡å·
    confidence: float       # 0åˆ°1ä¹‹é—´çš„ç½®ä¿¡åº¦
    model_weights: Dict[str, float]  # å„æ¨¡å‹æƒé‡
    ensemble_method: str    # é›†æˆæ–¹æ³•
    feature_contributions: Dict[str, float]  # ç‰¹å¾è´¡çŒ®åº¦
    reasoning: str          # å†³ç­–æ¨ç†
    timestamp: datetime
    execution_time_ms: float


class EnsembleNetwork(nn.Module):
    """é›†æˆç¥ç»ç½‘ç»œ"""
    
    def __init__(self, input_dim: int, hidden_dims: List[int] = [64, 32, 16]):
        super(EnsembleNetwork, self).__init__()
        
        layers = []
        prev_dim = input_dim
        
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.BatchNorm1d(hidden_dim)
            ])
            prev_dim = hidden_dim
        
        # è¾“å‡ºå±‚
        layers.append(nn.Linear(prev_dim, 1))
        layers.append(nn.Tanh())  # è¾“å‡º-1åˆ°1ä¹‹é—´
        
        self.network = nn.Sequential(*layers)
        
    def forward(self, x):
        return self.network(x)


class IntegrationLearningCoordinator:
    """é›†æˆå­¦ä¹ åè°ƒAI"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–åè°ƒå™¨"""
        self.config = config or {}
        self.models = {}
        self.model_weights = {}
        self.performance_history = {}
        self.prediction_history = []
        self.is_training = False
        self.lock = threading.Lock()
        
        # é…ç½®å‚æ•°
        self.max_models = self.config.get('max_models', 10)
        self.weight_decay = self.config.get('weight_decay', 0.95)
        self.min_confidence = self.config.get('min_confidence', 0.1)
        self.ensemble_methods = ['weighted_average', 'voting', 'stacking', 'neural_ensemble']
        self.current_ensemble_method = 'weighted_average'
        
        # åˆå§‹åŒ–é›†æˆç½‘ç»œ
        self.ensemble_net = None
        self.ensemble_optimizer = None
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # åˆå§‹åŒ–åŸºç¡€æ¨¡å‹
        self._initialize_base_models()
        
        # å¯åŠ¨åå°ä»»åŠ¡
        self._start_background_tasks()
        
        logger.info("ğŸ§  é›†æˆå­¦ä¹ åè°ƒAI (Level 5) åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_base_models(self):
        """åˆå§‹åŒ–åŸºç¡€æ¨¡å‹"""
        try:
            # çº¿æ€§å›å½’æ¨¡å‹
            self.models['linear'] = {
                'instance': LinearRegression(),
                'weight': 0.2,
                'performance': 0.5,
                'last_update': time.time()
            }
            
            # å†³ç­–æ ‘æ¨¡å‹
            self.models['tree'] = {
                'instance': DecisionTreeRegressor(max_depth=10, random_state=42),
                'weight': 0.2,
                'performance': 0.5,
                'last_update': time.time()
            }
            
            # ç¥ç»ç½‘ç»œæ¨¡å‹
            self.models['mlp'] = {
                'instance': MLPRegressor(
                    hidden_layer_sizes=(64, 32),
                    max_iter=500,
                    random_state=42
                ),
                'weight': 0.3,
                'performance': 0.5,
                'last_update': time.time()
            }
            
            # Baggingé›†æˆæ¨¡å‹
            self.models['bagging'] = {
                'instance': BaggingRegressor(
                    base_estimator=DecisionTreeRegressor(max_depth=5),
                    n_estimators=10,
                    random_state=42
                ),
                'weight': 0.3,
                'performance': 0.5,
                'last_update': time.time()
            }
            
            logger.info(f"åˆå§‹åŒ– {len(self.models)} ä¸ªåŸºç¡€æ¨¡å‹")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–åŸºç¡€æ¨¡å‹å¤±è´¥: {e}")
    
    def _start_background_tasks(self):
        """å¯åŠ¨åå°ä»»åŠ¡"""
        # æƒé‡æ›´æ–°ä»»åŠ¡
        threading.Thread(
            target=self._weight_update_loop,
            daemon=True,
            name="WeightUpdateThread"
        ).start()
        
        # æ¨¡å‹é‡è®­ç»ƒä»»åŠ¡
        threading.Thread(
            target=self._retrain_loop,
            daemon=True,
            name="RetrainThread"
        ).start()
    
    async def coordinate_decision(self, market_data: Dict[str, Any]) -> CoordinationDecision:
        """åè°ƒå†³ç­–"""
        start_time = time.time()
        
        try:
            # å‡†å¤‡ç‰¹å¾æ•°æ®
            features = self._prepare_features(market_data)
            
            # æ”¶é›†å„æ¨¡å‹é¢„æµ‹
            model_predictions = await self._collect_model_predictions(features)
            
            # æ‰§è¡Œé›†æˆå†³ç­–
            coordination_result = await self._ensemble_predict(model_predictions, features)
            
            # è®°å½•é¢„æµ‹å†å²
            execution_time = (time.time() - start_time) * 1000
            coordination_result.execution_time_ms = execution_time
            
            self._record_prediction(coordination_result)
            
            logger.debug(f"åè°ƒå†³ç­–å®Œæˆ: ä¿¡å·={coordination_result.signal:.4f}, "
                        f"ç½®ä¿¡åº¦={coordination_result.confidence:.4f}, "
                        f"æ–¹æ³•={coordination_result.ensemble_method}")
            
            return coordination_result
            
        except Exception as e:
            logger.error(f"åè°ƒå†³ç­–å¤±è´¥: {e}")
            return CoordinationDecision(
                signal=0.0,
                confidence=0.0,
                model_weights={},
                ensemble_method="error",
                feature_contributions={},
                reasoning=f"å†³ç­–å¤±è´¥: {str(e)}",
                timestamp=datetime.now(),
                execution_time_ms=(time.time() - start_time) * 1000
            )
    
    def _prepare_features(self, market_data: Dict[str, Any]) -> np.ndarray:
        """å‡†å¤‡ç‰¹å¾æ•°æ®"""
        try:
            features = []
            
            # ä»·æ ¼ç‰¹å¾
            if 'price' in market_data:
                features.append(market_data['price'])
            
            # æˆäº¤é‡ç‰¹å¾
            if 'volume' in market_data:
                features.append(market_data['volume'])
            
            # æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
            if 'indicators' in market_data:
                indicators = market_data['indicators']
                for key, value in indicators.items():
                    if isinstance(value, (int, float)):
                        features.append(value)
            
            # æ—¶é—´ç‰¹å¾
            if 'timestamp' in market_data:
                timestamp = market_data['timestamp']
                features.extend([
                    timestamp % 86400,  # ä¸€å¤©å†…çš„ç§’æ•°
                    (timestamp // 86400) % 7,  # æ˜ŸæœŸå‡ 
                ])
            
            # ç¡®ä¿è‡³å°‘æœ‰ä¸€äº›ç‰¹å¾
            if len(features) < 5:
                features.extend([0.0] * (5 - len(features)))
            
            return np.array(features).reshape(1, -1)
            
        except Exception as e:
            logger.error(f"å‡†å¤‡ç‰¹å¾æ•°æ®å¤±è´¥: {e}")
            return np.array([[0.0] * 5])
    
    async def _collect_model_predictions(self, features: np.ndarray) -> List[ModelPrediction]:
        """æ”¶é›†å„æ¨¡å‹é¢„æµ‹"""
        predictions = []
        
        with self.lock:
            models_copy = self.models.copy()
        
        for model_id, model_info in models_copy.items():
            try:
                start_time = time.time()
                
                model_instance = model_info['instance']
                
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²è®­ç»ƒ
                if not hasattr(model_instance, 'predict'):
                    continue
                
                # æ‰§è¡Œé¢„æµ‹
                if hasattr(model_instance, 'predict'):
                    try:
                        prediction = model_instance.predict(features)[0]
                    except:
                        # å¦‚æœæ¨¡å‹æœªè®­ç»ƒï¼Œä½¿ç”¨é»˜è®¤é¢„æµ‹
                        prediction = 0.0
                else:
                    prediction = 0.0
                
                # è®¡ç®—ç½®ä¿¡åº¦
                confidence = self._calculate_model_confidence(model_id, prediction)
                
                # ç‰¹å¾é‡è¦æ€§
                feature_importance = self._get_feature_importance(model_instance, features)
                
                execution_time = (time.time() - start_time) * 1000
                
                predictions.append(ModelPrediction(
                    model_id=model_id,
                    model_name=model_id,
                    prediction=prediction,
                    confidence=confidence,
                    feature_importance=feature_importance,
                    execution_time_ms=execution_time,
                    timestamp=datetime.now()
                ))
                
            except Exception as e:
                logger.warning(f"æ¨¡å‹ {model_id} é¢„æµ‹å¤±è´¥: {e}")
                # æ·»åŠ é»˜è®¤é¢„æµ‹
                predictions.append(ModelPrediction(
                    model_id=model_id,
                    model_name=model_id,
                    prediction=0.0,
                    confidence=0.1,
                    feature_importance={},
                    execution_time_ms=0.0,
                    timestamp=datetime.now()
                ))
        
        return predictions
    
    def _calculate_model_confidence(self, model_id: str, prediction: float) -> float:
        """è®¡ç®—æ¨¡å‹ç½®ä¿¡åº¦"""
        try:
            # åŸºäºå†å²æ€§èƒ½çš„ç½®ä¿¡åº¦
            performance = self.models.get(model_id, {}).get('performance', 0.5)
            
            # åŸºäºé¢„æµ‹å€¼çš„ç½®ä¿¡åº¦è°ƒæ•´
            prediction_confidence = 1.0 - abs(prediction)  # é¢„æµ‹å€¼è¶Šæ¥è¿‘0ï¼Œç½®ä¿¡åº¦è¶Šä½
            
            # ç»¼åˆç½®ä¿¡åº¦
            confidence = (performance * 0.7 + prediction_confidence * 0.3)
            
            return np.clip(confidence, self.min_confidence, 1.0)
            
        except Exception as e:
            logger.error(f"è®¡ç®—æ¨¡å‹ç½®ä¿¡åº¦å¤±è´¥: {e}")
            return 0.5
    
    def _get_feature_importance(self, model_instance: Any, features: np.ndarray) -> Dict[str, float]:
        """è·å–ç‰¹å¾é‡è¦æ€§"""
        try:
            importance = {}
            
            # å†³ç­–æ ‘ç±»æ¨¡å‹
            if hasattr(model_instance, 'feature_importances_'):
                importances = model_instance.feature_importances_
                for i, imp in enumerate(importances):
                    importance[f'feature_{i}'] = float(imp)
            
            # çº¿æ€§æ¨¡å‹
            elif hasattr(model_instance, 'coef_'):
                coefs = model_instance.coef_
                if len(coefs.shape) == 1:
                    for i, coef in enumerate(coefs):
                        importance[f'feature_{i}'] = float(abs(coef))
            
            # ç¥ç»ç½‘ç»œç­‰å…¶ä»–æ¨¡å‹ï¼Œä½¿ç”¨ç®€å•çš„æƒé‡ä¼°è®¡
            else:
                for i in range(features.shape[1]):
                    importance[f'feature_{i}'] = 1.0 / features.shape[1]
            
            return importance
            
        except Exception as e:
            logger.error(f"è·å–ç‰¹å¾é‡è¦æ€§å¤±è´¥: {e}")
            return {}
    
    async def _ensemble_predict(self, predictions: List[ModelPrediction], features: np.ndarray) -> CoordinationDecision:
        """é›†æˆé¢„æµ‹"""
        if not predictions:
            return CoordinationDecision(
                signal=0.0,
                confidence=0.0,
                model_weights={},
                ensemble_method="no_models",
                feature_contributions={},
                reasoning="æ— å¯ç”¨æ¨¡å‹",
                timestamp=datetime.now(),
                execution_time_ms=0.0
            )
        
        # æ ¹æ®å½“å‰é›†æˆæ–¹æ³•æ‰§è¡Œé¢„æµ‹
        if self.current_ensemble_method == 'weighted_average':
            return await self._weighted_average_ensemble(predictions)
        elif self.current_ensemble_method == 'voting':
            return await self._voting_ensemble(predictions)
        elif self.current_ensemble_method == 'stacking':
            return await self._stacking_ensemble(predictions, features)
        elif self.current_ensemble_method == 'neural_ensemble':
            return await self._neural_ensemble(predictions, features)
        else:
            return await self._weighted_average_ensemble(predictions)
    
    async def _weighted_average_ensemble(self, predictions: List[ModelPrediction]) -> CoordinationDecision:
        """åŠ æƒå¹³å‡é›†æˆ"""
        try:
            weighted_sum = 0.0
            total_weight = 0.0
            model_weights = {}
            feature_contributions = {}
            
            for pred in predictions:
                # è·å–æ¨¡å‹æƒé‡
                model_weight = self.models.get(pred.model_id, {}).get('weight', 0.1)
                
                # åŸºäºç½®ä¿¡åº¦è°ƒæ•´æƒé‡
                adjusted_weight = model_weight * pred.confidence
                
                weighted_sum += pred.prediction * adjusted_weight
                total_weight += adjusted_weight
                model_weights[pred.model_id] = adjusted_weight
                
                # ç´¯ç§¯ç‰¹å¾è´¡çŒ®åº¦
                for feature, importance in pred.feature_importance.items():
                    if feature not in feature_contributions:
                        feature_contributions[feature] = 0.0
                    feature_contributions[feature] += importance * adjusted_weight
            
            # è®¡ç®—æœ€ç»ˆä¿¡å·
            if total_weight > 0:
                final_signal = weighted_sum / total_weight
                # å½’ä¸€åŒ–æ¨¡å‹æƒé‡
                for model_id in model_weights:
                    model_weights[model_id] /= total_weight
                # å½’ä¸€åŒ–ç‰¹å¾è´¡çŒ®åº¦
                for feature in feature_contributions:
                    feature_contributions[feature] /= total_weight
            else:
                final_signal = 0.0
            
            # è®¡ç®—ç»¼åˆç½®ä¿¡åº¦
            confidence = min(total_weight, 1.0) if total_weight > 0 else 0.0
            
            # ç”Ÿæˆæ¨ç†
            reasoning = f"åŠ æƒå¹³å‡é›†æˆ {len(predictions)} ä¸ªæ¨¡å‹"
            
            return CoordinationDecision(
                signal=np.clip(final_signal, -1.0, 1.0),
                confidence=confidence,
                model_weights=model_weights,
                ensemble_method="weighted_average",
                feature_contributions=feature_contributions,
                reasoning=reasoning,
                timestamp=datetime.now(),
                execution_time_ms=0.0
            )
            
        except Exception as e:
            logger.error(f"åŠ æƒå¹³å‡é›†æˆå¤±è´¥: {e}")
            return CoordinationDecision(
                signal=0.0,
                confidence=0.0,
                model_weights={},
                ensemble_method="error",
                feature_contributions={},
                reasoning=f"é›†æˆå¤±è´¥: {str(e)}",
                timestamp=datetime.now(),
                execution_time_ms=0.0
            )
    
    async def _voting_ensemble(self, predictions: List[ModelPrediction]) -> CoordinationDecision:
        """æŠ•ç¥¨é›†æˆ"""
        try:
            # å°†è¿ç»­é¢„æµ‹è½¬æ¢ä¸ºç¦»æ•£æŠ•ç¥¨
            votes = {'buy': 0, 'sell': 0, 'hold': 0}
            model_weights = {}
            
            for pred in predictions:
                model_weight = self.models.get(pred.model_id, {}).get('weight', 0.1)
                adjusted_weight = model_weight * pred.confidence
                
                # è½¬æ¢ä¸ºæŠ•ç¥¨
                if pred.prediction > 0.1:
                    votes['buy'] += adjusted_weight
                elif pred.prediction < -0.1:
                    votes['sell'] += adjusted_weight
                else:
                    votes['hold'] += adjusted_weight
                
                model_weights[pred.model_id] = adjusted_weight
            
            # ç¡®å®šæœ€ç»ˆä¿¡å·
            max_vote = max(votes.values())
            if max_vote == 0:
                final_signal = 0.0
                confidence = 0.0
            else:
                if votes['buy'] == max_vote:
                    final_signal = 0.5
                elif votes['sell'] == max_vote:
                    final_signal = -0.5
                else:
                    final_signal = 0.0
                
                # è®¡ç®—ç½®ä¿¡åº¦
                total_votes = sum(votes.values())
                confidence = max_vote / total_votes if total_votes > 0 else 0.0
            
            reasoning = f"æŠ•ç¥¨é›†æˆ: ä¹°å…¥={votes['buy']:.2f}, å–å‡º={votes['sell']:.2f}, æŒæœ‰={votes['hold']:.2f}"
            
            return CoordinationDecision(
                signal=final_signal,
                confidence=confidence,
                model_weights=model_weights,
                ensemble_method="voting",
                feature_contributions={},
                reasoning=reasoning,
                timestamp=datetime.now(),
                execution_time_ms=0.0
            )
            
        except Exception as e:
            logger.error(f"æŠ•ç¥¨é›†æˆå¤±è´¥: {e}")
            return await self._weighted_average_ensemble(predictions)
    
    async def _stacking_ensemble(self, predictions: List[ModelPrediction], features: np.ndarray) -> CoordinationDecision:
        """å †å é›†æˆ"""
        try:
            # ç®€åŒ–çš„å †å å®ç°ï¼šä½¿ç”¨çº¿æ€§å›å½’ä½œä¸ºå…ƒå­¦ä¹ å™¨
            if len(predictions) < 2:
                return await self._weighted_average_ensemble(predictions)
            
            # æ„å»ºå…ƒç‰¹å¾
            meta_features = []
            for pred in predictions:
                meta_features.append(pred.prediction)
                meta_features.append(pred.confidence)
            
            # ç®€å•çš„çº¿æ€§ç»„åˆ
            weights = np.array([0.8, 0.2] * len(predictions))[:len(meta_features)]
            weights = weights / weights.sum()
            
            final_signal = np.dot(meta_features, weights)
            confidence = np.mean([pred.confidence for pred in predictions])
            
            model_weights = {pred.model_id: 1.0/len(predictions) for pred in predictions}
            
            return CoordinationDecision(
                signal=np.clip(final_signal, -1.0, 1.0),
                confidence=confidence,
                model_weights=model_weights,
                ensemble_method="stacking",
                feature_contributions={},
                reasoning=f"å †å é›†æˆ {len(predictions)} ä¸ªæ¨¡å‹",
                timestamp=datetime.now(),
                execution_time_ms=0.0
            )
            
        except Exception as e:
            logger.error(f"å †å é›†æˆå¤±è´¥: {e}")
            return await self._weighted_average_ensemble(predictions)
    
    async def _neural_ensemble(self, predictions: List[ModelPrediction], features: np.ndarray) -> CoordinationDecision:
        """ç¥ç»ç½‘ç»œé›†æˆ"""
        try:
            # å¦‚æœç¥ç»ç½‘ç»œæœªåˆå§‹åŒ–ï¼Œä½¿ç”¨åŠ æƒå¹³å‡
            if self.ensemble_net is None:
                return await self._weighted_average_ensemble(predictions)
            
            # æ„å»ºè¾“å…¥ç‰¹å¾
            ensemble_input = []
            ensemble_input.extend(features.flatten())
            for pred in predictions:
                ensemble_input.append(pred.prediction)
                ensemble_input.append(pred.confidence)
            
            # è½¬æ¢ä¸ºå¼ é‡
            input_tensor = torch.FloatTensor(ensemble_input).unsqueeze(0).to(self.device)
            
            # ç¥ç»ç½‘ç»œé¢„æµ‹
            with torch.no_grad():
                output = self.ensemble_net(input_tensor)
                final_signal = output.item()
            
            # è®¡ç®—ç½®ä¿¡åº¦
            confidence = np.mean([pred.confidence for pred in predictions])
            
            model_weights = {pred.model_id: 1.0/len(predictions) for pred in predictions}
            
            return CoordinationDecision(
                signal=np.clip(final_signal, -1.0, 1.0),
                confidence=confidence,
                model_weights=model_weights,
                ensemble_method="neural_ensemble",
                feature_contributions={},
                reasoning=f"ç¥ç»ç½‘ç»œé›†æˆ {len(predictions)} ä¸ªæ¨¡å‹",
                timestamp=datetime.now(),
                execution_time_ms=0.0
            )
            
        except Exception as e:
            logger.error(f"ç¥ç»ç½‘ç»œé›†æˆå¤±è´¥: {e}")
            return await self._weighted_average_ensemble(predictions)
    
    def _record_prediction(self, decision: CoordinationDecision):
        """è®°å½•é¢„æµ‹å†å²"""
        with self.lock:
            self.prediction_history.append(decision)
            
            # é™åˆ¶å†å²è®°å½•æ•°é‡
            if len(self.prediction_history) > 1000:
                self.prediction_history = self.prediction_history[-1000:]
    
    def _weight_update_loop(self):
        """æƒé‡æ›´æ–°å¾ªç¯"""
        while True:
            try:
                time.sleep(300)  # 5åˆ†é’Ÿæ›´æ–°ä¸€æ¬¡
                self._update_model_weights()
            except Exception as e:
                logger.error(f"æƒé‡æ›´æ–°å¤±è´¥: {e}")
    
    def _retrain_loop(self):
        """é‡è®­ç»ƒå¾ªç¯"""
        while True:
            try:
                time.sleep(3600)  # 1å°æ—¶é‡è®­ç»ƒä¸€æ¬¡
                await self._retrain_models()
            except Exception as e:
                logger.error(f"é‡è®­ç»ƒå¤±è´¥: {e}")
    
    def _update_model_weights(self):
        """æ›´æ–°æ¨¡å‹æƒé‡"""
        try:
            with self.lock:
                # åŸºäºå†å²æ€§èƒ½æ›´æ–°æƒé‡
                for model_id in self.models:
                    current_weight = self.models[model_id]['weight']
                    performance = self.models[model_id]['performance']
                    
                    # æƒé‡è¡°å‡å’Œæ€§èƒ½è°ƒæ•´
                    new_weight = current_weight * self.weight_decay + performance * (1 - self.weight_decay)
                    self.models[model_id]['weight'] = np.clip(new_weight, 0.01, 1.0)
                
                # å½’ä¸€åŒ–æƒé‡
                total_weight = sum(model['weight'] for model in self.models.values())
                if total_weight > 0:
                    for model_id in self.models:
                        self.models[model_id]['weight'] /= total_weight
                
                logger.debug("æ¨¡å‹æƒé‡å·²æ›´æ–°")
                
        except Exception as e:
            logger.error(f"æ›´æ–°æ¨¡å‹æƒé‡å¤±è´¥: {e}")
    
    async def _retrain_models(self):
        """é‡è®­ç»ƒæ¨¡å‹"""
        if self.is_training:
            return
        
        self.is_training = True
        try:
            # è¿™é‡Œåº”è¯¥å®ç°æ¨¡å‹é‡è®­ç»ƒé€»è¾‘
            # ç”±äºéœ€è¦è®­ç»ƒæ•°æ®ï¼Œè¿™é‡Œåªæ˜¯å ä½ç¬¦
            logger.info("å¼€å§‹é‡è®­ç»ƒæ¨¡å‹...")
            
            # æ¨¡æ‹Ÿé‡è®­ç»ƒè¿‡ç¨‹
            await asyncio.sleep(1)
            
            logger.info("æ¨¡å‹é‡è®­ç»ƒå®Œæˆ")
            
        except Exception as e:
            logger.error(f"é‡è®­ç»ƒæ¨¡å‹å¤±è´¥: {e}")
        finally:
            self.is_training = False
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–çŠ¶æ€ä¿¡æ¯"""
        with self.lock:
            return {
                'level': 5,
                'name': 'Integration Learning Coordinator',
                'models_count': len(self.models),
                'current_ensemble_method': self.current_ensemble_method,
                'prediction_count': len(self.prediction_history),
                'is_training': self.is_training,
                'model_weights': {
                    model_id: info['weight'] 
                    for model_id, info in self.models.items()
                },
                'model_performance': {
                    model_id: info['performance'] 
                    for model_id, info in self.models.items()
                }
            }


# å…¨å±€å®ä¾‹
_coordinator = None

def get_integration_coordinator(config: Dict[str, Any] = None) -> IntegrationLearningCoordinator:
    """è·å–é›†æˆå­¦ä¹ åè°ƒå™¨å®ä¾‹"""
    global _coordinator
    if _coordinator is None:
        _coordinator = IntegrationLearningCoordinator(config)
    return _coordinator


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    async def test_coordinator():
        """æµ‹è¯•åè°ƒå™¨"""
        coordinator = get_integration_coordinator()
        
        # æ¨¡æ‹Ÿå¸‚åœºæ•°æ®
        market_data = {
            'price': 50000.0,
            'volume': 1000.0,
            'indicators': {
                'rsi': 65.0,
                'macd': 0.5,
                'bb_upper': 51000.0,
                'bb_lower': 49000.0
            },
            'timestamp': time.time()
        }
        
        # æ‰§è¡Œåè°ƒå†³ç­–
        decision = await coordinator.coordinate_decision(market_data)
        
        print(f"åè°ƒå†³ç­–ç»“æœ:")
        print(f"ä¿¡å·: {decision.signal}")
        print(f"ç½®ä¿¡åº¦: {decision.confidence}")
        print(f"é›†æˆæ–¹æ³•: {decision.ensemble_method}")
        print(f"æ¨ç†: {decision.reasoning}")
        
        # è·å–çŠ¶æ€
        status = coordinator.get_status()
        print(f"\nåè°ƒå™¨çŠ¶æ€: {json.dumps(status, indent=2)}")
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_coordinator())
