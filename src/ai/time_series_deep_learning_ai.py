#!/usr/bin/env python3
"""
ğŸ§  æ—¶åºæ·±åº¦å­¦ä¹ AI - Level 3æ™ºèƒ½ä½“
Time Series Deep Learning AI - Level 3 Agent

ä¸“æ³¨äºæ—¶é—´åºåˆ—é¢„æµ‹ï¼Œä½¿ç”¨LSTM/Transformerç­‰æ·±åº¦å­¦ä¹ æ¨¡å‹
å®ç°å¤šæ—¶é—´å°ºåº¦é¢„æµ‹ã€æ³¨æ„åŠ›æœºåˆ¶ã€åºåˆ—åˆ°åºåˆ—å­¦ä¹ 
"""

import asyncio
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime, timedelta
import json
from dataclasses import dataclass
from loguru import logger
import threading
import time
from collections import deque
import warnings
warnings.filterwarnings('ignore')


@dataclass
class TimeSeriesPrediction:
    """æ—¶åºé¢„æµ‹ç»“æœ"""
    signal: float           # -1åˆ°1ä¹‹é—´çš„ä¿¡å·
    confidence: float       # 0åˆ°1ä¹‹é—´çš„ç½®ä¿¡åº¦
    prediction_horizon: int # é¢„æµ‹æ—¶é—´èŒƒå›´(åˆ†é’Ÿ)
    attention_weights: Dict[str, float]  # æ³¨æ„åŠ›æƒé‡
    sequence_importance: List[float]     # åºåˆ—é‡è¦æ€§
    model_type: str         # æ¨¡å‹ç±»å‹
    reasoning: str          # é¢„æµ‹æ¨ç†
    timestamp: datetime
    execution_time_ms: float


class LSTMPredictor(nn.Module):
    """LSTMé¢„æµ‹å™¨"""
    
    def __init__(self, input_size: int, hidden_size: int = 128, num_layers: int = 2, dropout: float = 0.2):
        super(LSTMPredictor, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # LSTMå±‚
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout=dropout,
            batch_first=True,
            bidirectional=True
        )
        
        # æ³¨æ„åŠ›æœºåˆ¶
        self.attention = nn.MultiheadAttention(
            embed_dim=hidden_size * 2,
            num_heads=8,
            dropout=dropout,
            batch_first=True
        )
        
        # è¾“å‡ºå±‚
        self.fc = nn.Sequential(
            nn.Linear(hidden_size * 2, hidden_size),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size, 32),
            nn.ReLU(),
            nn.Linear(32, 1),
            nn.Tanh()  # è¾“å‡º-1åˆ°1ä¹‹é—´
        )
        
    def forward(self, x):
        # LSTMå¤„ç†
        lstm_out, _ = self.lstm(x)
        
        # æ³¨æ„åŠ›æœºåˆ¶
        attn_out, attn_weights = self.attention(lstm_out, lstm_out, lstm_out)
        
        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        output = self.fc(attn_out[:, -1, :])
        
        return output, attn_weights


class TransformerPredictor(nn.Module):
    """Transformeré¢„æµ‹å™¨"""
    
    def __init__(self, input_size: int, d_model: int = 128, nhead: int = 8, num_layers: int = 4, dropout: float = 0.1):
        super(TransformerPredictor, self).__init__()
        
        self.d_model = d_model
        
        # è¾“å…¥æŠ•å½±
        self.input_projection = nn.Linear(input_size, d_model)
        
        # ä½ç½®ç¼–ç 
        self.pos_encoding = PositionalEncoding(d_model, dropout)
        
        # Transformerç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 4,
            dropout=dropout,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)
        
        # è¾“å‡ºå±‚
        self.output_projection = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(d_model // 2, 1),
            nn.Tanh()
        )
        
    def forward(self, x):
        # è¾“å…¥æŠ•å½±
        x = self.input_projection(x)
        
        # ä½ç½®ç¼–ç 
        x = self.pos_encoding(x)
        
        # Transformerå¤„ç†
        transformer_out = self.transformer(x)
        
        # è¾“å‡ºæŠ•å½±
        output = self.output_projection(transformer_out[:, -1, :])
        
        return output


class PositionalEncoding(nn.Module):
    """ä½ç½®ç¼–ç """
    
    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):
        super(PositionalEncoding, self).__init__()
        self.dropout = nn.Dropout(p=dropout)
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        self.register_buffer('pe', pe)
        
    def forward(self, x):
        x = x + self.pe[:x.size(0), :].transpose(0, 1)
        return self.dropout(x)


class TimeSeriesDeepLearningAI:
    """æ—¶åºæ·±åº¦å­¦ä¹ AI"""
    
    def __init__(self, config: Dict[str, Any] = None):
        """åˆå§‹åŒ–æ—¶åºAI"""
        self.config = config or {}
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # é…ç½®å‚æ•°
        self.sequence_length = self.config.get('sequence_length', 60)  # 60ä¸ªæ—¶é—´ç‚¹
        self.feature_size = self.config.get('feature_size', 10)
        self.prediction_horizons = self.config.get('prediction_horizons', [5, 15, 30, 60])  # åˆ†é’Ÿ
        
        # æ•°æ®ç¼“å­˜
        self.data_buffer = deque(maxlen=1000)
        self.feature_buffer = deque(maxlen=1000)
        
        # æ¨¡å‹
        self.models = {}
        self.optimizers = {}
        self.is_training = False
        self.lock = threading.Lock()
        
        # é¢„æµ‹å†å²
        self.prediction_history = []
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._initialize_models()
        
        # å¯åŠ¨åå°ä»»åŠ¡
        self._start_background_tasks()
        
        logger.info("ğŸ§  æ—¶åºæ·±åº¦å­¦ä¹ AI (Level 3) åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_models(self):
        """åˆå§‹åŒ–æ¨¡å‹"""
        try:
            # LSTMæ¨¡å‹
            self.models['lstm'] = LSTMPredictor(
                input_size=self.feature_size,
                hidden_size=128,
                num_layers=2
            ).to(self.device)
            
            self.optimizers['lstm'] = optim.Adam(
                self.models['lstm'].parameters(),
                lr=0.001,
                weight_decay=1e-5
            )
            
            # Transformeræ¨¡å‹
            self.models['transformer'] = TransformerPredictor(
                input_size=self.feature_size,
                d_model=128,
                nhead=8,
                num_layers=4
            ).to(self.device)
            
            self.optimizers['transformer'] = optim.Adam(
                self.models['transformer'].parameters(),
                lr=0.0001,
                weight_decay=1e-5
            )
            
            logger.info(f"åˆå§‹åŒ– {len(self.models)} ä¸ªæ—¶åºæ¨¡å‹")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æ¨¡å‹å¤±è´¥: {e}")
    
    def _start_background_tasks(self):
        """å¯åŠ¨åå°ä»»åŠ¡"""
        # æ¨¡å‹è®­ç»ƒä»»åŠ¡
        threading.Thread(
            target=self._training_loop,
            daemon=True,
            name="TrainingThread"
        ).start()
        
        # æ•°æ®æ¸…ç†ä»»åŠ¡
        threading.Thread(
            target=self._data_cleanup_loop,
            daemon=True,
            name="DataCleanupThread"
        ).start()
    
    async def predict(self, market_data: Dict[str, Any]) -> TimeSeriesPrediction:
        """æ‰§è¡Œæ—¶åºé¢„æµ‹"""
        start_time = time.time()
        
        try:
            # æ›´æ–°æ•°æ®ç¼“å­˜
            self._update_data_buffer(market_data)
            
            # å‡†å¤‡åºåˆ—æ•°æ®
            sequence_data = self._prepare_sequence_data()
            
            if sequence_data is None:
                return self._get_default_prediction(start_time)
            
            # æ‰§è¡Œå¤šæ¨¡å‹é¢„æµ‹
            predictions = await self._multi_model_predict(sequence_data)
            
            # èåˆé¢„æµ‹ç»“æœ
            final_prediction = self._ensemble_predictions(predictions)
            
            # è®°å½•é¢„æµ‹å†å²
            execution_time = (time.time() - start_time) * 1000
            final_prediction.execution_time_ms = execution_time
            
            self._record_prediction(final_prediction)
            
            logger.debug(f"æ—¶åºé¢„æµ‹å®Œæˆ: ä¿¡å·={final_prediction.signal:.4f}, "
                        f"ç½®ä¿¡åº¦={final_prediction.confidence:.4f}")
            
            return final_prediction
            
        except Exception as e:
            logger.error(f"æ—¶åºé¢„æµ‹å¤±è´¥: {e}")
            return self._get_default_prediction(start_time, str(e))
    
    def _update_data_buffer(self, market_data: Dict[str, Any]):
        """æ›´æ–°æ•°æ®ç¼“å­˜"""
        try:
            # æå–ç‰¹å¾
            features = self._extract_features(market_data)
            
            # æ·»åŠ åˆ°ç¼“å­˜
            with self.lock:
                self.data_buffer.append(market_data)
                self.feature_buffer.append(features)
            
        except Exception as e:
            logger.error(f"æ›´æ–°æ•°æ®ç¼“å­˜å¤±è´¥: {e}")
    
    def _extract_features(self, market_data: Dict[str, Any]) -> np.ndarray:
        """æå–ç‰¹å¾"""
        try:
            features = []
            
            # ä»·æ ¼ç‰¹å¾
            if 'price' in market_data:
                features.append(market_data['price'])
            
            # æˆäº¤é‡ç‰¹å¾
            if 'volume' in market_data:
                features.append(market_data['volume'])
            
            # æŠ€æœ¯æŒ‡æ ‡ç‰¹å¾
            if 'indicators' in market_data:
                indicators = market_data['indicators']
                for key in ['rsi', 'macd', 'bb_upper', 'bb_lower', 'sma_20', 'ema_12', 'ema_26']:
                    features.append(indicators.get(key, 0.0))
            
            # æ—¶é—´ç‰¹å¾
            if 'timestamp' in market_data:
                timestamp = market_data['timestamp']
                features.extend([
                    timestamp % 86400,  # ä¸€å¤©å†…çš„ç§’æ•°
                    (timestamp // 86400) % 7,  # æ˜ŸæœŸå‡ 
                ])
            
            # ç¡®ä¿ç‰¹å¾æ•°é‡ä¸€è‡´
            while len(features) < self.feature_size:
                features.append(0.0)
            
            return np.array(features[:self.feature_size])
            
        except Exception as e:
            logger.error(f"æå–ç‰¹å¾å¤±è´¥: {e}")
            return np.zeros(self.feature_size)
    
    def _prepare_sequence_data(self) -> Optional[torch.Tensor]:
        """å‡†å¤‡åºåˆ—æ•°æ®"""
        try:
            with self.lock:
                if len(self.feature_buffer) < self.sequence_length:
                    return None
                
                # è·å–æœ€è¿‘çš„åºåˆ—æ•°æ®
                sequence = list(self.feature_buffer)[-self.sequence_length:]
                
            # è½¬æ¢ä¸ºå¼ é‡
            sequence_array = np.array(sequence)
            sequence_tensor = torch.FloatTensor(sequence_array).unsqueeze(0).to(self.device)
            
            return sequence_tensor
            
        except Exception as e:
            logger.error(f"å‡†å¤‡åºåˆ—æ•°æ®å¤±è´¥: {e}")
            return None
    
    async def _multi_model_predict(self, sequence_data: torch.Tensor) -> Dict[str, Dict]:
        """å¤šæ¨¡å‹é¢„æµ‹"""
        predictions = {}
        
        for model_name, model in self.models.items():
            try:
                model.eval()
                with torch.no_grad():
                    if model_name == 'lstm':
                        output, attention_weights = model(sequence_data)
                        
                        # å¤„ç†æ³¨æ„åŠ›æƒé‡
                        attn_weights_dict = {}
                        if attention_weights is not None:
                            attn_weights_np = attention_weights.cpu().numpy()[0, 0, :]  # å–ç¬¬ä¸€ä¸ªå¤´çš„æƒé‡
                            for i, weight in enumerate(attn_weights_np):
                                attn_weights_dict[f'step_{i}'] = float(weight)
                        
                        predictions[model_name] = {
                            'signal': float(output.item()),
                            'confidence': self._calculate_confidence(output, model_name),
                            'attention_weights': attn_weights_dict,
                            'model_type': 'LSTM'
                        }
                        
                    elif model_name == 'transformer':
                        output = model(sequence_data)
                        
                        predictions[model_name] = {
                            'signal': float(output.item()),
                            'confidence': self._calculate_confidence(output, model_name),
                            'attention_weights': {},
                            'model_type': 'Transformer'
                        }
                
            except Exception as e:
                logger.warning(f"æ¨¡å‹ {model_name} é¢„æµ‹å¤±è´¥: {e}")
                predictions[model_name] = {
                    'signal': 0.0,
                    'confidence': 0.1,
                    'attention_weights': {},
                    'model_type': model_name
                }
        
        return predictions
    
    def _calculate_confidence(self, output: torch.Tensor, model_name: str) -> float:
        """è®¡ç®—ç½®ä¿¡åº¦"""
        try:
            # åŸºäºè¾“å‡ºå€¼çš„ç½®ä¿¡åº¦
            signal_strength = abs(output.item())
            
            # åŸºäºæ¨¡å‹å†å²æ€§èƒ½çš„ç½®ä¿¡åº¦
            base_confidence = 0.7  # åŸºç¡€ç½®ä¿¡åº¦
            
            # ç»¼åˆç½®ä¿¡åº¦
            confidence = base_confidence * (0.5 + signal_strength * 0.5)
            
            return np.clip(confidence, 0.1, 1.0)
            
        except Exception as e:
            logger.error(f"è®¡ç®—ç½®ä¿¡åº¦å¤±è´¥: {e}")
            return 0.5
    
    def _ensemble_predictions(self, predictions: Dict[str, Dict]) -> TimeSeriesPrediction:
        """èåˆé¢„æµ‹ç»“æœ"""
        try:
            if not predictions:
                return self._get_default_prediction(time.time())
            
            # è®¡ç®—åŠ æƒå¹³å‡
            weighted_signals = []
            weighted_confidences = []
            total_weight = 0.0
            
            # æ¨¡å‹æƒé‡
            model_weights = {
                'lstm': 0.6,
                'transformer': 0.4
            }
            
            combined_attention = {}
            model_types = []
            
            for model_name, pred in predictions.items():
                weight = model_weights.get(model_name, 0.5)
                confidence = pred['confidence']
                
                # åŸºäºç½®ä¿¡åº¦è°ƒæ•´æƒé‡
                adjusted_weight = weight * confidence
                
                weighted_signals.append(pred['signal'] * adjusted_weight)
                weighted_confidences.append(confidence * adjusted_weight)
                total_weight += adjusted_weight
                
                # åˆå¹¶æ³¨æ„åŠ›æƒé‡
                for key, value in pred['attention_weights'].items():
                    if key not in combined_attention:
                        combined_attention[key] = 0.0
                    combined_attention[key] += value * adjusted_weight
                
                model_types.append(pred['model_type'])
            
            # è®¡ç®—æœ€ç»ˆç»“æœ
            if total_weight > 0:
                final_signal = sum(weighted_signals) / total_weight
                final_confidence = sum(weighted_confidences) / total_weight
                
                # å½’ä¸€åŒ–æ³¨æ„åŠ›æƒé‡
                for key in combined_attention:
                    combined_attention[key] /= total_weight
            else:
                final_signal = 0.0
                final_confidence = 0.0
            
            # ç”Ÿæˆåºåˆ—é‡è¦æ€§
            sequence_importance = self._calculate_sequence_importance(combined_attention)
            
            # ç”Ÿæˆæ¨ç†
            reasoning = f"æ—¶åºæ·±åº¦å­¦ä¹ èåˆ: {'+'.join(model_types)}"
            
            return TimeSeriesPrediction(
                signal=np.clip(final_signal, -1.0, 1.0),
                confidence=np.clip(final_confidence, 0.0, 1.0),
                prediction_horizon=15,  # é»˜è®¤15åˆ†é’Ÿé¢„æµ‹
                attention_weights=combined_attention,
                sequence_importance=sequence_importance,
                model_type="Ensemble",
                reasoning=reasoning,
                timestamp=datetime.now(),
                execution_time_ms=0.0
            )
            
        except Exception as e:
            logger.error(f"èåˆé¢„æµ‹ç»“æœå¤±è´¥: {e}")
            return self._get_default_prediction(time.time(), str(e))
    
    def _calculate_sequence_importance(self, attention_weights: Dict[str, float]) -> List[float]:
        """è®¡ç®—åºåˆ—é‡è¦æ€§"""
        try:
            # ä»æ³¨æ„åŠ›æƒé‡è®¡ç®—åºåˆ—é‡è¦æ€§
            importance = []
            
            if attention_weights:
                # æŒ‰æ­¥éª¤æ’åº
                sorted_steps = sorted(attention_weights.items(), key=lambda x: int(x[0].split('_')[1]) if '_' in x[0] else 0)
                importance = [weight for _, weight in sorted_steps]
            
            # å¦‚æœæ²¡æœ‰æ³¨æ„åŠ›æƒé‡ï¼Œä½¿ç”¨é»˜è®¤é‡è¦æ€§
            if not importance:
                importance = [1.0 / self.sequence_length] * self.sequence_length
            
            return importance
            
        except Exception as e:
            logger.error(f"è®¡ç®—åºåˆ—é‡è¦æ€§å¤±è´¥: {e}")
            return [1.0 / self.sequence_length] * self.sequence_length
    
    def _get_default_prediction(self, start_time: float, error_msg: str = "") -> TimeSeriesPrediction:
        """è·å–é»˜è®¤é¢„æµ‹"""
        return TimeSeriesPrediction(
            signal=0.0,
            confidence=0.0,
            prediction_horizon=15,
            attention_weights={},
            sequence_importance=[],
            model_type="Default",
            reasoning=f"é»˜è®¤é¢„æµ‹{': ' + error_msg if error_msg else ''}",
            timestamp=datetime.now(),
            execution_time_ms=(time.time() - start_time) * 1000
        )
    
    def _record_prediction(self, prediction: TimeSeriesPrediction):
        """è®°å½•é¢„æµ‹å†å²"""
        with self.lock:
            self.prediction_history.append(prediction)
            
            # é™åˆ¶å†å²è®°å½•æ•°é‡
            if len(self.prediction_history) > 1000:
                self.prediction_history = self.prediction_history[-1000:]
    
    def _training_loop(self):
        """è®­ç»ƒå¾ªç¯"""
        while True:
            try:
                time.sleep(1800)  # 30åˆ†é’Ÿè®­ç»ƒä¸€æ¬¡
                if not self.is_training and len(self.feature_buffer) > self.sequence_length * 2:
                    asyncio.run(self._train_models())
            except Exception as e:
                logger.error(f"è®­ç»ƒå¾ªç¯å¤±è´¥: {e}")
    
    def _data_cleanup_loop(self):
        """æ•°æ®æ¸…ç†å¾ªç¯"""
        while True:
            try:
                time.sleep(3600)  # 1å°æ—¶æ¸…ç†ä¸€æ¬¡
                self._cleanup_old_data()
            except Exception as e:
                logger.error(f"æ•°æ®æ¸…ç†å¤±è´¥: {e}")
    
    async def _train_models(self):
        """è®­ç»ƒæ¨¡å‹"""
        if self.is_training:
            return
        
        self.is_training = True
        try:
            logger.info("å¼€å§‹è®­ç»ƒæ—¶åºæ¨¡å‹...")
            
            # å‡†å¤‡è®­ç»ƒæ•°æ®
            train_data = self._prepare_training_data()
            
            if train_data is None:
                logger.warning("è®­ç»ƒæ•°æ®ä¸è¶³")
                return
            
            # è®­ç»ƒæ¯ä¸ªæ¨¡å‹
            for model_name, model in self.models.items():
                try:
                    await self._train_single_model(model_name, model, train_data)
                except Exception as e:
                    logger.error(f"è®­ç»ƒæ¨¡å‹ {model_name} å¤±è´¥: {e}")
            
            logger.info("æ—¶åºæ¨¡å‹è®­ç»ƒå®Œæˆ")
            
        except Exception as e:
            logger.error(f"è®­ç»ƒæ¨¡å‹å¤±è´¥: {e}")
        finally:
            self.is_training = False
    
    def _prepare_training_data(self) -> Optional[Tuple[torch.Tensor, torch.Tensor]]:
        """å‡†å¤‡è®­ç»ƒæ•°æ®"""
        try:
            with self.lock:
                if len(self.feature_buffer) < self.sequence_length + 10:
                    return None
                
                # æ„å»ºåºåˆ—æ•°æ®
                sequences = []
                targets = []
                
                features_list = list(self.feature_buffer)
                
                for i in range(len(features_list) - self.sequence_length):
                    # è¾“å…¥åºåˆ—
                    seq = features_list[i:i + self.sequence_length]
                    sequences.append(seq)
                    
                    # ç›®æ ‡å€¼ï¼ˆç®€åŒ–ä¸ºä»·æ ¼å˜åŒ–æ–¹å‘ï¼‰
                    current_price = features_list[i + self.sequence_length - 1][0]  # å‡è®¾ç¬¬ä¸€ä¸ªç‰¹å¾æ˜¯ä»·æ ¼
                    future_price = features_list[i + self.sequence_length][0]
                    
                    # è®¡ç®—ä»·æ ¼å˜åŒ–ç‡
                    price_change = (future_price - current_price) / current_price if current_price != 0 else 0
                    target = np.tanh(price_change * 100)  # å½’ä¸€åŒ–åˆ°-1åˆ°1ä¹‹é—´
                    targets.append(target)
                
                if len(sequences) < 10:
                    return None
                
                # è½¬æ¢ä¸ºå¼ é‡
                X = torch.FloatTensor(sequences).to(self.device)
                y = torch.FloatTensor(targets).unsqueeze(1).to(self.device)
                
                return X, y
                
        except Exception as e:
            logger.error(f"å‡†å¤‡è®­ç»ƒæ•°æ®å¤±è´¥: {e}")
            return None
    
    async def _train_single_model(self, model_name: str, model: nn.Module, train_data: Tuple[torch.Tensor, torch.Tensor]):
        """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
        try:
            X, y = train_data
            optimizer = self.optimizers[model_name]
            criterion = nn.MSELoss()
            
            model.train()
            
            # ç®€å•çš„è®­ç»ƒå¾ªç¯
            for epoch in range(10):
                optimizer.zero_grad()
                
                if model_name == 'lstm':
                    output, _ = model(X)
                else:
                    output = model(X)
                
                loss = criterion(output, y)
                loss.backward()
                optimizer.step()
                
                if epoch % 5 == 0:
                    logger.debug(f"æ¨¡å‹ {model_name} Epoch {epoch}, Loss: {loss.item():.6f}")
            
            logger.info(f"æ¨¡å‹ {model_name} è®­ç»ƒå®Œæˆ")
            
        except Exception as e:
            logger.error(f"è®­ç»ƒå•ä¸ªæ¨¡å‹å¤±è´¥: {e}")
    
    def _cleanup_old_data(self):
        """æ¸…ç†æ—§æ•°æ®"""
        try:
            with self.lock:
                # æ¸…ç†é¢„æµ‹å†å²
                if len(self.prediction_history) > 500:
                    self.prediction_history = self.prediction_history[-500:]
            
            logger.debug("æ•°æ®æ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"æ¸…ç†æ—§æ•°æ®å¤±è´¥: {e}")
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–çŠ¶æ€ä¿¡æ¯"""
        with self.lock:
            return {
                'level': 3,
                'name': 'Time Series Deep Learning AI',
                'models_count': len(self.models),
                'sequence_length': self.sequence_length,
                'data_buffer_size': len(self.data_buffer),
                'feature_buffer_size': len(self.feature_buffer),
                'prediction_count': len(self.prediction_history),
                'is_training': self.is_training,
                'device': str(self.device),
                'prediction_horizons': self.prediction_horizons
            }


# å…¨å±€å®ä¾‹
_time_series_ai = None

def get_time_series_ai(config: Dict[str, Any] = None) -> TimeSeriesDeepLearningAI:
    """è·å–æ—¶åºæ·±åº¦å­¦ä¹ AIå®ä¾‹"""
    global _time_series_ai
    if _time_series_ai is None:
        _time_series_ai = TimeSeriesDeepLearningAI(config)
    return _time_series_ai


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    async def test_time_series_ai():
        """æµ‹è¯•æ—¶åºAI"""
        ai = get_time_series_ai()
        
        # æ¨¡æ‹Ÿå†å²æ•°æ®
        for i in range(100):
            market_data = {
                'price': 50000.0 + np.sin(i * 0.1) * 1000,
                'volume': 1000.0 + np.random.normal(0, 100),
                'indicators': {
                    'rsi': 50 + np.sin(i * 0.05) * 20,
                    'macd': np.sin(i * 0.08) * 0.5,
                    'bb_upper': 51000.0,
                    'bb_lower': 49000.0,
                    'sma_20': 50000.0,
                    'ema_12': 50000.0,
                    'ema_26': 50000.0
                },
                'timestamp': time.time() + i * 60
            }
            ai._update_data_buffer(market_data)
        
        # æ‰§è¡Œé¢„æµ‹
        prediction = await ai.predict(market_data)
        
        print(f"æ—¶åºé¢„æµ‹ç»“æœ:")
        print(f"ä¿¡å·: {prediction.signal}")
        print(f"ç½®ä¿¡åº¦: {prediction.confidence}")
        print(f"æ¨¡å‹ç±»å‹: {prediction.model_type}")
        print(f"æ¨ç†: {prediction.reasoning}")
        
        # è·å–çŠ¶æ€
        status = ai.get_status()
        print(f"\næ—¶åºAIçŠ¶æ€: {json.dumps(status, indent=2)}")
    
    # è¿è¡Œæµ‹è¯•
    asyncio.run(test_time_series_ai())
