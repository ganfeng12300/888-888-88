#!/usr/bin/env python3
"""
ğŸ§  åˆ†å±‚AIç³»ç»Ÿ - é«˜é˜¶AIæ¨¡å‹é¢†å¯¼ä½é˜¶AIæ¨¡å‹
Hierarchical AI System - High-level AI models leading low-level AI models
"""
import os
import asyncio
import json
import time
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import logging
from concurrent.futures import ThreadPoolExecutor
import threading
import queue
import sqlite3
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
import joblib
import warnings
warnings.filterwarnings('ignore')

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

@dataclass
class AIModelConfig:
    """AIæ¨¡å‹é…ç½®"""
    name: str
    level: int  # 1-6çº§ï¼Œ6çº§æœ€é«˜
    model_type: str
    features: List[str]
    target: str
    update_frequency: int  # ç§’
    confidence_threshold: float
    max_memory_mb: int
    
@dataclass
class AIDecision:
    """AIå†³ç­–"""
    model_name: str
    level: int
    action: str  # BUY, SELL, HOLD
    confidence: float
    price_target: float
    stop_loss: float
    take_profit: float
    position_size: float
    reasoning: str
    timestamp: datetime
    
@dataclass
class MarketData:
    """å¸‚åœºæ•°æ®"""
    symbol: str
    price: float
    volume: float
    timestamp: datetime
    indicators: Dict[str, float]

class HierarchicalAISystem:
    """åˆ†å±‚AIç³»ç»Ÿ"""
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        # AIæ¨¡å‹å­˜å‚¨
        self.models: Dict[str, Any] = {}
        self.scalers: Dict[str, StandardScaler] = {}
        self.model_configs: Dict[str, AIModelConfig] = {}
        
        # å†³ç­–é˜Ÿåˆ—
        self.decision_queue = queue.Queue()
        self.market_data_queue = queue.Queue()
        
        # æ•°æ®å­˜å‚¨
        self.db_path = self.data_dir / "hierarchical_ai.db"
        self.init_database()
        
        # è¿è¡ŒçŠ¶æ€
        self.running = False
        self.threads = []
        
        # åˆå§‹åŒ–AIæ¨¡å‹é…ç½®
        self.init_ai_models()
        
        logger.info("ğŸ§  åˆ†å±‚AIç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ›å»ºè¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS ai_decisions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                model_name TEXT,
                level INTEGER,
                action TEXT,
                confidence REAL,
                price_target REAL,
                stop_loss REAL,
                take_profit REAL,
                position_size REAL,
                reasoning TEXT,
                timestamp DATETIME,
                executed BOOLEAN DEFAULT FALSE
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS model_performance (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                model_name TEXT,
                level INTEGER,
                accuracy REAL,
                profit_loss REAL,
                trades_count INTEGER,
                win_rate REAL,
                timestamp DATETIME
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS market_data (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                symbol TEXT,
                price REAL,
                volume REAL,
                indicators TEXT,
                timestamp DATETIME
            )
        ''')
        
        conn.commit()
        conn.close()
    
    def init_ai_models(self):
        """åˆå§‹åŒ–AIæ¨¡å‹é…ç½®"""
        
        # 6çº§ - æˆ˜ç•¥æ€»æŒ‡æŒ¥AI (Strategic Command AI)
        self.model_configs["strategic_commander"] = AIModelConfig(
            name="strategic_commander",
            level=6,
            model_type="ensemble",
            features=["market_trend", "volatility", "volume_profile", "sentiment", "macro_indicators"],
            target="strategic_direction",
            update_frequency=3600,  # 1å°æ—¶æ›´æ–°
            confidence_threshold=0.85,
            max_memory_mb=500
        )
        
        # 5çº§ - æˆ˜æœ¯åè°ƒAI (Tactical Coordinator AI)
        self.model_configs["tactical_coordinator"] = AIModelConfig(
            name="tactical_coordinator",
            level=5,
            model_type="gradient_boosting",
            features=["price_action", "support_resistance", "trend_strength", "momentum"],
            target="tactical_signals",
            update_frequency=1800,  # 30åˆ†é’Ÿæ›´æ–°
            confidence_threshold=0.80,
            max_memory_mb=300
        )
        
        # 4çº§ - é£é™©ç®¡ç†AI (Risk Management AI)
        self.model_configs["risk_manager"] = AIModelConfig(
            name="risk_manager",
            level=4,
            model_type="neural_network",
            features=["portfolio_exposure", "volatility", "correlation", "drawdown"],
            target="risk_adjustment",
            update_frequency=900,  # 15åˆ†é’Ÿæ›´æ–°
            confidence_threshold=0.75,
            max_memory_mb=200
        )
        
        # 3çº§ - æŠ€æœ¯åˆ†æAI (Technical Analysis AI)
        self.model_configs["technical_analyst"] = AIModelConfig(
            name="technical_analyst",
            level=3,
            model_type="random_forest",
            features=["rsi", "macd", "bollinger", "stochastic", "williams_r"],
            target="technical_signals",
            update_frequency=300,  # 5åˆ†é’Ÿæ›´æ–°
            confidence_threshold=0.70,
            max_memory_mb=150
        )
        
        # 2çº§ - æ‰§è¡Œä¼˜åŒ–AI (Execution Optimizer AI)
        self.model_configs["execution_optimizer"] = AIModelConfig(
            name="execution_optimizer",
            level=2,
            model_type="gradient_boosting",
            features=["order_book", "spread", "liquidity", "slippage"],
            target="execution_timing",
            update_frequency=60,  # 1åˆ†é’Ÿæ›´æ–°
            confidence_threshold=0.65,
            max_memory_mb=100
        )
        
        # 1çº§ - å®æ—¶ç›‘æ§AI (Real-time Monitor AI)
        self.model_configs["realtime_monitor"] = AIModelConfig(
            name="realtime_monitor",
            level=1,
            model_type="neural_network",
            features=["price", "volume", "bid_ask", "tick_data"],
            target="immediate_signals",
            update_frequency=10,  # 10ç§’æ›´æ–°
            confidence_threshold=0.60,
            max_memory_mb=50
        )
    
    def create_model(self, config: AIModelConfig) -> Any:
        """åˆ›å»ºAIæ¨¡å‹"""
        if config.model_type == "random_forest":
            return RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
        elif config.model_type == "gradient_boosting":
            return GradientBoostingRegressor(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=6,
                random_state=42
            )
        elif config.model_type == "neural_network":
            return MLPRegressor(
                hidden_layer_sizes=(100, 50),
                activation='relu',
                solver='adam',
                max_iter=500,
                random_state=42
            )
        elif config.model_type == "ensemble":
            # é›†æˆæ¨¡å‹
            return {
                'rf': RandomForestRegressor(n_estimators=50, random_state=42),
                'gb': GradientBoostingRegressor(n_estimators=50, random_state=42),
                'nn': MLPRegressor(hidden_layer_sizes=(50,), max_iter=300, random_state=42)
            }
        else:
            raise ValueError(f"æœªçŸ¥æ¨¡å‹ç±»å‹: {config.model_type}")
    
    def train_model(self, model_name: str, X: np.ndarray, y: np.ndarray):
        """è®­ç»ƒAIæ¨¡å‹"""
        config = self.model_configs[model_name]
        
        # æ•°æ®é¢„å¤„ç†
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)
        self.scalers[model_name] = scaler
        
        # åˆ›å»ºå¹¶è®­ç»ƒæ¨¡å‹
        model = self.create_model(config)
        
        if config.model_type == "ensemble":
            # è®­ç»ƒé›†æˆæ¨¡å‹
            for sub_model_name, sub_model in model.items():
                sub_model.fit(X_scaled, y)
        else:
            model.fit(X_scaled, y)
        
        self.models[model_name] = model
        
        # ä¿å­˜æ¨¡å‹
        model_path = self.data_dir / f"{model_name}_model.joblib"
        scaler_path = self.data_dir / f"{model_name}_scaler.joblib"
        
        joblib.dump(model, model_path)
        joblib.dump(scaler, scaler_path)
        
        logger.info(f"âœ… AIæ¨¡å‹ {model_name} (Level {config.level}) è®­ç»ƒå®Œæˆ")
    
    def predict(self, model_name: str, X: np.ndarray) -> Tuple[float, float]:
        """AIæ¨¡å‹é¢„æµ‹"""
        if model_name not in self.models:
            return 0.0, 0.0
        
        config = self.model_configs[model_name]
        model = self.models[model_name]
        scaler = self.scalers[model_name]
        
        # æ•°æ®é¢„å¤„ç†
        X_scaled = scaler.transform(X.reshape(1, -1))
        
        if config.model_type == "ensemble":
            # é›†æˆé¢„æµ‹
            predictions = []
            for sub_model in model.values():
                pred = sub_model.predict(X_scaled)[0]
                predictions.append(pred)
            
            prediction = np.mean(predictions)
            confidence = 1.0 - np.std(predictions) / np.mean(np.abs(predictions)) if np.mean(np.abs(predictions)) > 0 else 0.5
        else:
            prediction = model.predict(X_scaled)[0]
            confidence = min(abs(prediction) / 100.0, 1.0)  # ç®€åŒ–çš„ç½®ä¿¡åº¦è®¡ç®—
        
        return prediction, confidence
    
    def make_decision(self, model_name: str, market_data: MarketData) -> Optional[AIDecision]:
        """AIå†³ç­–åˆ¶å®š"""
        config = self.model_configs[model_name]
        
        # å‡†å¤‡ç‰¹å¾æ•°æ®
        features = self.extract_features(market_data, config.features)
        if features is None:
            return None
        
        # AIé¢„æµ‹
        prediction, confidence = self.predict(model_name, features)
        
        # ç½®ä¿¡åº¦æ£€æŸ¥
        if confidence < config.confidence_threshold:
            return None
        
        # å†³ç­–é€»è¾‘
        if prediction > 0.1:
            action = "BUY"
            price_target = market_data.price * (1 + prediction / 100)
            stop_loss = market_data.price * 0.98
            take_profit = market_data.price * 1.05
        elif prediction < -0.1:
            action = "SELL"
            price_target = market_data.price * (1 + prediction / 100)
            stop_loss = market_data.price * 1.02
            take_profit = market_data.price * 0.95
        else:
            action = "HOLD"
            price_target = market_data.price
            stop_loss = market_data.price
            take_profit = market_data.price
        
        # ä½ç½®å¤§å°è®¡ç®—ï¼ˆåŸºäºçº§åˆ«å’Œç½®ä¿¡åº¦ï¼‰
        base_size = 0.1  # åŸºç¡€ä»“ä½10%
        level_multiplier = config.level / 6.0  # çº§åˆ«æƒé‡
        position_size = base_size * level_multiplier * confidence
        
        decision = AIDecision(
            model_name=model_name,
            level=config.level,
            action=action,
            confidence=confidence,
            price_target=price_target,
            stop_loss=stop_loss,
            take_profit=take_profit,
            position_size=position_size,
            reasoning=f"Level {config.level} AIé¢„æµ‹: {prediction:.4f}, ç½®ä¿¡åº¦: {confidence:.4f}",
            timestamp=datetime.now()
        )
        
        return decision
    
    def extract_features(self, market_data: MarketData, feature_names: List[str]) -> Optional[np.ndarray]:
        """æå–ç‰¹å¾"""
        features = []
        
        for feature_name in feature_names:
            if feature_name == "price":
                features.append(market_data.price)
            elif feature_name == "volume":
                features.append(market_data.volume)
            elif feature_name in market_data.indicators:
                features.append(market_data.indicators[feature_name])
            else:
                # é»˜è®¤å€¼
                features.append(0.0)
        
        return np.array(features) if features else None
    
    def hierarchical_decision_making(self, market_data: MarketData) -> List[AIDecision]:
        """åˆ†å±‚å†³ç­–åˆ¶å®š"""
        decisions = []
        
        # æŒ‰çº§åˆ«ä»é«˜åˆ°ä½è¿›è¡Œå†³ç­–
        for level in range(6, 0, -1):
            for model_name, config in self.model_configs.items():
                if config.level == level:
                    decision = self.make_decision(model_name, market_data)
                    if decision:
                        decisions.append(decision)
                        
                        # é«˜çº§åˆ«å†³ç­–å½±å“ä½çº§åˆ«
                        if level >= 4:  # 4çº§ä»¥ä¸Šçš„å†³ç­–ä¼šå½±å“ä¸‹çº§
                            self.influence_lower_levels(decision)
        
        return decisions
    
    def influence_lower_levels(self, high_level_decision: AIDecision):
        """é«˜çº§åˆ«å†³ç­–å½±å“ä½çº§åˆ«"""
        # é«˜çº§åˆ«çš„å†³ç­–ä¼šè°ƒæ•´ä½çº§åˆ«æ¨¡å‹çš„å‚æ•°
        influence_factor = high_level_decision.confidence * (high_level_decision.level / 6.0)
        
        for model_name, config in self.model_configs.items():
            if config.level < high_level_decision.level:
                # è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼
                if high_level_decision.action in ["BUY", "SELL"]:
                    config.confidence_threshold *= (1 - influence_factor * 0.1)
                else:
                    config.confidence_threshold *= (1 + influence_factor * 0.1)
                
                # ç¡®ä¿é˜ˆå€¼åœ¨åˆç†èŒƒå›´å†…
                config.confidence_threshold = max(0.5, min(0.9, config.confidence_threshold))
    
    def save_decision(self, decision: AIDecision):
        """ä¿å­˜å†³ç­–åˆ°æ•°æ®åº“"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO ai_decisions 
            (model_name, level, action, confidence, price_target, stop_loss, take_profit, 
             position_size, reasoning, timestamp)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            decision.model_name, decision.level, decision.action, decision.confidence,
            decision.price_target, decision.stop_loss, decision.take_profit,
            decision.position_size, decision.reasoning, decision.timestamp
        ))
        
        conn.commit()
        conn.close()
    
    def get_consensus_decision(self, decisions: List[AIDecision]) -> Optional[AIDecision]:
        """è·å–å…±è¯†å†³ç­–"""
        if not decisions:
            return None
        
        # æŒ‰çº§åˆ«æƒé‡è®¡ç®—
        total_weight = 0
        weighted_actions = {"BUY": 0, "SELL": 0, "HOLD": 0}
        
        for decision in decisions:
            weight = decision.level * decision.confidence
            total_weight += weight
            weighted_actions[decision.action] += weight
        
        # æ‰¾å‡ºæƒé‡æœ€é«˜çš„è¡ŒåŠ¨
        best_action = max(weighted_actions, key=weighted_actions.get)
        
        if total_weight == 0:
            return None
        
        # è®¡ç®—å¹³å‡å€¼
        avg_confidence = sum(d.confidence * d.level for d in decisions) / total_weight
        avg_price_target = sum(d.price_target * d.level * d.confidence for d in decisions) / total_weight
        avg_position_size = sum(d.position_size * d.level * d.confidence for d in decisions) / total_weight
        
        # åˆ›å»ºå…±è¯†å†³ç­–
        consensus = AIDecision(
            model_name="consensus",
            level=6,  # æœ€é«˜çº§åˆ«
            action=best_action,
            confidence=avg_confidence,
            price_target=avg_price_target,
            stop_loss=min(d.stop_loss for d in decisions if d.action == best_action),
            take_profit=max(d.take_profit for d in decisions if d.action == best_action),
            position_size=avg_position_size,
            reasoning=f"å…±è¯†å†³ç­–åŸºäº{len(decisions)}ä¸ªAIæ¨¡å‹",
            timestamp=datetime.now()
        )
        
        return consensus
    
    def cleanup_old_data(self, days_to_keep: int = 30):
        """æ¸…ç†æ—§æ•°æ®"""
        cutoff_date = datetime.now() - timedelta(days=days_to_keep)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # åˆ é™¤æ—§çš„å†³ç­–è®°å½•
        cursor.execute('DELETE FROM ai_decisions WHERE timestamp < ?', (cutoff_date,))
        cursor.execute('DELETE FROM model_performance WHERE timestamp < ?', (cutoff_date,))
        cursor.execute('DELETE FROM market_data WHERE timestamp < ?', (cutoff_date,))
        
        deleted_count = cursor.rowcount
        conn.commit()
        conn.close()
        
        logger.info(f"ğŸ—‘ï¸ æ¸…ç†äº† {deleted_count} æ¡æ—§æ•°æ®è®°å½•")
    
    async def start(self):
        """å¯åŠ¨åˆ†å±‚AIç³»ç»Ÿ"""
        self.running = True
        logger.info("ğŸš€ åˆ†å±‚AIç³»ç»Ÿå¯åŠ¨")
        
        # å¯åŠ¨å„ä¸ªçº¿ç¨‹
        self.threads = [
            threading.Thread(target=self.data_processing_loop, daemon=True),
            threading.Thread(target=self.decision_making_loop, daemon=True),
            threading.Thread(target=self.cleanup_loop, daemon=True)
        ]
        
        for thread in self.threads:
            thread.start()
    
    def data_processing_loop(self):
        """æ•°æ®å¤„ç†å¾ªç¯"""
        while self.running:
            try:
                # å¤„ç†å¸‚åœºæ•°æ®
                if not self.market_data_queue.empty():
                    market_data = self.market_data_queue.get()
                    
                    # ä¿å­˜å¸‚åœºæ•°æ®
                    conn = sqlite3.connect(self.db_path)
                    cursor = conn.cursor()
                    cursor.execute('''
                        INSERT INTO market_data (symbol, price, volume, indicators, timestamp)
                        VALUES (?, ?, ?, ?, ?)
                    ''', (
                        market_data.symbol, market_data.price, market_data.volume,
                        json.dumps(market_data.indicators), market_data.timestamp
                    ))
                    conn.commit()
                    conn.close()
                
                time.sleep(1)
            except Exception as e:
                logger.error(f"æ•°æ®å¤„ç†é”™è¯¯: {e}")
    
    def decision_making_loop(self):
        """å†³ç­–åˆ¶å®šå¾ªç¯"""
        while self.running:
            try:
                # è·å–æœ€æ–°å¸‚åœºæ•°æ®
                conn = sqlite3.connect(self.db_path)
                cursor = conn.cursor()
                cursor.execute('''
                    SELECT symbol, price, volume, indicators, timestamp 
                    FROM market_data 
                    ORDER BY timestamp DESC 
                    LIMIT 1
                ''')
                row = cursor.fetchone()
                conn.close()
                
                if row:
                    market_data = MarketData(
                        symbol=row[0],
                        price=row[1],
                        volume=row[2],
                        timestamp=datetime.fromisoformat(row[4]),
                        indicators=json.loads(row[3]) if row[3] else {}
                    )
                    
                    # åˆ†å±‚å†³ç­–
                    decisions = self.hierarchical_decision_making(market_data)
                    
                    # ä¿å­˜å†³ç­–
                    for decision in decisions:
                        self.save_decision(decision)
                        self.decision_queue.put(decision)
                    
                    # è·å–å…±è¯†å†³ç­–
                    consensus = self.get_consensus_decision(decisions)
                    if consensus:
                        self.decision_queue.put(consensus)
                        logger.info(f"ğŸ¯ å…±è¯†å†³ç­–: {consensus.action} - ç½®ä¿¡åº¦: {consensus.confidence:.4f}")
                
                time.sleep(10)  # 10ç§’æ£€æŸ¥ä¸€æ¬¡
            except Exception as e:
                logger.error(f"å†³ç­–åˆ¶å®šé”™è¯¯: {e}")
    
    def cleanup_loop(self):
        """æ¸…ç†å¾ªç¯"""
        while self.running:
            try:
                # æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡
                self.cleanup_old_data()
                time.sleep(3600)
            except Exception as e:
                logger.error(f"æ¸…ç†é”™è¯¯: {e}")
    
    def stop(self):
        """åœæ­¢ç³»ç»Ÿ"""
        self.running = False
        logger.info("ğŸ›‘ åˆ†å±‚AIç³»ç»Ÿåœæ­¢")
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ç»Ÿè®¡ä¿¡æ¯
        cursor.execute('SELECT COUNT(*) FROM ai_decisions WHERE timestamp > datetime("now", "-1 day")')
        daily_decisions = cursor.fetchone()[0]
        
        cursor.execute('SELECT COUNT(*) FROM market_data WHERE timestamp > datetime("now", "-1 hour")')
        hourly_data_points = cursor.fetchone()[0]
        
        conn.close()
        
        return {
            "running": self.running,
            "models_loaded": len(self.models),
            "daily_decisions": daily_decisions,
            "hourly_data_points": hourly_data_points,
            "model_configs": {name: asdict(config) for name, config in self.model_configs.items()},
            "timestamp": datetime.now().isoformat()
        }

# å…¨å±€å®ä¾‹
hierarchical_ai = HierarchicalAISystem()

if __name__ == "__main__":
    import asyncio
    
    async def main():
        # å¯åŠ¨ç³»ç»Ÿ
        await hierarchical_ai.start()
        
        # æ¨¡æ‹Ÿå¸‚åœºæ•°æ®
        while True:
            market_data = MarketData(
                symbol="BTCUSDT",
                price=50000 + np.random.normal(0, 1000),
                volume=1000000 + np.random.normal(0, 100000),
                timestamp=datetime.now(),
                indicators={
                    "rsi": np.random.uniform(20, 80),
                    "macd": np.random.normal(0, 10),
                    "bollinger": np.random.uniform(-2, 2),
                    "volume_profile": np.random.uniform(0.5, 1.5),
                    "sentiment": np.random.uniform(-1, 1)
                }
            )
            
            hierarchical_ai.market_data_queue.put(market_data)
            await asyncio.sleep(10)
    
    asyncio.run(main())

