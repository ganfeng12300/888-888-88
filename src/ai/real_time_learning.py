"""
ğŸ¯ å®æ—¶å­¦ä¹ ä¸åŠ¨æ€ä¼˜åŒ–ç³»ç»Ÿ
ç”Ÿäº§çº§å®æ—¶å­¦ä¹ ç³»ç»Ÿï¼Œæ”¯æŒåœ¨çº¿å­¦ä¹ ã€å¢é‡è®­ç»ƒã€åŠ¨æ€å‚æ•°è°ƒæ•´
å®ç°å®Œæ•´çš„è‡ªé€‚åº”å­¦ä¹ æµç¨‹ã€æ€§èƒ½è¯„ä¼°ã€æ¨¡å‹æ›´æ–°ç­‰åŠŸèƒ½
"""
import asyncio
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import logging
from collections import deque
import json
import threading
from concurrent.futures import ThreadPoolExecutor
import pickle
import os

@dataclass
class LearningMetrics:
    """å­¦ä¹ æŒ‡æ ‡"""
    accuracy: float = 0.0
    precision: float = 0.0
    recall: float = 0.0
    f1_score: float = 0.0
    sharpe_ratio: float = 0.0
    max_drawdown: float = 0.0
    profit_factor: float = 0.0
    win_rate: float = 0.0
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class AdaptationEvent:
    """é€‚åº”äº‹ä»¶"""
    event_type: str  # 'parameter_update', 'model_retrain', 'weight_adjust'
    model_name: str
    old_value: Any
    new_value: Any
    reason: str
    impact_score: float
    timestamp: datetime = field(default_factory=datetime.now)

class RealTimeLearningEngine:
    """å®æ—¶å­¦ä¹ å¼•æ“"""
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.is_running = False
        self.executor = ThreadPoolExecutor(max_workers=4)
        
        # å­¦ä¹ å‚æ•°
        self.learning_rate = 0.001
        self.momentum = 0.9
        self.decay_rate = 0.95
        self.adaptation_threshold = 0.05
        self.min_samples_for_update = 50
        
        # æ•°æ®å­˜å‚¨
        self.training_buffer = deque(maxlen=10000)
        self.validation_buffer = deque(maxlen=2000)
        self.performance_history = deque(maxlen=5000)
        self.adaptation_history = deque(maxlen=1000)
        
        # æ¨¡å‹çŠ¶æ€
        self.model_states = {}
        self.gradient_cache = {}
        self.momentum_cache = {}
        
        # æ€§èƒ½ç›‘æ§
        self.current_metrics = LearningMetrics()
        self.baseline_metrics = LearningMetrics()
        
    async def start(self):
        """å¯åŠ¨å®æ—¶å­¦ä¹ å¼•æ“"""
        self.is_running = True
        self.logger.info("ğŸ¯ å®æ—¶å­¦ä¹ å¼•æ“å¯åŠ¨")
        
        # å¯åŠ¨å­¦ä¹ å¾ªç¯
        tasks = [
            asyncio.create_task(self._online_learning_loop()),
            asyncio.create_task(self._performance_evaluation_loop()),
            asyncio.create_task(self._adaptation_loop()),
            asyncio.create_task(self._model_optimization_loop())
        ]
        
        await asyncio.gather(*tasks)
        
    async def stop(self):
        """åœæ­¢å®æ—¶å­¦ä¹ å¼•æ“"""
        self.is_running = False
        self.executor.shutdown(wait=True)
        self.logger.info("ğŸ¯ å®æ—¶å­¦ä¹ å¼•æ“åœæ­¢")
        
    async def _online_learning_loop(self):
        """åœ¨çº¿å­¦ä¹ å¾ªç¯"""
        while self.is_running:
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ–°æ•°æ®è¿›è¡Œå­¦ä¹ 
                if len(self.training_buffer) >= self.min_samples_for_update:
                    await self._perform_incremental_learning()
                    
                await asyncio.sleep(30)  # 30ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                self.logger.error(f"åœ¨çº¿å­¦ä¹ é”™è¯¯: {e}")
                await asyncio.sleep(60)
                
    async def _perform_incremental_learning(self):
        """æ‰§è¡Œå¢é‡å­¦ä¹ """
        try:
            # è·å–æœ€æ–°çš„è®­ç»ƒæ•°æ®
            recent_data = list(self.training_buffer)[-self.min_samples_for_update:]
            
            # å‡†å¤‡è®­ç»ƒæ•°æ®
            X, y = self._prepare_learning_data(recent_data)
            
            if len(X) == 0:
                return
                
            # å¯¹æ¯ä¸ªæ¨¡å‹è¿›è¡Œå¢é‡å­¦ä¹ 
            for model_name in self.model_states.keys():
                await self._incremental_update(model_name, X, y)
                
            self.logger.info(f"å®Œæˆå¢é‡å­¦ä¹ ï¼Œæ ·æœ¬æ•°: {len(X)}")
            
        except Exception as e:
            self.logger.error(f"å¢é‡å­¦ä¹ å¤±è´¥: {e}")
            
    def _prepare_learning_data(self, data: List[Dict]) -> Tuple[np.ndarray, np.ndarray]:
        """å‡†å¤‡å­¦ä¹ æ•°æ®"""
        if not data:
            return np.array([]), np.array([])
            
        df = pd.DataFrame(data)
        
        # ç‰¹å¾åˆ—
        feature_columns = [
            'price', 'volume', 'rsi', 'macd', 'bb_upper', 'bb_lower',
            'sma_5', 'sma_20', 'price_change', 'volume_change'
        ]
        
        # è¿‡æ»¤å­˜åœ¨çš„åˆ—
        available_columns = [col for col in feature_columns if col in df.columns]
        
        if not available_columns:
            return np.array([]), np.array([])
            
        X = df[available_columns].fillna(0).values
        
        # æ ‡ç­¾ï¼ˆå®é™…æ”¶ç›Šç‡ï¼‰
        if 'actual_return' in df.columns:
            y = (df['actual_return'] > 0).astype(int).values
        else:
            # å¦‚æœæ²¡æœ‰å®é™…æ”¶ç›Šç‡ï¼Œä½¿ç”¨ä»·æ ¼å˜åŒ–
            y = (df['price'].pct_change() > 0).astype(int).values
            
        # ç§»é™¤NaNå€¼
        valid_indices = ~(np.isnan(X).any(axis=1) | np.isnan(y))
        X = X[valid_indices]
        y = y[valid_indices]
        
        return X, y
        
    async def _incremental_update(self, model_name: str, X: np.ndarray, y: np.ndarray):
        """å¢é‡æ›´æ–°æ¨¡å‹"""
        try:
            if model_name not in self.model_states:
                self._initialize_model_state(model_name, X.shape[1])
                
            # è®¡ç®—æ¢¯åº¦
            gradients = await self._compute_gradients(model_name, X, y)
            
            # æ›´æ–°æ¨¡å‹å‚æ•°
            await self._update_model_parameters(model_name, gradients)
            
            # è®°å½•æ›´æ–°äº‹ä»¶
            self._record_adaptation_event(
                'parameter_update',
                model_name,
                'gradients',
                gradients,
                f'å¢é‡å­¦ä¹ æ›´æ–°ï¼Œæ ·æœ¬æ•°: {len(X)}'
            )
            
        except Exception as e:
            self.logger.error(f"å¢é‡æ›´æ–°æ¨¡å‹ {model_name} å¤±è´¥: {e}")
            
    def _initialize_model_state(self, model_name: str, input_dim: int):
        """åˆå§‹åŒ–æ¨¡å‹çŠ¶æ€"""
        # ç®€å•çš„çº¿æ€§æ¨¡å‹å‚æ•°
        self.model_states[model_name] = {
            'weights': np.random.normal(0, 0.1, (input_dim, 1)),
            'bias': np.zeros((1,)),
            'input_dim': input_dim
        }
        
        # åˆå§‹åŒ–æ¢¯åº¦ç¼“å­˜
        self.gradient_cache[model_name] = {
            'weights': np.zeros((input_dim, 1)),
            'bias': np.zeros((1,))
        }
        
        # åˆå§‹åŒ–åŠ¨é‡ç¼“å­˜
        self.momentum_cache[model_name] = {
            'weights': np.zeros((input_dim, 1)),
            'bias': np.zeros((1,))
        }
        
    async def _compute_gradients(self, model_name: str, X: np.ndarray, y: np.ndarray) -> Dict[str, np.ndarray]:
        """è®¡ç®—æ¢¯åº¦"""
        state = self.model_states[model_name]
        weights = state['weights']
        bias = state['bias']
        
        # å‰å‘ä¼ æ’­
        z = np.dot(X, weights) + bias
        predictions = self._sigmoid(z)
        
        # è®¡ç®—æŸå¤±æ¢¯åº¦
        m = X.shape[0]
        dz = predictions - y.reshape(-1, 1)
        
        dw = (1/m) * np.dot(X.T, dz)
        db = (1/m) * np.sum(dz, axis=0)
        
        return {
            'weights': dw,
            'bias': db
        }
        
    def _sigmoid(self, z: np.ndarray) -> np.ndarray:
        """Sigmoidæ¿€æ´»å‡½æ•°"""
        return 1 / (1 + np.exp(-np.clip(z, -250, 250)))
        
    async def _update_model_parameters(self, model_name: str, gradients: Dict[str, np.ndarray]):
        """æ›´æ–°æ¨¡å‹å‚æ•°"""
        state = self.model_states[model_name]
        momentum = self.momentum_cache[model_name]
        
        # åŠ¨é‡æ›´æ–°
        momentum['weights'] = self.momentum * momentum['weights'] - self.learning_rate * gradients['weights']
        momentum['bias'] = self.momentum * momentum['bias'] - self.learning_rate * gradients['bias']
        
        # å‚æ•°æ›´æ–°
        state['weights'] += momentum['weights']
        state['bias'] += momentum['bias']
        
        # æ¢¯åº¦ç¼“å­˜æ›´æ–°
        self.gradient_cache[model_name] = gradients
        
    async def _performance_evaluation_loop(self):
        """æ€§èƒ½è¯„ä¼°å¾ªç¯"""
        while self.is_running:
            try:
                await self._evaluate_model_performance()
                await self._update_performance_metrics()
                await asyncio.sleep(60)  # 1åˆ†é’Ÿè¯„ä¼°ä¸€æ¬¡
                
            except Exception as e:
                self.logger.error(f"æ€§èƒ½è¯„ä¼°é”™è¯¯: {e}")
                await asyncio.sleep(30)
                
    async def _evaluate_model_performance(self):
        """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        if len(self.validation_buffer) < 20:
            return
            
        # è·å–éªŒè¯æ•°æ®
        validation_data = list(self.validation_buffer)[-100:]
        X_val, y_val = self._prepare_learning_data(validation_data)
        
        if len(X_val) == 0:
            return
            
        # è¯„ä¼°æ¯ä¸ªæ¨¡å‹
        for model_name, state in self.model_states.items():
            try:
                # é¢„æµ‹
                predictions = await self._predict_with_state(model_name, X_val)
                
                # è®¡ç®—æŒ‡æ ‡
                metrics = self._calculate_metrics(y_val, predictions)
                
                # æ›´æ–°æ€§èƒ½å†å²
                self.performance_history.append({
                    'model_name': model_name,
                    'timestamp': datetime.now(),
                    'metrics': metrics
                })
                
            except Exception as e:
                self.logger.error(f"è¯„ä¼°æ¨¡å‹ {model_name} æ€§èƒ½å¤±è´¥: {e}")
                
    async def _predict_with_state(self, model_name: str, X: np.ndarray) -> np.ndarray:
        """ä½¿ç”¨æ¨¡å‹çŠ¶æ€è¿›è¡Œé¢„æµ‹"""
        state = self.model_states[model_name]
        z = np.dot(X, state['weights']) + state['bias']
        predictions = self._sigmoid(z)
        return (predictions > 0.5).astype(int).flatten()
        
    def _calculate_metrics(self, y_true: np.ndarray, y_pred: np.ndarray) -> LearningMetrics:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        # åŸºæœ¬åˆ†ç±»æŒ‡æ ‡
        tp = np.sum((y_true == 1) & (y_pred == 1))
        tn = np.sum((y_true == 0) & (y_pred == 0))
        fp = np.sum((y_true == 0) & (y_pred == 1))
        fn = np.sum((y_true == 1) & (y_pred == 0))
        
        accuracy = (tp + tn) / len(y_true) if len(y_true) > 0 else 0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
        
        return LearningMetrics(
            accuracy=accuracy,
            precision=precision,
            recall=recall,
            f1_score=f1_score,
            win_rate=accuracy  # ç®€åŒ–å¤„ç†
        )
        
    async def _update_performance_metrics(self):
        """æ›´æ–°æ€§èƒ½æŒ‡æ ‡"""
        if not self.performance_history:
            return
            
        # è®¡ç®—æœ€è¿‘çš„å¹³å‡æ€§èƒ½
        recent_metrics = list(self.performance_history)[-10:]
        
        if recent_metrics:
            avg_accuracy = np.mean([m['metrics'].accuracy for m in recent_metrics])
            avg_precision = np.mean([m['metrics'].precision for m in recent_metrics])
            avg_recall = np.mean([m['metrics'].recall for m in recent_metrics])
            avg_f1 = np.mean([m['metrics'].f1_score for m in recent_metrics])
            
            self.current_metrics = LearningMetrics(
                accuracy=avg_accuracy,
                precision=avg_precision,
                recall=avg_recall,
                f1_score=avg_f1,
                timestamp=datetime.now()
            )
            
    async def _adaptation_loop(self):
        """è‡ªé€‚åº”è°ƒæ•´å¾ªç¯"""
        while self.is_running:
            try:
                await self._check_adaptation_triggers()
                await self._perform_adaptive_adjustments()
                await asyncio.sleep(120)  # 2åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                self.logger.error(f"è‡ªé€‚åº”è°ƒæ•´é”™è¯¯: {e}")
                await asyncio.sleep(60)
                
    async def _check_adaptation_triggers(self):
        """æ£€æŸ¥é€‚åº”è§¦å‘æ¡ä»¶"""
        if len(self.performance_history) < 10:
            return
            
        # æ£€æŸ¥æ€§èƒ½ä¸‹é™
        recent_performance = [m['metrics'].accuracy for m in list(self.performance_history)[-5:]]
        older_performance = [m['metrics'].accuracy for m in list(self.performance_history)[-10:-5]]
        
        if len(recent_performance) >= 3 and len(older_performance) >= 3:
            recent_avg = np.mean(recent_performance)
            older_avg = np.mean(older_performance)
            
            # å¦‚æœæ€§èƒ½ä¸‹é™è¶…è¿‡é˜ˆå€¼ï¼Œè§¦å‘é€‚åº”
            if older_avg - recent_avg > self.adaptation_threshold:
                await self._trigger_adaptation('performance_decline')
                
    async def _trigger_adaptation(self, reason: str):
        """è§¦å‘é€‚åº”è°ƒæ•´"""
        self.logger.info(f"è§¦å‘é€‚åº”è°ƒæ•´: {reason}")
        
        # è°ƒæ•´å­¦ä¹ ç‡
        if reason == 'performance_decline':
            old_lr = self.learning_rate
            self.learning_rate *= 1.1  # å¢åŠ å­¦ä¹ ç‡
            self.learning_rate = min(self.learning_rate, 0.01)  # é™åˆ¶æœ€å¤§å€¼
            
            self._record_adaptation_event(
                'parameter_update',
                'learning_engine',
                old_lr,
                self.learning_rate,
                f'æ€§èƒ½ä¸‹é™ï¼Œè°ƒæ•´å­¦ä¹ ç‡: {reason}'
            )
            
    async def _perform_adaptive_adjustments(self):
        """æ‰§è¡Œè‡ªé€‚åº”è°ƒæ•´"""
        # åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡
        if len(self.performance_history) >= 5:
            recent_metrics = list(self.performance_history)[-5:]
            accuracies = [m['metrics'].accuracy for m in recent_metrics]
            
            # å¦‚æœå‡†ç¡®ç‡æ–¹å·®å¤ªå¤§ï¼Œé™ä½å­¦ä¹ ç‡
            if np.var(accuracies) > 0.01:
                old_lr = self.learning_rate
                self.learning_rate *= 0.95
                self.learning_rate = max(self.learning_rate, 0.0001)
                
                if abs(old_lr - self.learning_rate) > 0.0001:
                    self._record_adaptation_event(
                        'parameter_update',
                        'learning_engine',
                        old_lr,
                        self.learning_rate,
                        'å‡†ç¡®ç‡æ–¹å·®è¿‡å¤§ï¼Œé™ä½å­¦ä¹ ç‡'
                    )
                    
    async def _model_optimization_loop(self):
        """æ¨¡å‹ä¼˜åŒ–å¾ªç¯"""
        while self.is_running:
            try:
                await self._optimize_model_architecture()
                await self._prune_ineffective_features()
                await asyncio.sleep(600)  # 10åˆ†é’Ÿä¼˜åŒ–ä¸€æ¬¡
                
            except Exception as e:
                self.logger.error(f"æ¨¡å‹ä¼˜åŒ–é”™è¯¯: {e}")
                await asyncio.sleep(300)
                
    async def _optimize_model_architecture(self):
        """ä¼˜åŒ–æ¨¡å‹æ¶æ„"""
        # è¿™é‡Œå¯ä»¥å®ç°æ¨¡å‹æ¶æ„ä¼˜åŒ–
        # ä¾‹å¦‚ï¼šæ·»åŠ /åˆ é™¤å±‚ã€è°ƒæ•´ç¥ç»å…ƒæ•°é‡ç­‰
        pass
        
    async def _prune_ineffective_features(self):
        """å‰ªææ— æ•ˆç‰¹å¾"""
        # è¿™é‡Œå¯ä»¥å®ç°ç‰¹å¾é€‰æ‹©å’Œå‰ªæ
        # åŸºäºç‰¹å¾é‡è¦æ€§åˆ†æ
        pass
        
    def _record_adaptation_event(self, event_type: str, model_name: str, 
                                old_value: Any, new_value: Any, reason: str):
        """è®°å½•é€‚åº”äº‹ä»¶"""
        event = AdaptationEvent(
            event_type=event_type,
            model_name=model_name,
            old_value=old_value,
            new_value=new_value,
            reason=reason,
            impact_score=0.0  # å¯ä»¥åç»­è®¡ç®—å½±å“åˆ†æ•°
        )
        
        self.adaptation_history.append(event)
        self.logger.info(f"é€‚åº”äº‹ä»¶: {event_type} - {model_name} - {reason}")
        
    async def add_training_sample(self, sample: Dict):
        """æ·»åŠ è®­ç»ƒæ ·æœ¬"""
        self.training_buffer.append(sample)
        
    async def add_validation_sample(self, sample: Dict):
        """æ·»åŠ éªŒè¯æ ·æœ¬"""
        self.validation_buffer.append(sample)
        
    def get_learning_status(self) -> Dict[str, Any]:
        """è·å–å­¦ä¹ çŠ¶æ€"""
        return {
            'is_running': self.is_running,
            'learning_rate': self.learning_rate,
            'momentum': self.momentum,
            'training_samples': len(self.training_buffer),
            'validation_samples': len(self.validation_buffer),
            'current_metrics': {
                'accuracy': self.current_metrics.accuracy,
                'precision': self.current_metrics.precision,
                'recall': self.current_metrics.recall,
                'f1_score': self.current_metrics.f1_score
            },
            'model_count': len(self.model_states),
            'adaptation_events': len(self.adaptation_history)
        }
        
    def get_recent_adaptations(self, limit: int = 10) -> List[Dict]:
        """è·å–æœ€è¿‘çš„é€‚åº”äº‹ä»¶"""
        events = list(self.adaptation_history)[-limit:]
        return [
            {
                'event_type': e.event_type,
                'model_name': e.model_name,
                'reason': e.reason,
                'timestamp': e.timestamp.isoformat(),
                'impact_score': e.impact_score
            }
            for e in events
        ]
        
    async def reset_learning_state(self):
        """é‡ç½®å­¦ä¹ çŠ¶æ€"""
        self.model_states.clear()
        self.gradient_cache.clear()
        self.momentum_cache.clear()
        self.training_buffer.clear()
        self.validation_buffer.clear()
        self.logger.info("å­¦ä¹ çŠ¶æ€å·²é‡ç½®")
        
    async def save_learning_state(self, filepath: str):
        """ä¿å­˜å­¦ä¹ çŠ¶æ€"""
        try:
            state = {
                'model_states': self.model_states,
                'learning_rate': self.learning_rate,
                'momentum': self.momentum,
                'current_metrics': self.current_metrics,
                'timestamp': datetime.now().isoformat()
            }
            
            with open(filepath, 'wb') as f:
                pickle.dump(state, f)
                
            self.logger.info(f"å­¦ä¹ çŠ¶æ€å·²ä¿å­˜åˆ°: {filepath}")
            
        except Exception as e:
            self.logger.error(f"ä¿å­˜å­¦ä¹ çŠ¶æ€å¤±è´¥: {e}")
            
    async def load_learning_state(self, filepath: str):
        """åŠ è½½å­¦ä¹ çŠ¶æ€"""
        try:
            if not os.path.exists(filepath):
                self.logger.warning(f"å­¦ä¹ çŠ¶æ€æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
                return
                
            with open(filepath, 'rb') as f:
                state = pickle.load(f)
                
            self.model_states = state.get('model_states', {})
            self.learning_rate = state.get('learning_rate', 0.001)
            self.momentum = state.get('momentum', 0.9)
            self.current_metrics = state.get('current_metrics', LearningMetrics())
            
            self.logger.info(f"å­¦ä¹ çŠ¶æ€å·²ä» {filepath} åŠ è½½")
            
        except Exception as e:
            self.logger.error(f"åŠ è½½å­¦ä¹ çŠ¶æ€å¤±è´¥: {e}")

