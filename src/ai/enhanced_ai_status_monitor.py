#!/usr/bin/env python3
"""
ğŸ¤– å¢å¼ºç‰ˆAIæ¨¡å‹çŠ¶æ€ç›‘æ§å™¨
ç›‘æ§æ‰€æœ‰145ä¸ªAIæ¨¡å‹çš„å·¥ä½œçŠ¶æ€ã€é¢„æµ‹æ€§èƒ½ã€ä¿¡å·è´¨é‡
"""

import asyncio
import time
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, field
from enum import Enum
import json
import sqlite3
from pathlib import Path
from loguru import logger
import random
import numpy as np


class AIModelStatus(Enum):
    """AIæ¨¡å‹çŠ¶æ€"""
    INACTIVE = "inactive"
    LOADING = "loading"
    ACTIVE = "active"
    PREDICTING = "predicting"
    TRAINING = "training"
    ERROR = "error"
    STANDBY = "standby"


class AIModelCategory(Enum):
    """AIæ¨¡å‹ç±»åˆ«"""
    DEEP_LEARNING = "æ·±åº¦å­¦ä¹ æ¨¡å‹"
    MACHINE_LEARNING = "æœºå™¨å­¦ä¹ æ¨¡å‹"
    AI_ENGINE = "AIå¼•æ“"
    AI_TRADER = "äº¤æ˜“AI"
    AI_PREDICTOR = "AIé¢„æµ‹å™¨"
    AI_MONITOR = "AIç›‘æ§"
    AI_COMPONENT = "AIç»„ä»¶"


@dataclass
class EnhancedModelPerformance:
    """å¢å¼ºç‰ˆæ¨¡å‹æ€§èƒ½æŒ‡æ ‡"""
    model_name: str
    category: str
    accuracy: float
    precision: float
    recall: float
    f1_score: float
    prediction_count: int
    success_rate: float
    avg_confidence: float
    last_prediction_time: datetime
    training_time: Optional[datetime] = None
    status: AIModelStatus = AIModelStatus.ACTIVE
    specialization: List[str] = field(default_factory=list)
    resource_usage: Dict[str, float] = field(default_factory=dict)


@dataclass
class AISystemStatus:
    """AIç³»ç»ŸçŠ¶æ€"""
    status: AIModelStatus
    active_models: List[str]
    total_models: int
    models_by_category: Dict[str, int]
    prediction_engine_status: str
    last_update: datetime
    uptime_seconds: float
    models_performance: Dict[str, EnhancedModelPerformance] = field(default_factory=dict)
    signal_stats: Optional[Dict] = None


class EnhancedAIStatusMonitor:
    """å¢å¼ºç‰ˆAIçŠ¶æ€ç›‘æ§å™¨"""
    
    def __init__(self, db_path: str = "data/enhanced_ai_monitor.db"):
        self.db_path = db_path
        self.monitoring = False
        self.monitor_thread: Optional[threading.Thread] = None
        
        # åŠ è½½å‘ç°çš„AIæ¨¡å‹
        self.discovered_models = self._load_discovered_models()
        
        # çŠ¶æ€æ•°æ®
        self.system_status = AISystemStatus(
            status=AIModelStatus.INACTIVE,
            active_models=[],
            total_models=len(self.discovered_models),
            models_by_category={},
            prediction_engine_status="inactive",
            last_update=datetime.now(),
            uptime_seconds=0.0
        )
        
        # ç»Ÿè®¡æ•°æ®
        self.start_time = datetime.now()
        
        self.init_database()
        logger.info(f"ğŸ¤– å¢å¼ºç‰ˆAIçŠ¶æ€ç›‘æ§å™¨åˆå§‹åŒ–å®Œæˆï¼Œå‘ç° {len(self.discovered_models)} ä¸ªAIæ¨¡å‹")
    
    def _load_discovered_models(self) -> Dict[str, Any]:
        """åŠ è½½å‘ç°çš„AIæ¨¡å‹"""
        try:
            with open("ai_models_discovery_report.json", "r", encoding="utf-8") as f:
                report = json.load(f)
            
            # åˆå¹¶æ‰€æœ‰ç±»åˆ«çš„æ¨¡å‹
            all_models = {}
            for category_name, models in report["categories"].items():
                for model_name, model_info in models.items():
                    all_models[model_name] = {
                        **model_info,
                        "category_name": category_name
                    }
            
            logger.info(f"âœ… æˆåŠŸåŠ è½½ {len(all_models)} ä¸ªAIæ¨¡å‹é…ç½®")
            return all_models
            
        except FileNotFoundError:
            logger.warning("âš ï¸ AIæ¨¡å‹å‘ç°æŠ¥å‘Šæœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹é…ç½®")
            return self._get_default_models()
    
    def _get_default_models(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤AIæ¨¡å‹é…ç½®"""
        return {
            "LSTM": {
                "name": "LSTM",
                "category": "æ·±åº¦å­¦ä¹ æ¨¡å‹",
                "functionality": ["é¢„æµ‹", "è®­ç»ƒ"],
                "description": "é•¿çŸ­æœŸè®°å¿†ç½‘ç»œæ¨¡å‹"
            },
            "Transformer": {
                "name": "Transformer",
                "category": "æ·±åº¦å­¦ä¹ æ¨¡å‹", 
                "functionality": ["é¢„æµ‹", "è®­ç»ƒ"],
                "description": "Transformeræ³¨æ„åŠ›æœºåˆ¶æ¨¡å‹"
            },
            "CNN": {
                "name": "CNN",
                "category": "æ·±åº¦å­¦ä¹ æ¨¡å‹",
                "functionality": ["é¢„æµ‹", "è®­ç»ƒ"],
                "description": "å·ç§¯ç¥ç»ç½‘ç»œæ¨¡å‹"
            }
        }
    
    def init_database(self) -> None:
        """åˆå§‹åŒ–æ•°æ®åº“"""
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # å¢å¼ºç‰ˆæ¨¡å‹æ€§èƒ½è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS enhanced_model_performance (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                model_name TEXT NOT NULL,
                category TEXT NOT NULL,
                accuracy REAL NOT NULL,
                precision REAL NOT NULL,
                recall REAL NOT NULL,
                f1_score REAL NOT NULL,
                prediction_count INTEGER NOT NULL,
                success_rate REAL NOT NULL,
                avg_confidence REAL NOT NULL,
                status TEXT NOT NULL,
                specialization TEXT,
                resource_usage TEXT,
                last_prediction_time INTEGER NOT NULL,
                training_time INTEGER,
                timestamp INTEGER NOT NULL
            )
        """)
        
        # AIä¿¡å·è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS ai_signals_enhanced (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                model_name TEXT NOT NULL,
                symbol TEXT NOT NULL,
                signal_type TEXT NOT NULL,
                confidence REAL NOT NULL,
                predicted_price REAL,
                actual_price REAL,
                success INTEGER,
                category TEXT NOT NULL,
                timestamp INTEGER NOT NULL
            )
        """)
        
        # ç³»ç»ŸçŠ¶æ€è¡¨
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS system_status_enhanced (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                status TEXT NOT NULL,
                active_models TEXT NOT NULL,
                total_models INTEGER NOT NULL,
                models_by_category TEXT NOT NULL,
                prediction_engine_status TEXT NOT NULL,
                uptime_seconds REAL NOT NULL,
                timestamp INTEGER NOT NULL
            )
        """)
        
        conn.commit()
        conn.close()
    
    def start_monitoring(self) -> None:
        """å¼€å§‹ç›‘æ§"""
        if self.monitoring:
            logger.warning("âš ï¸ AIç›‘æ§å·²åœ¨è¿è¡Œ")
            return
        
        self.monitoring = True
        self.start_time = datetime.now()
        
        # åˆå§‹åŒ–æ‰€æœ‰AIæ¨¡å‹
        self._initialize_all_ai_models()
        
        # å¯åŠ¨ç›‘æ§çº¿ç¨‹
        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)
        self.monitor_thread.start()
        
        logger.info("ğŸš€ å¢å¼ºç‰ˆAIçŠ¶æ€ç›‘æ§å·²å¯åŠ¨")
    
    def stop_monitoring(self) -> None:
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join(timeout=5)
        logger.info("â¹ï¸ å¢å¼ºç‰ˆAIçŠ¶æ€ç›‘æ§å·²åœæ­¢")
    
    def _initialize_all_ai_models(self) -> None:
        """åˆå§‹åŒ–æ‰€æœ‰AIæ¨¡å‹"""
        try:
            logger.info(f"ğŸ”§ åˆå§‹åŒ– {len(self.discovered_models)} ä¸ªAIæ¨¡å‹...")
            
            # æŒ‰ç±»åˆ«ç»Ÿè®¡
            category_counts = {}
            active_models = []
            
            for model_name, model_info in self.discovered_models.items():
                category = model_info.get("category", "AIç»„ä»¶")
                category_counts[category] = category_counts.get(category, 0) + 1
                
                # åˆ›å»ºæ¨¡å‹æ€§èƒ½å¯¹è±¡
                performance = self._create_model_performance(model_name, model_info)
                self.system_status.models_performance[model_name] = performance
                
                # éšæœºæ¿€æ´»ä¸€äº›æ¨¡å‹ï¼ˆæ¨¡æ‹ŸçœŸå®æƒ…å†µï¼‰
                if random.random() > 0.3:  # 70%çš„æ¨¡å‹å¤„äºæ´»è·ƒçŠ¶æ€
                    active_models.append(model_name)
                    performance.status = AIModelStatus.ACTIVE
                else:
                    performance.status = AIModelStatus.STANDBY
            
            # æ›´æ–°ç³»ç»ŸçŠ¶æ€
            self.system_status.status = AIModelStatus.ACTIVE
            self.system_status.active_models = active_models
            self.system_status.models_by_category = category_counts
            self.system_status.prediction_engine_status = "active"
            
            logger.info(f"âœ… AIæ¨¡å‹åˆå§‹åŒ–å®Œæˆï¼Œ{len(active_models)} ä¸ªæ¨¡å‹å¤„äºæ´»è·ƒçŠ¶æ€")
            
        except Exception as e:
            logger.error(f"âŒ AIæ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self.system_status.status = AIModelStatus.ERROR
    
    def _create_model_performance(self, model_name: str, model_info: Dict) -> EnhancedModelPerformance:
        """åˆ›å»ºæ¨¡å‹æ€§èƒ½å¯¹è±¡"""
        category = model_info.get("category", "AIç»„ä»¶")
        functionality = model_info.get("functionality", [])
        
        # ç”Ÿæˆæ¨¡æ‹Ÿæ€§èƒ½æ•°æ®ï¼ˆåŸºäºæ¨¡å‹åç§°çš„å“ˆå¸Œå€¼ï¼Œä¿è¯ä¸€è‡´æ€§ï¼‰
        seed = hash(model_name) % 1000
        np.random.seed(seed)
        
        # æ ¹æ®ç±»åˆ«è°ƒæ•´æ€§èƒ½åŸºå‡†
        base_accuracy = 0.75
        if "æ·±åº¦å­¦ä¹ " in category:
            base_accuracy = 0.85
        elif "æœºå™¨å­¦ä¹ " in category:
            base_accuracy = 0.80
        elif "å¼•æ“" in category:
            base_accuracy = 0.90
        
        performance = EnhancedModelPerformance(
            model_name=model_name,
            category=category,
            accuracy=min(0.99, base_accuracy + np.random.normal(0, 0.1)),
            precision=min(0.99, base_accuracy + np.random.normal(0, 0.08)),
            recall=min(0.99, base_accuracy + np.random.normal(0, 0.08)),
            f1_score=min(0.99, base_accuracy + np.random.normal(0, 0.08)),
            prediction_count=int(100 + np.random.exponential(200)),
            success_rate=min(0.99, base_accuracy + np.random.normal(0, 0.12)),
            avg_confidence=min(0.99, 0.6 + np.random.normal(0, 0.15)),
            last_prediction_time=datetime.now() - timedelta(minutes=np.random.randint(1, 120)),
            training_time=datetime.now() - timedelta(hours=np.random.randint(1, 48)),
            specialization=functionality,
            resource_usage={
                "cpu_usage": np.random.uniform(0.1, 0.8),
                "memory_usage": np.random.uniform(0.2, 0.9),
                "gpu_usage": np.random.uniform(0.0, 0.7) if "æ·±åº¦å­¦ä¹ " in category else 0.0
            }
        )
        
        return performance
    
    def _monitor_loop(self) -> None:
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring:
            try:
                # æ›´æ–°ç³»ç»ŸçŠ¶æ€
                self._update_system_status()
                
                # æ›´æ–°æ¨¡å‹æ€§èƒ½
                self._update_all_models_performance()
                
                # æ›´æ–°ä¿¡å·ç»Ÿè®¡
                self._update_signal_stats()
                
                # ä¿å­˜çŠ¶æ€åˆ°æ•°æ®åº“
                self._save_status()
                
                time.sleep(30)  # 30ç§’æ›´æ–°é—´éš”
                
            except Exception as e:
                logger.error(f"âŒ AIç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")
                time.sleep(30)
    
    def _update_system_status(self) -> None:
        """æ›´æ–°ç³»ç»ŸçŠ¶æ€"""
        try:
            # è®¡ç®—è¿è¡Œæ—¶é—´
            uptime = (datetime.now() - self.start_time).total_seconds()
            
            # ç»Ÿè®¡æ´»è·ƒæ¨¡å‹
            active_models = [
                name for name, perf in self.system_status.models_performance.items()
                if perf.status == AIModelStatus.ACTIVE
            ]
            
            # æ›´æ–°çŠ¶æ€
            self.system_status.active_models = active_models
            self.system_status.last_update = datetime.now()
            self.system_status.uptime_seconds = uptime
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            self.system_status.status = AIModelStatus.ERROR
    
    def _update_all_models_performance(self) -> None:
        """æ›´æ–°æ‰€æœ‰æ¨¡å‹æ€§èƒ½"""
        try:
            for model_name, performance in self.system_status.models_performance.items():
                if performance.status == AIModelStatus.ACTIVE:
                    # æ¨¡æ‹Ÿæ€§èƒ½æ³¢åŠ¨
                    seed = int(time.time()) + hash(model_name)
                    np.random.seed(seed % 1000)
                    
                    # å°å¹…åº¦æ›´æ–°æ€§èƒ½æŒ‡æ ‡
                    performance.accuracy = max(0.5, min(0.99, 
                        performance.accuracy + np.random.normal(0, 0.01)))
                    performance.avg_confidence = max(0.3, min(0.99,
                        performance.avg_confidence + np.random.normal(0, 0.02)))
                    performance.success_rate = max(0.4, min(0.99,
                        performance.success_rate + np.random.normal(0, 0.015)))
                    
                    # æ›´æ–°é¢„æµ‹è®¡æ•°
                    if np.random.random() > 0.7:  # 30%æ¦‚ç‡å¢åŠ é¢„æµ‹è®¡æ•°
                        performance.prediction_count += np.random.randint(1, 5)
                        performance.last_prediction_time = datetime.now()
                    
                    # æ›´æ–°èµ„æºä½¿ç”¨
                    performance.resource_usage["cpu_usage"] = max(0.1, min(0.9,
                        performance.resource_usage["cpu_usage"] + np.random.normal(0, 0.05)))
                    performance.resource_usage["memory_usage"] = max(0.1, min(0.9,
                        performance.resource_usage["memory_usage"] + np.random.normal(0, 0.03)))
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°æ¨¡å‹æ€§èƒ½å¤±è´¥: {e}")
    
    def _update_signal_stats(self) -> None:
        """æ›´æ–°ä¿¡å·ç»Ÿè®¡"""
        try:
            # ç»Ÿè®¡æ‰€æœ‰æ´»è·ƒæ¨¡å‹çš„ä¿¡å·
            active_models = [
                perf for perf in self.system_status.models_performance.values()
                if perf.status == AIModelStatus.ACTIVE
            ]
            
            total_signals = sum(perf.prediction_count for perf in active_models)
            total_successful = sum(int(perf.prediction_count * perf.success_rate) for perf in active_models)
            avg_confidence = np.mean([perf.avg_confidence for perf in active_models]) if active_models else 0.0
            
            # æ¨¡æ‹Ÿä¿¡å·åˆ†å¸ƒ
            buy_signals = int(total_signals * 0.35)
            sell_signals = int(total_signals * 0.30)
            hold_signals = total_signals - buy_signals - sell_signals
            high_confidence_signals = int(total_signals * 0.6)
            
            signal_stats = {
                "total_signals": total_signals,
                "buy_signals": buy_signals,
                "sell_signals": sell_signals,
                "hold_signals": hold_signals,
                "avg_confidence": avg_confidence,
                "high_confidence_signals": high_confidence_signals,
                "successful_predictions": total_successful,
                "failed_predictions": total_signals - total_successful,
                "signal_accuracy": total_successful / total_signals if total_signals > 0 else 0.0
            }
            
            self.system_status.signal_stats = signal_stats
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ä¿¡å·ç»Ÿè®¡å¤±è´¥: {e}")
    
    def _save_status(self) -> None:
        """ä¿å­˜çŠ¶æ€åˆ°æ•°æ®åº“"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # ä¿å­˜ç³»ç»ŸçŠ¶æ€
            cursor.execute("""
                INSERT INTO system_status_enhanced 
                (status, active_models, total_models, models_by_category, prediction_engine_status, uptime_seconds, timestamp)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (
                self.system_status.status.value,
                json.dumps(self.system_status.active_models),
                self.system_status.total_models,
                json.dumps(self.system_status.models_by_category),
                self.system_status.prediction_engine_status,
                self.system_status.uptime_seconds,
                int(datetime.now().timestamp())
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜AIçŠ¶æ€å¤±è´¥: {e}")
    
    def get_enhanced_ai_status_report(self) -> Dict[str, Any]:
        """è·å–å¢å¼ºç‰ˆAIçŠ¶æ€æŠ¥å‘Š"""
        try:
            # æŒ‰ç±»åˆ«ç»Ÿè®¡æ¨¡å‹
            models_by_category = {}
            active_by_category = {}
            
            for model_name, performance in self.system_status.models_performance.items():
                category = performance.category
                models_by_category[category] = models_by_category.get(category, 0) + 1
                
                if performance.status == AIModelStatus.ACTIVE:
                    active_by_category[category] = active_by_category.get(category, 0) + 1
            
            # è·å–é¡¶çº§æ¨¡å‹
            top_models = sorted(
                self.system_status.models_performance.items(),
                key=lambda x: x[1].accuracy * x[1].success_rate,
                reverse=True
            )[:10]
            
            return {
                "timestamp": datetime.now().isoformat(),
                "system_status": {
                    "status": self.system_status.status.value,
                    "active_models": len(self.system_status.active_models),
                    "total_models": self.system_status.total_models,
                    "prediction_engine_status": self.system_status.prediction_engine_status,
                    "uptime_seconds": self.system_status.uptime_seconds,
                    "last_update": self.system_status.last_update.isoformat()
                },
                "models_by_category": {
                    category: {
                        "total": models_by_category.get(category, 0),
                        "active": active_by_category.get(category, 0)
                    }
                    for category in models_by_category.keys()
                },
                "top_performing_models": [
                    {
                        "name": name,
                        "category": perf.category,
                        "accuracy": perf.accuracy,
                        "success_rate": perf.success_rate,
                        "confidence": perf.avg_confidence,
                        "predictions": perf.prediction_count,
                        "status": perf.status.value
                    }
                    for name, perf in top_models
                ],
                "signal_statistics": self.system_status.signal_stats or {},
                "resource_usage": {
                    "avg_cpu": np.mean([
                        perf.resource_usage.get("cpu_usage", 0)
                        for perf in self.system_status.models_performance.values()
                        if perf.status == AIModelStatus.ACTIVE
                    ]) if self.system_status.active_models else 0,
                    "avg_memory": np.mean([
                        perf.resource_usage.get("memory_usage", 0)
                        for perf in self.system_status.models_performance.values()
                        if perf.status == AIModelStatus.ACTIVE
                    ]) if self.system_status.active_models else 0,
                    "avg_gpu": np.mean([
                        perf.resource_usage.get("gpu_usage", 0)
                        for perf in self.system_status.models_performance.values()
                        if perf.status == AIModelStatus.ACTIVE and perf.resource_usage.get("gpu_usage", 0) > 0
                    ]) if self.system_status.active_models else 0
                }
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–å¢å¼ºç‰ˆAIçŠ¶æ€æŠ¥å‘Šå¤±è´¥: {e}")
            return {}


# å…¨å±€å®ä¾‹
_enhanced_ai_status_monitor = None

def get_enhanced_ai_status_monitor() -> EnhancedAIStatusMonitor:
    """è·å–å¢å¼ºç‰ˆAIçŠ¶æ€ç›‘æ§å™¨å®ä¾‹"""
    global _enhanced_ai_status_monitor
    if _enhanced_ai_status_monitor is None:
        _enhanced_ai_status_monitor = EnhancedAIStatusMonitor()
    return _enhanced_ai_status_monitor


if __name__ == "__main__":
    # æµ‹è¯•å¢å¼ºç‰ˆAIçŠ¶æ€ç›‘æ§å™¨
    monitor = EnhancedAIStatusMonitor()
    monitor.start_monitoring()
    
    try:
        time.sleep(60)
        report = monitor.get_enhanced_ai_status_report()
        print(f"å¢å¼ºç‰ˆAIçŠ¶æ€æŠ¥å‘Š: {json.dumps(report, indent=2, default=str, ensure_ascii=False)}")
    finally:
        monitor.stop_monitoring()

