#!/usr/bin/env python3
"""
ğŸ”® æ—¶é—´åºåˆ—é¢„æµ‹å…ˆçŸ¥ - ä»·æ ¼é¢„æµ‹å¼•æ“
ä½¿ç”¨æ·±åº¦å­¦ä¹ è¿›è¡Œé«˜ç²¾åº¦ä»·æ ¼é¢„æµ‹
ä¸“ä¸ºç”Ÿäº§çº§å®ç›˜äº¤æ˜“è®¾è®¡ï¼Œæ”¯æŒå¤šæ—¶é—´æ¡†æ¶é¢„æµ‹
"""

import asyncio
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from typing import Dict, List, Any, Optional, Tuple, Union
from datetime import datetime, timezone, timedelta
import json
from dataclasses import dataclass
from loguru import logger
import threading
import time
from concurrent.futures import ThreadPoolExecutor
import pandas as pd
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error
import warnings
warnings.filterwarnings('ignore')

@dataclass
class PredictionResult:
    """é¢„æµ‹ç»“æœ"""
    timestamp: datetime
    current_price: float
    predicted_prices: Dict[str, float]  # ä¸åŒæ—¶é—´æ¡†æ¶çš„é¢„æµ‹
    confidence_scores: Dict[str, float]  # ç½®ä¿¡åº¦åˆ†æ•°
    trend_direction: str  # 'up', 'down', 'sideways'
    trend_strength: float  # 0-1ä¹‹é—´
    support_levels: List[float]
    resistance_levels: List[float]
    volatility_forecast: float
    risk_score: float

@dataclass
class MarketFeatures:
    """å¸‚åœºç‰¹å¾"""
    prices: List[float]
    volumes: List[float]
    timestamps: List[datetime]
    technical_indicators: Dict[str, List[float]]
    market_sentiment: List[float]
    news_scores: List[float]

class TransformerPredictor(nn.Module):
    """åŸºäºTransformerçš„ä»·æ ¼é¢„æµ‹æ¨¡å‹"""
    
    def __init__(self, input_dim: int = 20, d_model: int = 256, nhead: int = 8, 
                 num_layers: int = 6, seq_len: int = 100, pred_len: int = 24):
        super().__init__()
        self.input_dim = input_dim
        self.d_model = d_model
        self.seq_len = seq_len
        self.pred_len = pred_len
        
        # è¾“å…¥åµŒå…¥å±‚
        self.input_embedding = nn.Linear(input_dim, d_model)
        self.positional_encoding = PositionalEncoding(d_model, max_len=seq_len)
        
        # Transformerç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model,
            nhead=nhead,
            dim_feedforward=d_model * 4,
            dropout=0.1,
            activation='gelu',
            batch_first=True
        )
        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)
        
        # é¢„æµ‹å¤´
        self.prediction_head = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(d_model // 2, d_model // 4),
            nn.GELU(),
            nn.Linear(d_model // 4, pred_len)
        )
        
        # ç½®ä¿¡åº¦å¤´
        self.confidence_head = nn.Sequential(
            nn.Linear(d_model, d_model // 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(d_model // 2, pred_len),
            nn.Sigmoid()
        )
        
        # æ³¢åŠ¨ç‡é¢„æµ‹å¤´
        self.volatility_head = nn.Sequential(
            nn.Linear(d_model, d_model // 4),
            nn.GELU(),
            nn.Linear(d_model // 4, 1),
            nn.Softplus()
        )
        
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        å‰å‘ä¼ æ’­
        Args:
            x: [batch_size, seq_len, input_dim]
        Returns:
            predictions: [batch_size, pred_len]
            confidence: [batch_size, pred_len]
            volatility: [batch_size, 1]
        """
        # è¾“å…¥åµŒå…¥å’Œä½ç½®ç¼–ç 
        embedded = self.input_embedding(x)  # [batch_size, seq_len, d_model]
        embedded = self.positional_encoding(embedded)
        
        # Transformerç¼–ç 
        encoded = self.transformer_encoder(embedded)  # [batch_size, seq_len, d_model]
        
        # å…¨å±€å¹³å‡æ± åŒ–
        pooled = torch.mean(encoded, dim=1)  # [batch_size, d_model]
        
        # é¢„æµ‹
        predictions = self.prediction_head(pooled)
        confidence = self.confidence_head(pooled)
        volatility = self.volatility_head(pooled)
        
        return predictions, confidence, volatility

class PositionalEncoding(nn.Module):
    """ä½ç½®ç¼–ç """
    
    def __init__(self, d_model: int, max_len: int = 5000):
        super().__init__()
        
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * 
                           (-np.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0).transpose(0, 1)
        
        self.register_buffer('pe', pe)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return x + self.pe[:x.size(1), :].transpose(0, 1)

class TimeSeriesProphet:
    """æ—¶é—´åºåˆ—é¢„æµ‹å…ˆçŸ¥"""
    
    def __init__(self, device: str = None, model_path: str = None):
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        self.model_path = model_path or "models/time_series_prophet.pth"
        
        # æ¨¡å‹å‚æ•°
        self.seq_len = 100  # è¾“å…¥åºåˆ—é•¿åº¦
        self.pred_len = 24  # é¢„æµ‹é•¿åº¦ï¼ˆå°æ—¶ï¼‰
        self.input_dim = 20  # è¾“å…¥ç‰¹å¾ç»´åº¦
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = TransformerPredictor(
            input_dim=self.input_dim,
            seq_len=self.seq_len,
            pred_len=self.pred_len
        ).to(self.device)
        
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=1e-4,
            weight_decay=0.01
        )
        
        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer, T_0=100, T_mult=2
        )
        
        # æ•°æ®é¢„å¤„ç†
        self.price_scaler = MinMaxScaler()
        self.feature_scaler = StandardScaler()
        self.is_fitted = False
        
        # å†å²æ•°æ®ç¼“å­˜
        self.price_history = []
        self.feature_history = []
        self.max_history = 1000
        
        # é¢„æµ‹ç¼“å­˜
        self.prediction_cache = {}
        self.cache_duration = 300  # 5åˆ†é’Ÿç¼“å­˜
        
        # æ€§èƒ½ç»Ÿè®¡
        self.performance_metrics = {
            'mse': 0.0,
            'mae': 0.0,
            'mape': 0.0,
            'accuracy': 0.0,
            'sharpe_ratio': 0.0,
            'hit_rate': 0.0,
            'total_predictions': 0,
            'correct_predictions': 0
        }
        
        # å®æ—¶çŠ¶æ€
        self.last_prediction = None
        self.last_confidence = 0.0
        self.performance_score = 0.5
        
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        self.load_model()
        
        logger.info(f"ğŸ”® æ—¶é—´åºåˆ—é¢„æµ‹å…ˆçŸ¥åˆå§‹åŒ–å®Œæˆ - è®¾å¤‡: {self.device}")
    
    async def predict_prices(self, market_data: Dict[str, Any], 
                           timeframes: List[str] = None) -> PredictionResult:
        """é¢„æµ‹ä»·æ ¼"""
        try:
            if timeframes is None:
                timeframes = ['1h', '4h', '1d']
            
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"prediction_{int(time.time() // self.cache_duration)}"
            if cache_key in self.prediction_cache:
                return self.prediction_cache[cache_key]
            
            # å‡†å¤‡è¾“å…¥æ•°æ®
            input_features = self._prepare_features(market_data)
            if input_features is None:
                return self._create_fallback_prediction(market_data)
            
            # GPUé¢„æµ‹
            with torch.no_grad():
                self.model.eval()
                input_tensor = torch.FloatTensor(input_features).unsqueeze(0).to(self.device)
                predictions, confidence, volatility = self.model(input_tensor)
                
                # è½¬æ¢ä¸ºnumpy
                pred_prices = predictions.cpu().numpy()[0]
                conf_scores = confidence.cpu().numpy()[0]
                vol_forecast = float(volatility.cpu().numpy()[0][0])
            
            # åæ ‡å‡†åŒ–é¢„æµ‹ç»“æœ
            current_price = market_data.get('price', 0.0)
            predicted_prices = self._denormalize_predictions(pred_prices, current_price)
            
            # è®¡ç®—ä¸åŒæ—¶é—´æ¡†æ¶çš„é¢„æµ‹
            timeframe_predictions = {}
            timeframe_confidence = {}
            
            for i, tf in enumerate(timeframes):
                if i < len(predicted_prices):
                    timeframe_predictions[tf] = predicted_prices[i]
                    timeframe_confidence[tf] = conf_scores[i] if i < len(conf_scores) else 0.5
            
            # è¶‹åŠ¿åˆ†æ
            trend_direction, trend_strength = self._analyze_trend(predicted_prices)
            
            # æ”¯æ’‘é˜»åŠ›ä½
            support_levels, resistance_levels = self._calculate_support_resistance(
                market_data, predicted_prices
            )
            
            # é£é™©è¯„ä¼°
            risk_score = self._calculate_risk_score(vol_forecast, conf_scores, market_data)
            
            # åˆ›å»ºé¢„æµ‹ç»“æœ
            result = PredictionResult(
                timestamp=datetime.now(timezone.utc),
                current_price=current_price,
                predicted_prices=timeframe_predictions,
                confidence_scores=timeframe_confidence,
                trend_direction=trend_direction,
                trend_strength=trend_strength,
                support_levels=support_levels,
                resistance_levels=resistance_levels,
                volatility_forecast=vol_forecast,
                risk_score=risk_score
            )
            
            # ç¼“å­˜ç»“æœ
            self.prediction_cache[cache_key] = result
            
            # æ¸…ç†æ—§ç¼“å­˜
            self._cleanup_cache()
            
            # æ›´æ–°çŠ¶æ€
            self.last_prediction = result
            self.last_confidence = np.mean(list(timeframe_confidence.values()))
            
            logger.info(f"ğŸ”® ä»·æ ¼é¢„æµ‹å®Œæˆ - è¶‹åŠ¿: {trend_direction}, å¼ºåº¦: {trend_strength:.3f}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ä»·æ ¼é¢„æµ‹å¤±è´¥: {e}")
            return self._create_fallback_prediction(market_data)
    
    def _prepare_features(self, market_data: Dict[str, Any]) -> Optional[np.ndarray]:
        """å‡†å¤‡è¾“å…¥ç‰¹å¾"""
        try:
            # æ£€æŸ¥å†å²æ•°æ®æ˜¯å¦è¶³å¤Ÿ
            if len(self.price_history) < self.seq_len:
                logger.warning("âš ï¸ å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
                return None
            
            # è·å–æœ€è¿‘çš„ä»·æ ¼å’Œç‰¹å¾
            recent_prices = self.price_history[-self.seq_len:]
            recent_features = self.feature_history[-self.seq_len:]
            
            # æ„å»ºç‰¹å¾çŸ©é˜µ
            features = []
            for i in range(self.seq_len):
                feature_vector = [
                    recent_prices[i],  # ä»·æ ¼
                    market_data.get('volume', 0.0),  # æˆäº¤é‡
                    market_data.get('rsi', 50.0),  # RSI
                    market_data.get('macd', 0.0),  # MACD
                    market_data.get('bb_upper', 0.0),  # å¸ƒæ—å¸¦ä¸Šè½¨
                    market_data.get('bb_lower', 0.0),  # å¸ƒæ—å¸¦ä¸‹è½¨
                    market_data.get('atr', 0.0),  # ATR
                    market_data.get('ema_12', 0.0),  # EMA12
                    market_data.get('ema_26', 0.0),  # EMA26
                    market_data.get('sma_50', 0.0),  # SMA50
                    market_data.get('volume_sma', 0.0),  # æˆäº¤é‡å‡çº¿
                    market_data.get('price_change', 0.0),  # ä»·æ ¼å˜åŒ–
                    market_data.get('volatility', 0.0),  # æ³¢åŠ¨ç‡
                    market_data.get('sentiment', 0.0),  # å¸‚åœºæƒ…ç»ª
                    market_data.get('news_impact', 0.0),  # æ–°é—»å½±å“
                    market_data.get('time_of_day', 0.5),  # æ—¶é—´ç‰¹å¾
                    market_data.get('day_of_week', 0.5),  # æ˜ŸæœŸç‰¹å¾
                    market_data.get('support_level', 0.0),  # æ”¯æ’‘ä½
                    market_data.get('resistance_level', 0.0),  # é˜»åŠ›ä½
                    market_data.get('trend_strength', 0.0)  # è¶‹åŠ¿å¼ºåº¦
                ]
                features.append(feature_vector)
            
            # æ ‡å‡†åŒ–ç‰¹å¾
            features_array = np.array(features)
            if not self.is_fitted:
                self.feature_scaler.fit(features_array)
                self.is_fitted = True
            
            normalized_features = self.feature_scaler.transform(features_array)
            return normalized_features
            
        except Exception as e:
            logger.error(f"âŒ ç‰¹å¾å‡†å¤‡å¤±è´¥: {e}")
            return None
