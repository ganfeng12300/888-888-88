#!/usr/bin/env python3
"""
ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨ - ç”Ÿäº§çº§æ€§èƒ½ç›‘æ§
Performance Metrics Collector - Production-Grade Performance Monitoring

ç”Ÿäº§çº§ç‰¹æ€§ï¼š
- å¤šç»´åº¦æ€§èƒ½æŒ‡æ ‡æ”¶é›†
- å®æ—¶æ€§èƒ½åŸºçº¿å»ºç«‹
- æ€§èƒ½è¶‹åŠ¿åˆ†æ
- å¼‚å¸¸æ£€æµ‹å’Œé¢„è­¦
- æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ
"""

import time
import psutil
import threading
import asyncio
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, asdict
from collections import deque, defaultdict
import json
import statistics
import numpy as np
from pathlib import Path

from .unified_logging_system import UnifiedLogger

@dataclass
class PerformanceMetric:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç»“æ„"""
    timestamp: datetime
    metric_name: str
    value: float
    unit: str
    tags: Dict[str, str] = None
    source: str = "system"

@dataclass
class PerformanceBaseline:
    """æ€§èƒ½åŸºçº¿æ•°æ®ç»“æ„"""
    metric_name: str
    avg_value: float
    min_value: float
    max_value: float
    std_deviation: float
    percentile_95: float
    percentile_99: float
    sample_count: int
    created_at: datetime
    updated_at: datetime

class SystemMetricsCollector:
    """ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        log_config = LogConfig(
            log_dir="logs",
            console_output=True,
            file_output=True,
            json_format=False
        )
        self.logger = UnifiedLoggingSystem(log_config) # "SystemMetricsCollector")
        self.metrics_history = deque(maxlen=10000)
        self._collection_interval = 1.0
        self._running = False
        self._collection_thread = None
    
    def start_collection(self):
        """å¼€å§‹æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        if self._running:
            return
        
        self._running = True
        self._collection_thread = threading.Thread(target=self._collection_loop, daemon=True)
        self._collection_thread.start()
        self.logger.info("ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å·²å¯åŠ¨")
    
    def stop_collection(self):
        """åœæ­¢æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        self._running = False
        if self._collection_thread:
            self._collection_thread.join(timeout=5)
        self.logger.info("ç³»ç»ŸæŒ‡æ ‡æ”¶é›†å·²åœæ­¢")
    
    def _collection_loop(self):
        """æŒ‡æ ‡æ”¶é›†å¾ªç¯"""
        while self._running:
            try:
                self._collect_cpu_metrics()
                self._collect_memory_metrics()
                self._collect_disk_metrics()
                self._collect_network_metrics()
                self._collect_process_metrics()
                
                time.sleep(self._collection_interval)
                
            except Exception as e:
                self.logger.error(f"æ”¶é›†ç³»ç»ŸæŒ‡æ ‡å¼‚å¸¸: {e}")
                time.sleep(5)
    
    def _collect_cpu_metrics(self):
        """æ”¶é›†CPUæŒ‡æ ‡"""
        try:
            # CPUä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=None)
            self._add_metric("cpu.usage_percent", cpu_percent, "%")
            
            # CPUæ ¸å¿ƒä½¿ç”¨ç‡
            cpu_per_core = psutil.cpu_percent(interval=None, percpu=True)
            for i, usage in enumerate(cpu_per_core):
                self._add_metric("cpu.core_usage_percent", usage, "%", {"core": str(i)})
            
            # CPUé¢‘ç‡
            cpu_freq = psutil.cpu_freq()
            if cpu_freq:
                self._add_metric("cpu.frequency_mhz", cpu_freq.current, "MHz")
            
            # ç³»ç»Ÿè´Ÿè½½
            load_avg = psutil.getloadavg()
            self._add_metric("cpu.load_1min", load_avg[0], "")
            self._add_metric("cpu.load_5min", load_avg[1], "")
            self._add_metric("cpu.load_15min", load_avg[2], "")
            
        except Exception as e:
            self.logger.error(f"æ”¶é›†CPUæŒ‡æ ‡å¤±è´¥: {e}")
    
    def _collect_memory_metrics(self):
        """æ”¶é›†å†…å­˜æŒ‡æ ‡"""
        try:
            # è™šæ‹Ÿå†…å­˜
            memory = psutil.virtual_memory()
            self._add_metric("memory.total_bytes", memory.total, "bytes")
            self._add_metric("memory.available_bytes", memory.available, "bytes")
            self._add_metric("memory.used_bytes", memory.used, "bytes")
            self._add_metric("memory.usage_percent", memory.percent, "%")
            
            # äº¤æ¢å†…å­˜
            swap = psutil.swap_memory()
            self._add_metric("swap.total_bytes", swap.total, "bytes")
            self._add_metric("swap.used_bytes", swap.used, "bytes")
            self._add_metric("swap.usage_percent", swap.percent, "%")
            
        except Exception as e:
            self.logger.error(f"æ”¶é›†å†…å­˜æŒ‡æ ‡å¤±è´¥: {e}")
    
    def _collect_disk_metrics(self):
        """æ”¶é›†ç£ç›˜æŒ‡æ ‡"""
        try:
            # ç£ç›˜ä½¿ç”¨æƒ…å†µ
            disk_usage = psutil.disk_usage('/')
            self._add_metric("disk.total_bytes", disk_usage.total, "bytes")
            self._add_metric("disk.used_bytes", disk_usage.used, "bytes")
            self._add_metric("disk.free_bytes", disk_usage.free, "bytes")
            self._add_metric("disk.usage_percent", (disk_usage.used / disk_usage.total) * 100, "%")
            
            # ç£ç›˜IO
            disk_io = psutil.disk_io_counters()
            if disk_io:
                self._add_metric("disk.read_bytes", disk_io.read_bytes, "bytes")
                self._add_metric("disk.write_bytes", disk_io.write_bytes, "bytes")
                self._add_metric("disk.read_count", disk_io.read_count, "count")
                self._add_metric("disk.write_count", disk_io.write_count, "count")
                self._add_metric("disk.read_time_ms", disk_io.read_time, "ms")
                self._add_metric("disk.write_time_ms", disk_io.write_time, "ms")
            
        except Exception as e:
            self.logger.error(f"æ”¶é›†ç£ç›˜æŒ‡æ ‡å¤±è´¥: {e}")
    
    def _collect_network_metrics(self):
        """æ”¶é›†ç½‘ç»œæŒ‡æ ‡"""
        try:
            # ç½‘ç»œIO
            network_io = psutil.net_io_counters()
            if network_io:
                self._add_metric("network.bytes_sent", network_io.bytes_sent, "bytes")
                self._add_metric("network.bytes_recv", network_io.bytes_recv, "bytes")
                self._add_metric("network.packets_sent", network_io.packets_sent, "count")
                self._add_metric("network.packets_recv", network_io.packets_recv, "count")
                self._add_metric("network.errin", network_io.errin, "count")
                self._add_metric("network.errout", network_io.errout, "count")
                self._add_metric("network.dropin", network_io.dropin, "count")
                self._add_metric("network.dropout", network_io.dropout, "count")
            
            # ç½‘ç»œè¿æ¥æ•°
            connections = psutil.net_connections()
            connection_states = defaultdict(int)
            for conn in connections:
                if conn.status:
                    connection_states[conn.status] += 1
            
            for state, count in connection_states.items():
                self._add_metric("network.connections", count, "count", {"state": state})
            
        except Exception as e:
            self.logger.error(f"æ”¶é›†ç½‘ç»œæŒ‡æ ‡å¤±è´¥: {e}")
    
    def _collect_process_metrics(self):
        """æ”¶é›†è¿›ç¨‹æŒ‡æ ‡"""
        try:
            # è¿›ç¨‹æ•°é‡
            process_count = len(psutil.pids())
            self._add_metric("process.total_count", process_count, "count")
            
            # å½“å‰è¿›ç¨‹æŒ‡æ ‡
            current_process = psutil.Process()
            
            # å†…å­˜ä½¿ç”¨
            memory_info = current_process.memory_info()
            self._add_metric("process.memory_rss_bytes", memory_info.rss, "bytes")
            self._add_metric("process.memory_vms_bytes", memory_info.vms, "bytes")
            
            # CPUä½¿ç”¨
            cpu_percent = current_process.cpu_percent()
            self._add_metric("process.cpu_percent", cpu_percent, "%")
            
            # æ–‡ä»¶æè¿°ç¬¦
            try:
                num_fds = current_process.num_fds()
                self._add_metric("process.file_descriptors", num_fds, "count")
            except:
                pass  # Windowsä¸æ”¯æŒ
            
            # çº¿ç¨‹æ•°
            num_threads = current_process.num_threads()
            self._add_metric("process.thread_count", num_threads, "count")
            
        except Exception as e:
            self.logger.error(f"æ”¶é›†è¿›ç¨‹æŒ‡æ ‡å¤±è´¥: {e}")
    
    def _add_metric(self, name: str, value: float, unit: str, tags: Dict[str, str] = None):
        """æ·»åŠ æŒ‡æ ‡"""
        metric = PerformanceMetric(
            timestamp=datetime.now(),
            metric_name=name,
            value=value,
            unit=unit,
            tags=tags or {},
            source="system"
        )
        self.metrics_history.append(metric)

class ApplicationMetricsCollector:
    """åº”ç”¨æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self):
        # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        log_config = LogConfig(
            log_dir="logs",
            console_output=True,
            file_output=True,
            json_format=False
        )
        self.logger = UnifiedLoggingSystem(log_config) # "ApplicationMetricsCollector")
        self.metrics_history = deque(maxlen=10000)
        self.function_timers = {}
        self.counters = defaultdict(int)
        self.gauges = {}
        self.histograms = defaultdict(list)
    
    def start_timer(self, name: str) -> str:
        """å¼€å§‹è®¡æ—¶å™¨"""
        timer_id = f"{name}_{int(time.time() * 1000000)}"
        self.function_timers[timer_id] = {
            'name': name,
            'start_time': time.perf_counter(),
            'start_timestamp': datetime.now()
        }
        return timer_id
    
    def end_timer(self, timer_id: str) -> Optional[float]:
        """ç»“æŸè®¡æ—¶å™¨"""
        if timer_id not in self.function_timers:
            return None
        
        timer_info = self.function_timers[timer_id]
        end_time = time.perf_counter()
        duration = end_time - timer_info['start_time']
        
        # è®°å½•æŒ‡æ ‡
        self._add_metric(f"function.{timer_info['name']}.duration", duration * 1000, "ms")
        
        # æ·»åŠ åˆ°ç›´æ–¹å›¾
        self.histograms[f"function.{timer_info['name']}.duration"].append(duration * 1000)
        
        # æ¸…ç†è®¡æ—¶å™¨
        del self.function_timers[timer_id]
        
        return duration
    
    def increment_counter(self, name: str, value: int = 1, tags: Dict[str, str] = None):
        """å¢åŠ è®¡æ•°å™¨"""
        self.counters[name] += value
        self._add_metric(f"counter.{name}", self.counters[name], "count", tags)
    
    def set_gauge(self, name: str, value: float, tags: Dict[str, str] = None):
        """è®¾ç½®ä»ªè¡¨"""
        self.gauges[name] = value
        self._add_metric(f"gauge.{name}", value, "value", tags)
    
    def record_histogram(self, name: str, value: float, tags: Dict[str, str] = None):
        """è®°å½•ç›´æ–¹å›¾"""
        self.histograms[name].append(value)
        self._add_metric(f"histogram.{name}", value, "value", tags)
    
    def _add_metric(self, name: str, value: float, unit: str, tags: Dict[str, str] = None):
        """æ·»åŠ æŒ‡æ ‡"""
        metric = PerformanceMetric(
            timestamp=datetime.now(),
            metric_name=name,
            value=value,
            unit=unit,
            tags=tags or {},
            source="application"
        )
        self.metrics_history.append(metric)

class PerformanceAnalyzer:
    """æ€§èƒ½åˆ†æå™¨"""
    
    def __init__(self):
        # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        log_config = LogConfig(
            log_dir="logs",
            console_output=True,
            file_output=True,
            json_format=False
        )
        self.logger = UnifiedLoggingSystem(log_config) # "PerformanceAnalyzer")
        self.baselines: Dict[str, PerformanceBaseline] = {}
        self.anomaly_threshold = 2.0  # æ ‡å‡†å·®å€æ•°
    
    def create_baseline(self, metrics: List[PerformanceMetric], metric_name: str) -> PerformanceBaseline:
        """åˆ›å»ºæ€§èƒ½åŸºçº¿"""
        try:
            # è¿‡æ»¤æŒ‡å®šæŒ‡æ ‡
            filtered_metrics = [m for m in metrics if m.metric_name == metric_name]
            
            if len(filtered_metrics) < 10:
                self.logger.warning(f"æŒ‡æ ‡ {metric_name} æ ·æœ¬æ•°é‡ä¸è¶³ï¼Œæ— æ³•åˆ›å»ºåŸºçº¿")
                return None
            
            values = [m.value for m in filtered_metrics]
            
            baseline = PerformanceBaseline(
                metric_name=metric_name,
                avg_value=statistics.mean(values),
                min_value=min(values),
                max_value=max(values),
                std_deviation=statistics.stdev(values) if len(values) > 1 else 0,
                percentile_95=np.percentile(values, 95),
                percentile_99=np.percentile(values, 99),
                sample_count=len(values),
                created_at=datetime.now(),
                updated_at=datetime.now()
            )
            
            self.baselines[metric_name] = baseline
            self.logger.info(f"åˆ›å»ºæ€§èƒ½åŸºçº¿: {metric_name}")
            return baseline
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºæ€§èƒ½åŸºçº¿å¤±è´¥: {e}")
            return None
    
    def update_baseline(self, metrics: List[PerformanceMetric], metric_name: str):
        """æ›´æ–°æ€§èƒ½åŸºçº¿"""
        if metric_name not in self.baselines:
            return self.create_baseline(metrics, metric_name)
        
        try:
            # è·å–æœ€è¿‘çš„æŒ‡æ ‡
            recent_metrics = [
                m for m in metrics 
                if m.metric_name == metric_name and 
                (datetime.now() - m.timestamp).total_seconds() < 3600  # æœ€è¿‘1å°æ—¶
            ]
            
            if len(recent_metrics) < 10:
                return
            
            values = [m.value for m in recent_metrics]
            baseline = self.baselines[metric_name]
            
            # æ›´æ–°åŸºçº¿
            baseline.avg_value = statistics.mean(values)
            baseline.min_value = min(values)
            baseline.max_value = max(values)
            baseline.std_deviation = statistics.stdev(values) if len(values) > 1 else 0
            baseline.percentile_95 = np.percentile(values, 95)
            baseline.percentile_99 = np.percentile(values, 99)
            baseline.sample_count = len(values)
            baseline.updated_at = datetime.now()
            
            self.logger.debug(f"æ›´æ–°æ€§èƒ½åŸºçº¿: {metric_name}")
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°æ€§èƒ½åŸºçº¿å¤±è´¥: {e}")
    
    def detect_anomalies(self, metrics: List[PerformanceMetric]) -> List[Dict]:
        """æ£€æµ‹æ€§èƒ½å¼‚å¸¸"""
        anomalies = []
        
        try:
            # æŒ‰æŒ‡æ ‡åç§°åˆ†ç»„
            metrics_by_name = defaultdict(list)
            for metric in metrics:
                metrics_by_name[metric.metric_name].append(metric)
            
            for metric_name, metric_list in metrics_by_name.items():
                if metric_name not in self.baselines:
                    continue
                
                baseline = self.baselines[metric_name]
                
                # æ£€æŸ¥æœ€è¿‘çš„æŒ‡æ ‡å€¼
                for metric in metric_list[-10:]:  # æ£€æŸ¥æœ€è¿‘10ä¸ªå€¼
                    deviation = abs(metric.value - baseline.avg_value)
                    threshold = baseline.std_deviation * self.anomaly_threshold
                    
                    if deviation > threshold and baseline.std_deviation > 0:
                        anomaly = {
                            'metric_name': metric_name,
                            'timestamp': metric.timestamp,
                            'value': metric.value,
                            'baseline_avg': baseline.avg_value,
                            'deviation': deviation,
                            'threshold': threshold,
                            'severity': self._calculate_anomaly_severity(deviation, threshold)
                        }
                        anomalies.append(anomaly)
            
        except Exception as e:
            self.logger.error(f"æ£€æµ‹æ€§èƒ½å¼‚å¸¸å¤±è´¥: {e}")
        
        return anomalies
    
    def _calculate_anomaly_severity(self, deviation: float, threshold: float) -> str:
        """è®¡ç®—å¼‚å¸¸ä¸¥é‡ç¨‹åº¦"""
        ratio = deviation / threshold
        
        if ratio >= 5:
            return "critical"
        elif ratio >= 3:
            return "high"
        elif ratio >= 2:
            return "medium"
        else:
            return "low"
    
    def generate_performance_report(self, metrics: List[PerformanceMetric], hours: int = 24) -> Dict:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        try:
            cutoff_time = datetime.now() - timedelta(hours=hours)
            
            # è¿‡æ»¤æ—¶é—´èŒƒå›´å†…çš„æŒ‡æ ‡
            filtered_metrics = [
                m for m in metrics 
                if m.timestamp >= cutoff_time
            ]
            
            # æŒ‰æŒ‡æ ‡åç§°åˆ†ç»„ç»Ÿè®¡
            metrics_stats = {}
            metrics_by_name = defaultdict(list)
            
            for metric in filtered_metrics:
                metrics_by_name[metric.metric_name].append(metric.value)
            
            for metric_name, values in metrics_by_name.items():
                if not values:
                    continue
                
                metrics_stats[metric_name] = {
                    'count': len(values),
                    'avg': statistics.mean(values),
                    'min': min(values),
                    'max': max(values),
                    'std': statistics.stdev(values) if len(values) > 1 else 0,
                    'p50': np.percentile(values, 50),
                    'p95': np.percentile(values, 95),
                    'p99': np.percentile(values, 99)
                }
            
            # æ£€æµ‹å¼‚å¸¸
            anomalies = self.detect_anomalies(filtered_metrics)
            
            # ç”ŸæˆæŠ¥å‘Š
            report = {
                'report_time': datetime.now().isoformat(),
                'time_range_hours': hours,
                'total_metrics': len(filtered_metrics),
                'unique_metric_names': len(metrics_stats),
                'metrics_statistics': metrics_stats,
                'anomalies_detected': len(anomalies),
                'anomalies': anomalies,
                'baselines': {name: asdict(baseline) for name, baseline in self.baselines.items()},
                'top_metrics_by_variance': self._get_top_metrics_by_variance(metrics_stats)
            }
            
            return report
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")
            return {}
    
    def _get_top_metrics_by_variance(self, metrics_stats: Dict, top_n: int = 10) -> List[Dict]:
        """è·å–æ–¹å·®æœ€å¤§çš„æŒ‡æ ‡"""
        try:
            variance_metrics = []
            
            for metric_name, stats in metrics_stats.items():
                if stats['std'] > 0:
                    # è®¡ç®—å˜å¼‚ç³»æ•° (CV = std / mean)
                    cv = stats['std'] / abs(stats['avg']) if stats['avg'] != 0 else float('inf')
                    variance_metrics.append({
                        'metric_name': metric_name,
                        'coefficient_of_variation': cv,
                        'std_deviation': stats['std'],
                        'mean': stats['avg']
                    })
            
            # æŒ‰å˜å¼‚ç³»æ•°æ’åº
            variance_metrics.sort(key=lambda x: x['coefficient_of_variation'], reverse=True)
            return variance_metrics[:top_n]
            
        except Exception as e:
            self.logger.error(f"è®¡ç®—æ–¹å·®æŒ‡æ ‡å¤±è´¥: {e}")
            return []

class PerformanceMetricsManager:
    """æ€§èƒ½æŒ‡æ ‡ç®¡ç†å™¨"""
    
    def __init__(self):
        # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        log_config = LogConfig(
            log_dir="logs",
            console_output=True,
            file_output=True,
            json_format=False
        )
        self.logger = UnifiedLoggingSystem(log_config) # "PerformanceMetricsManager")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.system_collector = SystemMetricsCollector()
        self.app_collector = ApplicationMetricsCollector()
        self.analyzer = PerformanceAnalyzer()
        
        # é…ç½®
        self.baseline_update_interval = 3600  # 1å°æ—¶æ›´æ–°ä¸€æ¬¡åŸºçº¿
        self.anomaly_check_interval = 300     # 5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡å¼‚å¸¸
        
        # çŠ¶æ€
        self._running = False
        self._analysis_thread = None
        
        self.logger.info("æ€§èƒ½æŒ‡æ ‡ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def start(self):
        """å¯åŠ¨æ€§èƒ½ç›‘æ§"""
        if self._running:
            return
        
        self._running = True
        
        # å¯åŠ¨ç³»ç»ŸæŒ‡æ ‡æ”¶é›†
        self.system_collector.start_collection()
        
        # å¯åŠ¨åˆ†æçº¿ç¨‹
        self._analysis_thread = threading.Thread(target=self._analysis_loop, daemon=True)
        self._analysis_thread.start()
        
        self.logger.info("æ€§èƒ½ç›‘æ§å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        if not self._running:
            return
        
        self._running = False
        
        # åœæ­¢ç³»ç»ŸæŒ‡æ ‡æ”¶é›†
        self.system_collector.stop_collection()
        
        # åœæ­¢åˆ†æçº¿ç¨‹
        if self._analysis_thread:
            self._analysis_thread.join(timeout=5)
        
        self.logger.info("æ€§èƒ½ç›‘æ§å·²åœæ­¢")
    
    def _analysis_loop(self):
        """åˆ†æå¾ªç¯"""
        last_baseline_update = 0
        last_anomaly_check = 0
        
        while self._running:
            try:
                current_time = time.time()
                
                # è·å–æ‰€æœ‰æŒ‡æ ‡
                all_metrics = list(self.system_collector.metrics_history) + list(self.app_collector.metrics_history)
                
                # æ›´æ–°åŸºçº¿
                if current_time - last_baseline_update >= self.baseline_update_interval:
                    self._update_all_baselines(all_metrics)
                    last_baseline_update = current_time
                
                # æ£€æŸ¥å¼‚å¸¸
                if current_time - last_anomaly_check >= self.anomaly_check_interval:
                    anomalies = self.analyzer.detect_anomalies(all_metrics)
                    if anomalies:
                        self._handle_anomalies(anomalies)
                    last_anomaly_check = current_time
                
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                self.logger.error(f"æ€§èƒ½åˆ†æå¾ªç¯å¼‚å¸¸: {e}")
                time.sleep(60)
    
    def _update_all_baselines(self, metrics: List[PerformanceMetric]):
        """æ›´æ–°æ‰€æœ‰åŸºçº¿"""
        try:
            # è·å–æ‰€æœ‰å”¯ä¸€çš„æŒ‡æ ‡åç§°
            metric_names = set(m.metric_name for m in metrics)
            
            for metric_name in metric_names:
                self.analyzer.update_baseline(metrics, metric_name)
            
            self.logger.info(f"æ›´æ–°äº† {len(metric_names)} ä¸ªæŒ‡æ ‡çš„åŸºçº¿")
            
        except Exception as e:
            self.logger.error(f"æ›´æ–°åŸºçº¿å¤±è´¥: {e}")
    
    def _handle_anomalies(self, anomalies: List[Dict]):
        """å¤„ç†å¼‚å¸¸"""
        for anomaly in anomalies:
            self.logger.warning(
                f"æ£€æµ‹åˆ°æ€§èƒ½å¼‚å¸¸: {anomaly['metric_name']} | "
                f"å½“å‰å€¼: {anomaly['value']:.2f} | "
                f"åŸºçº¿: {anomaly['baseline_avg']:.2f} | "
                f"åå·®: {anomaly['deviation']:.2f} | "
                f"ä¸¥é‡ç¨‹åº¦: {anomaly['severity']}"
            )
    
    def get_current_metrics(self) -> Dict:
        """è·å–å½“å‰æŒ‡æ ‡"""
        system_metrics = list(self.system_collector.metrics_history)[-100:]  # æœ€è¿‘100ä¸ª
        app_metrics = list(self.app_collector.metrics_history)[-100:]
        
        return {
            'system_metrics': [asdict(m) for m in system_metrics],
            'application_metrics': [asdict(m) for m in app_metrics],
            'timestamp': datetime.now().isoformat()
        }
    
    def generate_report(self, hours: int = 24) -> Dict:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        all_metrics = list(self.system_collector.metrics_history) + list(self.app_collector.metrics_history)
        return self.analyzer.generate_performance_report(all_metrics, hours)
    
    def export_metrics(self, filepath: str, hours: int = 24):
        """å¯¼å‡ºæŒ‡æ ‡æ•°æ®"""
        try:
            report = self.generate_report(hours)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, default=str, ensure_ascii=False)
            
            self.logger.info(f"æ€§èƒ½æŒ‡æ ‡å·²å¯¼å‡ºåˆ°: {filepath}")
            
        except Exception as e:
            self.logger.error(f"å¯¼å‡ºæ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")

# æ€§èƒ½ç›‘æ§è£…é¥°å™¨
def monitor_performance(metrics_manager: PerformanceMetricsManager):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            timer_id = metrics_manager.app_collector.start_timer(func.__name__)
            try:
                result = func(*args, **kwargs)
                metrics_manager.app_collector.increment_counter(f"{func.__name__}.success_count")
                return result
            except Exception as e:
                metrics_manager.app_collector.increment_counter(f"{func.__name__}.error_count")
                raise
            finally:
                duration = metrics_manager.app_collector.end_timer(timer_id)
                if duration and duration > 1.0:  # è®°å½•è¶…è¿‡1ç§’çš„å‡½æ•°è°ƒç”¨
                    metrics_manager.logger.info(f"å‡½æ•° {func.__name__} æ‰§è¡Œæ—¶é—´: {duration:.3f}ç§’")
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºæ€§èƒ½æŒ‡æ ‡ç®¡ç†å™¨
    metrics_manager = PerformanceMetricsManager()
    
    # å¯åŠ¨ç›‘æ§
    metrics_manager.start()
    
    try:
        # è¿è¡Œä¸€æ®µæ—¶é—´è¿›è¡Œæµ‹è¯•
        time.sleep(60)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = metrics_manager.generate_report(hours=1)
        print("æ€§èƒ½æŠ¥å‘Š:", json.dumps(report, indent=2, default=str, ensure_ascii=False))
        
    except KeyboardInterrupt:
        print("åœæ­¢ç›‘æ§...")
    finally:
        metrics_manager.stop()
