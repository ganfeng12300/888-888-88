#!/usr/bin/env python3
"""
ğŸ“Š ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ - ç”Ÿäº§çº§æ—¥å¿—ç®¡ç†
Unified Logging System - Production-Grade Log Management

ç”Ÿäº§çº§ç‰¹æ€§ï¼š
- ç»“æ„åŒ–æ—¥å¿—è®°å½•
- å¤šçº§åˆ«æ—¥å¿—åˆ†ç±»
- è‡ªåŠ¨æ—¥å¿—è½®è½¬
- æ€§èƒ½ç›‘æ§é›†æˆ
- å¼‚å¸¸è¿½è¸ª
- å®æ—¶æ—¥å¿—æµ
"""

import os
import sys
import json
import time
import threading
import traceback
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Union, Callable
from dataclasses import dataclass, asdict
from enum import Enum
import logging
import logging.handlers
from concurrent.futures import ThreadPoolExecutor
import queue
import gzip
import shutil

from loguru import logger as loguru_logger


class LogLevel(Enum):
    """æ—¥å¿—çº§åˆ«æšä¸¾"""
    TRACE = "TRACE"
    DEBUG = "DEBUG"
    INFO = "INFO"
    SUCCESS = "SUCCESS"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


class LogCategory(Enum):
    """æ—¥å¿—åˆ†ç±»æšä¸¾"""
    SYSTEM = "SYSTEM"          # ç³»ç»Ÿçº§æ—¥å¿—
    TRADING = "TRADING"        # äº¤æ˜“ç›¸å…³æ—¥å¿—
    AI = "AI"                 # AIç›¸å…³æ—¥å¿—
    RISK = "RISK"             # é£é™©ç®¡ç†æ—¥å¿—
    PERFORMANCE = "PERFORMANCE" # æ€§èƒ½ç›‘æ§æ—¥å¿—
    NETWORK = "NETWORK"        # ç½‘ç»œé€šä¿¡æ—¥å¿—
    DATABASE = "DATABASE"      # æ•°æ®åº“æ“ä½œæ—¥å¿—
    SECURITY = "SECURITY"      # å®‰å…¨ç›¸å…³æ—¥å¿—
    BUSINESS = "BUSINESS"      # ä¸šåŠ¡é€»è¾‘æ—¥å¿—
    AUDIT = "AUDIT"           # å®¡è®¡æ—¥å¿—
    ALERT = "ALERT"           # å‘Šè­¦æ—¥å¿—


@dataclass
class LogEntry:
    """æ—¥å¿—æ¡ç›®æ•°æ®ç»“æ„"""
    timestamp: str
    level: str
    category: str
    module: str
    function: str
    line: int
    message: str
    extra_data: Dict[str, Any]
    trace_id: Optional[str] = None
    user_id: Optional[str] = None
    session_id: Optional[str] = None
    request_id: Optional[str] = None
    execution_time: Optional[float] = None
    memory_usage: Optional[int] = None
    cpu_usage: Optional[float] = None


@dataclass
class LogConfig:
    """æ—¥å¿—é…ç½®"""
    log_dir: str = "logs"
    max_file_size: int = 100 * 1024 * 1024  # 100MB
    backup_count: int = 10
    compression: bool = True
    console_output: bool = True
    file_output: bool = True
    json_format: bool = True
    include_trace: bool = True
    buffer_size: int = 1000
    flush_interval: float = 5.0
    enable_performance_logging: bool = True
    enable_audit_logging: bool = True
    log_retention_days: int = 30


class LogBuffer:
    """æ—¥å¿—ç¼“å†²åŒº"""
    
    def __init__(self, max_size: int = 1000):
        self.max_size = max_size
        self.buffer = queue.Queue(maxsize=max_size)
        self.lock = threading.Lock()
    
    def add(self, log_entry: LogEntry) -> bool:
        """æ·»åŠ æ—¥å¿—æ¡ç›®åˆ°ç¼“å†²åŒº"""
        try:
            self.buffer.put_nowait(log_entry)
            return True
        except queue.Full:
            # ç¼“å†²åŒºæ»¡æ—¶ï¼Œç§»é™¤æœ€æ—§çš„æ¡ç›®
            try:
                self.buffer.get_nowait()
                self.buffer.put_nowait(log_entry)
                return True
            except queue.Empty:
                return False
    
    def get_all(self) -> List[LogEntry]:
        """è·å–æ‰€æœ‰ç¼“å†²çš„æ—¥å¿—æ¡ç›®"""
        entries = []
        while not self.buffer.empty():
            try:
                entries.append(self.buffer.get_nowait())
            except queue.Empty:
                break
        return entries
    
    def size(self) -> int:
        """è·å–ç¼“å†²åŒºå¤§å°"""
        return self.buffer.qsize()


class LogFormatter:
    """æ—¥å¿—æ ¼å¼åŒ–å™¨"""
    
    @staticmethod
    def format_json(log_entry: LogEntry) -> str:
        """æ ¼å¼åŒ–ä¸ºJSON"""
        return json.dumps(asdict(log_entry), ensure_ascii=False, default=str)
    
    @staticmethod
    def format_text(log_entry: LogEntry) -> str:
        """æ ¼å¼åŒ–ä¸ºæ–‡æœ¬"""
        base_info = f"{log_entry.timestamp} | {log_entry.level:<8} | {log_entry.category:<12} | {log_entry.module}:{log_entry.function}:{log_entry.line}"
        
        if log_entry.execution_time:
            base_info += f" | {log_entry.execution_time:.3f}s"
        
        if log_entry.trace_id:
            base_info += f" | trace:{log_entry.trace_id[:8]}"
        
        message_part = f" | {log_entry.message}"
        
        if log_entry.extra_data:
            extra_part = f" | {json.dumps(log_entry.extra_data, ensure_ascii=False)}"
        else:
            extra_part = ""
        
        return base_info + message_part + extra_part
    
    @staticmethod
    def format_console(log_entry: LogEntry) -> str:
        """æ ¼å¼åŒ–ä¸ºæ§åˆ¶å°è¾“å‡º"""
        # æ·»åŠ é¢œè‰²ä»£ç 
        level_colors = {
            "TRACE": "\033[90m",      # ç°è‰²
            "DEBUG": "\033[36m",      # é’è‰²
            "INFO": "\033[32m",       # ç»¿è‰²
            "SUCCESS": "\033[92m",    # äº®ç»¿è‰²
            "WARNING": "\033[33m",    # é»„è‰²
            "ERROR": "\033[31m",      # çº¢è‰²
            "CRITICAL": "\033[91m",   # äº®çº¢è‰²
        }
        
        reset_color = "\033[0m"
        color = level_colors.get(log_entry.level, "")
        
        time_str = log_entry.timestamp.split('T')[1][:12]  # åªæ˜¾ç¤ºæ—¶é—´éƒ¨åˆ†
        
        formatted = f"{color}{time_str} | {log_entry.level:<8} | {log_entry.category:<10} | {log_entry.message}{reset_color}"
        
        return formatted


class LogRotator:
    """æ—¥å¿—è½®è½¬ç®¡ç†å™¨"""
    
    def __init__(self, config: LogConfig):
        self.config = config
        self.log_dir = Path(config.log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
    
    def should_rotate(self, file_path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦è½®è½¬"""
        if not file_path.exists():
            return False
        
        return file_path.stat().st_size >= self.config.max_file_size
    
    def rotate_file(self, file_path: Path) -> Path:
        """è½®è½¬æ—¥å¿—æ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        rotated_name = f"{file_path.stem}_{timestamp}{file_path.suffix}"
        rotated_path = file_path.parent / rotated_name
        
        # ç§»åŠ¨å½“å‰æ–‡ä»¶
        shutil.move(str(file_path), str(rotated_path))
        
        # å‹ç¼©æ–‡ä»¶
        if self.config.compression:
            compressed_path = rotated_path.with_suffix(rotated_path.suffix + '.gz')
            with open(rotated_path, 'rb') as f_in:
                with gzip.open(compressed_path, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)
            rotated_path.unlink()  # åˆ é™¤æœªå‹ç¼©æ–‡ä»¶
            rotated_path = compressed_path
        
        return rotated_path
    
    def cleanup_old_logs(self):
        """æ¸…ç†è¿‡æœŸæ—¥å¿—"""
        cutoff_date = datetime.now() - timedelta(days=self.config.log_retention_days)
        
        for log_file in self.log_dir.glob("*.log*"):
            try:
                file_time = datetime.fromtimestamp(log_file.stat().st_mtime)
                if file_time < cutoff_date:
                    log_file.unlink()
                    print(f"åˆ é™¤è¿‡æœŸæ—¥å¿—æ–‡ä»¶: {log_file}")
            except Exception as e:
                print(f"æ¸…ç†æ—¥å¿—æ–‡ä»¶å¤±è´¥ {log_file}: {e}")


class PerformanceTracker:
    """æ€§èƒ½è¿½è¸ªå™¨"""
    
    def __init__(self):
        self.start_times = {}
        self.lock = threading.Lock()
    
    def start_tracking(self, trace_id: str):
        """å¼€å§‹æ€§èƒ½è¿½è¸ª"""
        with self.lock:
            self.start_times[trace_id] = time.time()
    
    def end_tracking(self, trace_id: str) -> Optional[float]:
        """ç»“æŸæ€§èƒ½è¿½è¸ª"""
        with self.lock:
            start_time = self.start_times.pop(trace_id, None)
            if start_time:
                return time.time() - start_time
            return None


class UnifiedLoggingSystem:
    """ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ"""
    
    def __init__(self, config: LogConfig = None):
        self.config = config or LogConfig()
        self.log_dir = Path(self.config.log_dir)
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.buffer = LogBuffer(self.config.buffer_size)
        self.formatter = LogFormatter()
        self.rotator = LogRotator(self.config)
        self.performance_tracker = PerformanceTracker()
        
        # çº¿ç¨‹æ± ç”¨äºå¼‚æ­¥æ—¥å¿—å¤„ç†
        self.executor = ThreadPoolExecutor(max_workers=2, thread_name_prefix="LogWorker")
        
        # æ–‡ä»¶å¥æŸ„ç¼“å­˜
        self.file_handlers = {}
        self.handler_locks = {}
        
        # æ§åˆ¶æ ‡å¿—
        self.is_running = True
        self.flush_thread = None
        
        # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
        self._setup_logging()
        self._start_flush_thread()
        
        # æ³¨å†Œæ¸…ç†å‡½æ•°
        import atexit
        atexit.register(self.shutdown)
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        # é…ç½®loguru
        loguru_logger.remove()  # ç§»é™¤é»˜è®¤å¤„ç†å™¨
        
        if self.config.console_output:
            loguru_logger.add(
                sys.stdout,
                format="<green>{time:HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> | <level>{message}</level>",
                level="DEBUG",
                colorize=True
            )
        
        # åˆ›å»ºåˆ†ç±»æ—¥å¿—æ–‡ä»¶
        for category in LogCategory:
            log_file = self.log_dir / f"{category.value.lower()}.log"
            self.file_handlers[category.value] = log_file
            self.handler_locks[category.value] = threading.Lock()
    
    def _start_flush_thread(self):
        """å¯åŠ¨æ—¥å¿—åˆ·æ–°çº¿ç¨‹"""
        def flush_worker():
            while self.is_running:
                try:
                    self._flush_buffer()
                    time.sleep(self.config.flush_interval)
                except Exception as e:
                    print(f"æ—¥å¿—åˆ·æ–°çº¿ç¨‹å¼‚å¸¸: {e}")
        
        self.flush_thread = threading.Thread(
            target=flush_worker,
            daemon=True,
            name="LogFlushThread"
        )
        self.flush_thread.start()
    
    def _flush_buffer(self):
        """åˆ·æ–°æ—¥å¿—ç¼“å†²åŒº"""
        entries = self.buffer.get_all()
        if not entries:
            return
        
        # æŒ‰åˆ†ç±»åˆ†ç»„
        categorized_entries = {}
        for entry in entries:
            category = entry.category
            if category not in categorized_entries:
                categorized_entries[category] = []
            categorized_entries[category].append(entry)
        
        # å†™å…¥æ–‡ä»¶
        for category, category_entries in categorized_entries.items():
            self._write_to_file(category, category_entries)
    
    def _write_to_file(self, category: str, entries: List[LogEntry]):
        """å†™å…¥æ—¥å¿—æ–‡ä»¶"""
        if not self.config.file_output:
            return
        
        log_file = self.file_handlers.get(category)
        if not log_file:
            return
        
        lock = self.handler_locks.get(category)
        if not lock:
            return
        
        with lock:
            try:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦è½®è½¬
                if self.rotator.should_rotate(log_file):
                    self.rotator.rotate_file(log_file)
                
                # å†™å…¥æ—¥å¿—
                with open(log_file, 'a', encoding='utf-8') as f:
                    for entry in entries:
                        if self.config.json_format:
                            line = self.formatter.format_json(entry)
                        else:
                            line = self.formatter.format_text(entry)
                        f.write(line + '\n')
                    f.flush()
                    
            except Exception as e:
                print(f"å†™å…¥æ—¥å¿—æ–‡ä»¶å¤±è´¥ {log_file}: {e}")
    
    def _get_caller_info(self) -> tuple:
        """è·å–è°ƒç”¨è€…ä¿¡æ¯"""
        frame = sys._getframe(3)  # è·³è¿‡è£…é¥°å™¨å’Œæ—¥å¿—æ–¹æ³•
        return (
            frame.f_code.co_filename.split('/')[-1],  # æ¨¡å—å
            frame.f_code.co_name,                     # å‡½æ•°å
            frame.f_lineno                            # è¡Œå·
        )
    
    def _create_log_entry(
        self,
        level: LogLevel,
        category: LogCategory,
        message: str,
        extra_data: Dict[str, Any] = None,
        trace_id: str = None,
        user_id: str = None,
        session_id: str = None,
        request_id: str = None,
        execution_time: float = None
    ) -> LogEntry:
        """åˆ›å»ºæ—¥å¿—æ¡ç›®"""
        module, function, line = self._get_caller_info()
        
        # è·å–ç³»ç»Ÿèµ„æºä¿¡æ¯
        memory_usage = None
        cpu_usage = None
        
        if self.config.enable_performance_logging:
            try:
                import psutil
                process = psutil.Process()
                memory_usage = process.memory_info().rss
                cpu_usage = process.cpu_percent()
            except:
                pass
        
        return LogEntry(
            timestamp=datetime.now().isoformat(),
            level=level.value,
            category=category.value,
            module=module,
            function=function,
            line=line,
            message=message,
            extra_data=extra_data or {},
            trace_id=trace_id,
            user_id=user_id,
            session_id=session_id,
            request_id=request_id,
            execution_time=execution_time,
            memory_usage=memory_usage,
            cpu_usage=cpu_usage
        )
    
    def log(
        self,
        level: LogLevel,
        category: LogCategory,
        message: str,
        extra_data: Dict[str, Any] = None,
        **kwargs
    ):
        """è®°å½•æ—¥å¿—"""
        try:
            log_entry = self._create_log_entry(
                level=level,
                category=category,
                message=message,
                extra_data=extra_data,
                **kwargs
            )
            
            # æ·»åŠ åˆ°ç¼“å†²åŒº
            self.buffer.add(log_entry)
            
            # æ§åˆ¶å°è¾“å‡º
            if self.config.console_output:
                console_msg = self.formatter.format_console(log_entry)
                print(console_msg)
            
            # å…³é”®æ—¥å¿—ç«‹å³åˆ·æ–°
            if level in [LogLevel.ERROR, LogLevel.CRITICAL]:
                self.executor.submit(self._flush_buffer)
                
        except Exception as e:
            print(f"æ—¥å¿—è®°å½•å¤±è´¥: {e}")
    
    # ä¾¿æ·æ–¹æ³•
    def trace(self, message: str, category: LogCategory = LogCategory.SYSTEM, **kwargs):
        """è®°å½•TRACEçº§åˆ«æ—¥å¿—"""
        self.log(LogLevel.TRACE, category, message, **kwargs)
    
    def debug(self, message: str, category: LogCategory = LogCategory.SYSTEM, **kwargs):
        """è®°å½•DEBUGçº§åˆ«æ—¥å¿—"""
        self.log(LogLevel.DEBUG, category, message, **kwargs)
    
    def info(self, message: str, category: LogCategory = LogCategory.SYSTEM, **kwargs):
        """è®°å½•INFOçº§åˆ«æ—¥å¿—"""
        self.log(LogLevel.INFO, category, message, **kwargs)
    
    def success(self, message: str, category: LogCategory = LogCategory.SYSTEM, **kwargs):
        """è®°å½•SUCCESSçº§åˆ«æ—¥å¿—"""
        self.log(LogLevel.SUCCESS, category, message, **kwargs)
    
    def warning(self, message: str, category: LogCategory = LogCategory.SYSTEM, **kwargs):
        """è®°å½•WARNINGçº§åˆ«æ—¥å¿—"""
        self.log(LogLevel.WARNING, category, message, **kwargs)
    
    def error(self, message: str, category: LogCategory = LogCategory.SYSTEM, **kwargs):
        """è®°å½•ERRORçº§åˆ«æ—¥å¿—"""
        # è‡ªåŠ¨æ·»åŠ å¼‚å¸¸ä¿¡æ¯
        if 'extra_data' not in kwargs:
            kwargs['extra_data'] = {}
        
        if self.config.include_trace:
            kwargs['extra_data']['traceback'] = traceback.format_exc()
        
        self.log(LogLevel.ERROR, category, message, **kwargs)
    
    def critical(self, message: str, category: LogCategory = LogCategory.SYSTEM, **kwargs):
        """è®°å½•CRITICALçº§åˆ«æ—¥å¿—"""
        # è‡ªåŠ¨æ·»åŠ å¼‚å¸¸ä¿¡æ¯
        if 'extra_data' not in kwargs:
            kwargs['extra_data'] = {}
        
        if self.config.include_trace:
            kwargs['extra_data']['traceback'] = traceback.format_exc()
        
        self.log(LogLevel.CRITICAL, category, message, **kwargs)
    
    # ç‰¹æ®Šæ—¥å¿—æ–¹æ³•
    def trading_log(self, message: str, level: LogLevel = LogLevel.INFO, **kwargs):
        """äº¤æ˜“æ—¥å¿—"""
        self.log(level, LogCategory.TRADING, message, **kwargs)
    
    def risk_log(self, message: str, level: LogLevel = LogLevel.WARNING, **kwargs):
        """é£é™©æ—¥å¿—"""
        self.log(level, LogCategory.RISK, message, **kwargs)
    
    def performance_log(self, message: str, execution_time: float = None, **kwargs):
        """æ€§èƒ½æ—¥å¿—"""
        self.log(LogLevel.INFO, LogCategory.PERFORMANCE, message, execution_time=execution_time, **kwargs)
    
    def security_log(self, message: str, level: LogLevel = LogLevel.WARNING, **kwargs):
        """å®‰å…¨æ—¥å¿—"""
        self.log(level, LogCategory.SECURITY, message, **kwargs)
    
    def audit_log(self, message: str, user_id: str = None, **kwargs):
        """å®¡è®¡æ—¥å¿—"""
        if not self.config.enable_audit_logging:
            return
        self.log(LogLevel.INFO, LogCategory.AUDIT, message, user_id=user_id, **kwargs)
    
    def alert_log(self, message: str, level: LogLevel = LogLevel.ERROR, **kwargs):
        """å‘Šè­¦æ—¥å¿—"""
        self.log(level, LogCategory.ALERT, message, **kwargs)
    
    # æ€§èƒ½è¿½è¸ªè£…é¥°å™¨
    def track_performance(self, category: LogCategory = LogCategory.PERFORMANCE):
        """æ€§èƒ½è¿½è¸ªè£…é¥°å™¨"""
        def decorator(func):
            def wrapper(*args, **kwargs):
                trace_id = f"{func.__name__}_{int(time.time() * 1000000)}"
                self.performance_tracker.start_tracking(trace_id)
                
                try:
                    result = func(*args, **kwargs)
                    execution_time = self.performance_tracker.end_tracking(trace_id)
                    
                    self.performance_log(
                        f"å‡½æ•° {func.__name__} æ‰§è¡Œå®Œæˆ",
                        execution_time=execution_time,
                        extra_data={
                            'function': func.__name__,
                            'args_count': len(args),
                            'kwargs_count': len(kwargs)
                        },
                        trace_id=trace_id
                    )
                    
                    return result
                    
                except Exception as e:
                    execution_time = self.performance_tracker.end_tracking(trace_id)
                    
                    self.error(
                        f"å‡½æ•° {func.__name__} æ‰§è¡Œå¼‚å¸¸: {str(e)}",
                        category=category,
                        execution_time=execution_time,
                        extra_data={
                            'function': func.__name__,
                            'exception': str(e),
                            'exception_type': type(e).__name__
                        },
                        trace_id=trace_id
                    )
                    raise
            
            return wrapper
        return decorator
    
    def get_log_stats(self) -> Dict[str, Any]:
        """è·å–æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'buffer_size': self.buffer.size(),
            'log_files': {},
            'system_info': {
                'log_dir': str(self.log_dir),
                'config': asdict(self.config),
                'is_running': self.is_running
            }
        }
        
        # ç»Ÿè®¡å„åˆ†ç±»æ—¥å¿—æ–‡ä»¶å¤§å°
        for category, log_file in self.file_handlers.items():
            if log_file.exists():
                stats['log_files'][category] = {
                    'size_bytes': log_file.stat().st_size,
                    'size_mb': round(log_file.stat().st_size / 1024 / 1024, 2),
                    'modified': datetime.fromtimestamp(log_file.stat().st_mtime).isoformat()
                }
        
        return stats
    
    def search_logs(
        self,
        category: str = None,
        level: str = None,
        start_time: datetime = None,
        end_time: datetime = None,
        keyword: str = None,
        limit: int = 100
    ) -> List[Dict[str, Any]]:
        """æœç´¢æ—¥å¿—"""
        results = []
        
        # ç¡®å®šè¦æœç´¢çš„æ–‡ä»¶
        if category:
            log_files = [self.file_handlers.get(category.upper())]
        else:
            log_files = list(self.file_handlers.values())
        
        for log_file in log_files:
            if not log_file or not log_file.exists():
                continue
            
            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        if len(results) >= limit:
                            break
                        
                        try:
                            if self.config.json_format:
                                log_data = json.loads(line.strip())
                            else:
                                # ç®€å•æ–‡æœ¬è§£æ
                                continue
                            
                            # è¿‡æ»¤æ¡ä»¶
                            if level and log_data.get('level') != level.upper():
                                continue
                            
                            if keyword and keyword.lower() not in log_data.get('message', '').lower():
                                continue
                            
                            if start_time or end_time:
                                log_time = datetime.fromisoformat(log_data.get('timestamp', ''))
                                if start_time and log_time < start_time:
                                    continue
                                if end_time and log_time > end_time:
                                    continue
                            
                            results.append(log_data)
                            
                        except (json.JSONDecodeError, ValueError):
                            continue
                            
            except Exception as e:
                self.error(f"æœç´¢æ—¥å¿—æ–‡ä»¶å¤±è´¥ {log_file}: {e}")
        
        return results
    
    def export_logs(
        self,
        output_file: str,
        category: str = None,
        start_time: datetime = None,
        end_time: datetime = None,
        format: str = 'json'
    ) -> bool:
        """å¯¼å‡ºæ—¥å¿—"""
        try:
            logs = self.search_logs(
                category=category,
                start_time=start_time,
                end_time=end_time,
                limit=10000
            )
            
            output_path = Path(output_file)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            
            if format.lower() == 'json':
                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(logs, f, ensure_ascii=False, indent=2, default=str)
            elif format.lower() == 'csv':
                import csv
                if logs:
                    with open(output_path, 'w', newline='', encoding='utf-8') as f:
                        writer = csv.DictWriter(f, fieldnames=logs[0].keys())
                        writer.writeheader()
                        writer.writerows(logs)
            
            self.info(f"æ—¥å¿—å¯¼å‡ºæˆåŠŸ: {output_file}, å…±{len(logs)}æ¡è®°å½•")
            return True
            
        except Exception as e:
            self.error(f"æ—¥å¿—å¯¼å‡ºå¤±è´¥: {e}")
            return False
    
    def cleanup_logs(self):
        """æ¸…ç†è¿‡æœŸæ—¥å¿—"""
        self.rotator.cleanup_old_logs()
    
    def shutdown(self):
        """å…³é—­æ—¥å¿—ç³»ç»Ÿ"""
        self.info("æ­£åœ¨å…³é—­ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ...")
        
        self.is_running = False
        
        # åˆ·æ–°å‰©ä½™æ—¥å¿—
        self._flush_buffer()
        
        # å…³é—­çº¿ç¨‹æ± 
        self.executor.shutdown(wait=True)
        
        # ç­‰å¾…åˆ·æ–°çº¿ç¨‹ç»“æŸ
        if self.flush_thread and self.flush_thread.is_alive():
            self.flush_thread.join(timeout=5)
        
        self.info("ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿå·²å…³é—­")


# å…¨å±€æ—¥å¿—å®ä¾‹
_global_logger = None


def get_logger(config: LogConfig = None) -> UnifiedLoggingSystem:
    """è·å–å…¨å±€æ—¥å¿—å®ä¾‹"""
    global _global_logger
    if _global_logger is None:
        _global_logger = UnifiedLoggingSystem(config)
    return _global_logger


def setup_logging(config: LogConfig = None) -> UnifiedLoggingSystem:
    """è®¾ç½®å…¨å±€æ—¥å¿—ç³»ç»Ÿ"""
    global _global_logger
    _global_logger = UnifiedLoggingSystem(config)
    return _global_logger


# ä¾¿æ·å‡½æ•°
def log_info(message: str, category: LogCategory = LogCategory.SYSTEM, **kwargs):
    """è®°å½•ä¿¡æ¯æ—¥å¿—"""
    get_logger().info(message, category, **kwargs)


def log_error(message: str, category: LogCategory = LogCategory.SYSTEM, **kwargs):
    """è®°å½•é”™è¯¯æ—¥å¿—"""
    get_logger().error(message, category, **kwargs)


def log_warning(message: str, category: LogCategory = LogCategory.SYSTEM, **kwargs):
    """è®°å½•è­¦å‘Šæ—¥å¿—"""
    get_logger().warning(message, category, **kwargs)


def log_trading(message: str, **kwargs):
    """è®°å½•äº¤æ˜“æ—¥å¿—"""
    get_logger().trading_log(message, **kwargs)


def log_risk(message: str, **kwargs):
    """è®°å½•é£é™©æ—¥å¿—"""
    get_logger().risk_log(message, **kwargs)


def log_performance(message: str, execution_time: float = None, **kwargs):
    """è®°å½•æ€§èƒ½æ—¥å¿—"""
    get_logger().performance_log(message, execution_time, **kwargs)


def track_performance(category: LogCategory = LogCategory.PERFORMANCE):
    """æ€§èƒ½è¿½è¸ªè£…é¥°å™¨"""
    return get_logger().track_performance(category)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    config = LogConfig(
        log_dir="test_logs",
        console_output=True,
        json_format=True
    )
    
    logger_system = UnifiedLoggingSystem(config)
    
    # æµ‹è¯•å„ç§æ—¥å¿—
    logger_system.info("ç³»ç»Ÿå¯åŠ¨", LogCategory.SYSTEM)
    logger_system.trading_log("å¼€å§‹äº¤æ˜“", extra_data={"symbol": "BTCUSDT", "price": 50000})
    logger_system.risk_log("é£é™©è­¦å‘Š", extra_data={"risk_score": 75})
    logger_system.performance_log("æ€§èƒ½æµ‹è¯•", execution_time=0.123)
    
    # æµ‹è¯•æ€§èƒ½è¿½è¸ªè£…é¥°å™¨
    @logger_system.track_performance(LogCategory.TRADING)
    def test_function():
        time.sleep(0.1)
        return "æµ‹è¯•å®Œæˆ"
    
    result = test_function()
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = logger_system.get_log_stats()
    print(f"æ—¥å¿—ç»Ÿè®¡: {json.dumps(stats, indent=2, ensure_ascii=False)}")
    
    # å…³é—­ç³»ç»Ÿ
    logger_system.shutdown()
