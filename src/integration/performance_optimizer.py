"""
ğŸ“Š æ€§èƒ½ç“¶é¢ˆä¼˜åŒ–ç³»ç»Ÿ
ç”Ÿäº§çº§ç³»ç»Ÿæ€§èƒ½åˆ†æå’Œä¼˜åŒ–ï¼Œå®ç°CPU/GPU/å†…å­˜/ç½‘ç»œå…¨æ–¹ä½ä¼˜åŒ–
æ”¯æŒæ•°æ®åº“æŸ¥è¯¢è°ƒä¼˜ã€å¹¶å‘å¤„ç†æå‡å’Œå®æ—¶æ€§èƒ½ç›‘æ§
"""

import asyncio
import time
import threading
import psutil
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Any, Tuple, Callable
from dataclasses import dataclass, field
from enum import Enum
from collections import deque
import json
import sqlite3
import redis
import gc
import sys
import os
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import multiprocessing as mp

from loguru import logger
from src.hardware.cpu_manager import CPUTaskType, assign_cpu_cores, get_cpu_usage
from src.hardware.gpu_manager import GPUTaskType, get_gpu_usage
from src.hardware.storage_manager import storage_manager


class OptimizationType(Enum):
    """ä¼˜åŒ–ç±»å‹"""
    CPU_OPTIMIZATION = "cpu_optimization"
    MEMORY_OPTIMIZATION = "memory_optimization"
    GPU_OPTIMIZATION = "gpu_optimization"
    DATABASE_OPTIMIZATION = "database_optimization"
    NETWORK_OPTIMIZATION = "network_optimization"
    CONCURRENCY_OPTIMIZATION = "concurrency_optimization"


class PerformanceLevel(Enum):
    """æ€§èƒ½ç­‰çº§"""
    CRITICAL = "critical"    # ä¸¥é‡æ€§èƒ½é—®é¢˜
    WARNING = "warning"      # æ€§èƒ½è­¦å‘Š
    NORMAL = "normal"        # æ­£å¸¸æ€§èƒ½
    OPTIMAL = "optimal"      # æœ€ä¼˜æ€§èƒ½


@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    timestamp: float
    cpu_usage: float
    cpu_frequency: float
    memory_usage: float
    memory_available: float
    gpu_usage: float
    gpu_memory_usage: float
    disk_io_read: float
    disk_io_write: float
    network_io_sent: float
    network_io_recv: float
    active_threads: int
    active_processes: int
    database_connections: int
    cache_hit_rate: float
    response_time_ms: float
    throughput_ops: float


@dataclass
class OptimizationResult:
    """ä¼˜åŒ–ç»“æœ"""
    optimization_type: OptimizationType
    before_metrics: PerformanceMetrics
    after_metrics: PerformanceMetrics
    improvement_percentage: float
    optimization_actions: List[str]
    success: bool
    error_message: Optional[str] = None
    timestamp: float = field(default_factory=time.time)


@dataclass
class BottleneckAnalysis:
    """ç“¶é¢ˆåˆ†æ"""
    component: str
    severity: PerformanceLevel
    current_usage: float
    threshold: float
    impact_score: float
    recommendations: List[str]
    estimated_improvement: float


class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        # æ€§èƒ½ç›‘æ§
        self.metrics_history: deque = deque(maxlen=1000)
        self.optimization_history: List[OptimizationResult] = []
        
        # æ€§èƒ½é˜ˆå€¼é…ç½®
        self.performance_thresholds = {
            'cpu_usage': 80.0,           # CPUä½¿ç”¨ç‡é˜ˆå€¼
            'memory_usage': 85.0,        # å†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼
            'gpu_usage': 90.0,           # GPUä½¿ç”¨ç‡é˜ˆå€¼
            'disk_io': 100.0,            # ç£ç›˜IOé˜ˆå€¼(MB/s)
            'network_latency': 50.0,     # ç½‘ç»œå»¶è¿Ÿé˜ˆå€¼(ms)
            'response_time': 100.0,      # å“åº”æ—¶é—´é˜ˆå€¼(ms)
            'cache_hit_rate': 0.8        # ç¼“å­˜å‘½ä¸­ç‡é˜ˆå€¼
        }
        
        # ä¼˜åŒ–é…ç½®
        self.optimization_enabled = True
        self.auto_optimization = True
        self.optimization_interval = 60.0  # ä¼˜åŒ–æ£€æŸ¥é—´éš”(ç§’)
        
        # çº¿ç¨‹æ± 
        self.thread_pool = ThreadPoolExecutor(max_workers=4)
        self.process_pool = ProcessPoolExecutor(max_workers=2)
        
        # åˆ†é…CPUæ ¸å¿ƒ
        assign_cpu_cores(CPUTaskType.PERFORMANCE_OPTIMIZATION, [17, 18])
        
        # å¯åŠ¨æ€§èƒ½ç›‘æ§
        self.monitoring_active = False
        self._start_performance_monitoring()
        
        logger.info("æ€§èƒ½ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _start_performance_monitoring(self):
        """å¯åŠ¨æ€§èƒ½ç›‘æ§"""
        self.monitoring_active = True
        
        def monitor_performance():
            while self.monitoring_active:
                try:
                    asyncio.run(self._collect_performance_metrics())
                    
                    # è‡ªåŠ¨ä¼˜åŒ–æ£€æŸ¥
                    if self.auto_optimization:
                        asyncio.run(self._check_and_optimize())
                    
                    time.sleep(self.optimization_interval)
                    
                except Exception as e:
                    logger.error(f"æ€§èƒ½ç›‘æ§å‡ºé”™: {e}")
                    time.sleep(5)
        
        monitor_thread = threading.Thread(target=monitor_performance, daemon=True)
        monitor_thread.start()
        
        logger.info("æ€§èƒ½ç›‘æ§å·²å¯åŠ¨")
    
    async def _collect_performance_metrics(self) -> PerformanceMetrics:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        try:
            # CPUæŒ‡æ ‡
            cpu_usage = psutil.cpu_percent(interval=1)
            cpu_freq = psutil.cpu_freq()
            cpu_frequency = cpu_freq.current if cpu_freq else 0
            
            # å†…å­˜æŒ‡æ ‡
            memory = psutil.virtual_memory()
            memory_usage = memory.percent
            memory_available = memory.available / (1024**3)  # GB
            
            # GPUæŒ‡æ ‡
            gpu_usage = 0.0
            gpu_memory_usage = 0.0
            try:
                import GPUtil
                gpus = GPUtil.getGPUs()
                if gpus:
                    gpu_usage = gpus[0].load * 100
                    gpu_memory_usage = gpus[0].memoryUtil * 100
            except:
                pass
            
            # ç£ç›˜IOæŒ‡æ ‡
            disk_io = psutil.disk_io_counters()
            disk_io_read = disk_io.read_bytes / (1024**2) if disk_io else 0  # MB/s
            disk_io_write = disk_io.write_bytes / (1024**2) if disk_io else 0  # MB/s
            
            # ç½‘ç»œIOæŒ‡æ ‡
            network_io = psutil.net_io_counters()
            network_io_sent = network_io.bytes_sent / (1024**2) if network_io else 0  # MB/s
            network_io_recv = network_io.bytes_recv / (1024**2) if network_io else 0  # MB/s
            
            # è¿›ç¨‹å’Œçº¿ç¨‹æ•°
            active_processes = len(psutil.pids())
            active_threads = sum(p.num_threads() for p in psutil.process_iter(['num_threads']) 
                               if p.info['num_threads'])
            
            # æ•°æ®åº“è¿æ¥æ•° (ç®€åŒ–)
            database_connections = self._get_database_connections()
            
            # ç¼“å­˜å‘½ä¸­ç‡ (ç®€åŒ–)
            cache_hit_rate = self._get_cache_hit_rate()
            
            # å“åº”æ—¶é—´å’Œååé‡ (ä»å†å²æ•°æ®è®¡ç®—)
            response_time_ms = self._calculate_avg_response_time()
            throughput_ops = self._calculate_throughput()
            
            metrics = PerformanceMetrics(
                timestamp=time.time(),
                cpu_usage=cpu_usage,
                cpu_frequency=cpu_frequency,
                memory_usage=memory_usage,
                memory_available=memory_available,
                gpu_usage=gpu_usage,
                gpu_memory_usage=gpu_memory_usage,
                disk_io_read=disk_io_read,
                disk_io_write=disk_io_write,
                network_io_sent=network_io_sent,
                network_io_recv=network_io_recv,
                active_threads=active_threads,
                active_processes=active_processes,
                database_connections=database_connections,
                cache_hit_rate=cache_hit_rate,
                response_time_ms=response_time_ms,
                throughput_ops=throughput_ops
            )
            
            self.metrics_history.append(metrics)
            return metrics
            
        except Exception as e:
            logger.error(f"æ”¶é›†æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
            return None
    
    def _get_database_connections(self) -> int:
        """è·å–æ•°æ®åº“è¿æ¥æ•°"""
        try:
            # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æŸ¥è¯¢å…·ä½“æ•°æ®åº“
            return 10  # æ¨¡æ‹Ÿè¿æ¥æ•°
        except:
            return 0
    
    def _get_cache_hit_rate(self) -> float:
        """è·å–ç¼“å­˜å‘½ä¸­ç‡"""
        try:
            # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥æŸ¥è¯¢Redisç­‰ç¼“å­˜ç³»ç»Ÿ
            return 0.85  # æ¨¡æ‹Ÿ85%å‘½ä¸­ç‡
        except:
            return 0.0
    
    def _calculate_avg_response_time(self) -> float:
        """è®¡ç®—å¹³å‡å“åº”æ—¶é—´"""
        if len(self.metrics_history) < 2:
            return 0.0
        
        # ä»å†å²æŒ‡æ ‡è®¡ç®—
        recent_metrics = list(self.metrics_history)[-10:]
        response_times = [m.response_time_ms for m in recent_metrics if m.response_time_ms > 0]
        
        return np.mean(response_times) if response_times else 50.0  # é»˜è®¤50ms
    
    def _calculate_throughput(self) -> float:
        """è®¡ç®—ååé‡"""
        if len(self.metrics_history) < 2:
            return 0.0
        
        # ç®€åŒ–è®¡ç®—
        return 100.0  # é»˜è®¤100 ops/s
    
    async def _check_and_optimize(self):
        """æ£€æŸ¥å¹¶æ‰§è¡Œä¼˜åŒ–"""
        try:
            if not self.metrics_history:
                return
            
            latest_metrics = self.metrics_history[-1]
            
            # åˆ†æç“¶é¢ˆ
            bottlenecks = self.analyze_bottlenecks(latest_metrics)
            
            # æ‰§è¡Œä¼˜åŒ–
            for bottleneck in bottlenecks:
                if bottleneck.severity in [PerformanceLevel.CRITICAL, PerformanceLevel.WARNING]:
                    await self._execute_optimization(bottleneck)
            
        except Exception as e:
            logger.error(f"è‡ªåŠ¨ä¼˜åŒ–æ£€æŸ¥å¤±è´¥: {e}")
    
    def analyze_bottlenecks(self, metrics: PerformanceMetrics) -> List[BottleneckAnalysis]:
        """åˆ†ææ€§èƒ½ç“¶é¢ˆ"""
        bottlenecks = []
        
        try:
            # CPUç“¶é¢ˆåˆ†æ
            if metrics.cpu_usage > self.performance_thresholds['cpu_usage']:
                severity = PerformanceLevel.CRITICAL if metrics.cpu_usage > 95 else PerformanceLevel.WARNING
                bottlenecks.append(BottleneckAnalysis(
                    component="CPU",
                    severity=severity,
                    current_usage=metrics.cpu_usage,
                    threshold=self.performance_thresholds['cpu_usage'],
                    impact_score=metrics.cpu_usage / 100.0,
                    recommendations=[
                        "ä¼˜åŒ–CPUå¯†é›†å‹ç®—æ³•",
                        "å¢åŠ CPUæ ¸å¿ƒåˆ†é…",
                        "ä½¿ç”¨å¼‚æ­¥å¤„ç†",
                        "å¯ç”¨CPUç¼“å­˜ä¼˜åŒ–"
                    ],
                    estimated_improvement=15.0
                ))
            
            # å†…å­˜ç“¶é¢ˆåˆ†æ
            if metrics.memory_usage > self.performance_thresholds['memory_usage']:
                severity = PerformanceLevel.CRITICAL if metrics.memory_usage > 95 else PerformanceLevel.WARNING
                bottlenecks.append(BottleneckAnalysis(
                    component="Memory",
                    severity=severity,
                    current_usage=metrics.memory_usage,
                    threshold=self.performance_thresholds['memory_usage'],
                    impact_score=metrics.memory_usage / 100.0,
                    recommendations=[
                        "æ‰§è¡Œåƒåœ¾å›æ”¶",
                        "ä¼˜åŒ–å†…å­˜åˆ†é…",
                        "æ¸…ç†æ— ç”¨å¯¹è±¡",
                        "å¯ç”¨å†…å­˜å‹ç¼©"
                    ],
                    estimated_improvement=20.0
                ))
            
            # GPUç“¶é¢ˆåˆ†æ
            if metrics.gpu_usage > self.performance_thresholds['gpu_usage']:
                severity = PerformanceLevel.WARNING
                bottlenecks.append(BottleneckAnalysis(
                    component="GPU",
                    severity=severity,
                    current_usage=metrics.gpu_usage,
                    threshold=self.performance_thresholds['gpu_usage'],
                    impact_score=metrics.gpu_usage / 100.0,
                    recommendations=[
                        "ä¼˜åŒ–GPUè®¡ç®—ä»»åŠ¡",
                        "è°ƒæ•´æ‰¹å¤„ç†å¤§å°",
                        "ä½¿ç”¨GPUå†…å­˜æ± ",
                        "å¯ç”¨æ··åˆç²¾åº¦è®¡ç®—"
                    ],
                    estimated_improvement=10.0
                ))
            
            # å“åº”æ—¶é—´ç“¶é¢ˆåˆ†æ
            if metrics.response_time_ms > self.performance_thresholds['response_time']:
                severity = PerformanceLevel.WARNING
                bottlenecks.append(BottleneckAnalysis(
                    component="Response Time",
                    severity=severity,
                    current_usage=metrics.response_time_ms,
                    threshold=self.performance_thresholds['response_time'],
                    impact_score=min(metrics.response_time_ms / 1000.0, 1.0),
                    recommendations=[
                        "ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢",
                        "å¯ç”¨æŸ¥è¯¢ç¼“å­˜",
                        "å‡å°‘ç½‘ç»œå¾€è¿”",
                        "ä½¿ç”¨è¿æ¥æ± "
                    ],
                    estimated_improvement=25.0
                ))
            
            # ç¼“å­˜å‘½ä¸­ç‡åˆ†æ
            if metrics.cache_hit_rate < self.performance_thresholds['cache_hit_rate']:
                severity = PerformanceLevel.WARNING
                bottlenecks.append(BottleneckAnalysis(
                    component="Cache",
                    severity=severity,
                    current_usage=metrics.cache_hit_rate * 100,
                    threshold=self.performance_thresholds['cache_hit_rate'] * 100,
                    impact_score=1.0 - metrics.cache_hit_rate,
                    recommendations=[
                        "ä¼˜åŒ–ç¼“å­˜ç­–ç•¥",
                        "å¢åŠ ç¼“å­˜å®¹é‡",
                        "è°ƒæ•´ç¼“å­˜è¿‡æœŸæ—¶é—´",
                        "é¢„çƒ­å…³é”®æ•°æ®"
                    ],
                    estimated_improvement=30.0
                ))
            
            return bottlenecks
            
        except Exception as e:
            logger.error(f"åˆ†ææ€§èƒ½ç“¶é¢ˆå¤±è´¥: {e}")
            return []
    
    async def _execute_optimization(self, bottleneck: BottleneckAnalysis):
        """æ‰§è¡Œä¼˜åŒ–"""
        try:
            logger.info(f"æ‰§è¡Œ{bottleneck.component}ä¼˜åŒ–ï¼Œä¸¥é‡ç¨‹åº¦: {bottleneck.severity.value}")
            
            before_metrics = self.metrics_history[-1] if self.metrics_history else None
            
            if bottleneck.component == "CPU":
                await self._optimize_cpu()
            elif bottleneck.component == "Memory":
                await self._optimize_memory()
            elif bottleneck.component == "GPU":
                await self._optimize_gpu()
            elif bottleneck.component == "Response Time":
                await self._optimize_response_time()
            elif bottleneck.component == "Cache":
                await self._optimize_cache()
            
            # ç­‰å¾…ä¼˜åŒ–ç”Ÿæ•ˆ
            await asyncio.sleep(5)
            
            # æ”¶é›†ä¼˜åŒ–åæŒ‡æ ‡
            after_metrics = await self._collect_performance_metrics()
            
            if before_metrics and after_metrics:
                # è®¡ç®—æ”¹å–„ç¨‹åº¦
                improvement = self._calculate_improvement(before_metrics, after_metrics, bottleneck.component)
                
                # è®°å½•ä¼˜åŒ–ç»“æœ
                result = OptimizationResult(
                    optimization_type=self._get_optimization_type(bottleneck.component),
                    before_metrics=before_metrics,
                    after_metrics=after_metrics,
                    improvement_percentage=improvement,
                    optimization_actions=bottleneck.recommendations,
                    success=improvement > 0
                )
                
                self.optimization_history.append(result)
                
                logger.info(f"{bottleneck.component}ä¼˜åŒ–å®Œæˆï¼Œæ”¹å–„: {improvement:.1f}%")
            
        except Exception as e:
            logger.error(f"æ‰§è¡Œä¼˜åŒ–å¤±è´¥: {e}")
    
    async def _optimize_cpu(self):
        """CPUä¼˜åŒ–"""
        try:
            # 1. åƒåœ¾å›æ”¶
            gc.collect()
            
            # 2. è°ƒæ•´è¿›ç¨‹ä¼˜å…ˆçº§
            current_process = psutil.Process()
            try:
                current_process.nice(-5)  # æé«˜ä¼˜å…ˆçº§
            except:
                pass
            
            # 3. ä¼˜åŒ–CPUäº²å’Œæ€§
            try:
                cpu_count = psutil.cpu_count()
                if cpu_count >= 4:
                    # ç»‘å®šåˆ°æ€§èƒ½æ ¸å¿ƒ
                    current_process.cpu_affinity([0, 1, 2, 3])
            except:
                pass
            
            logger.info("CPUä¼˜åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"CPUä¼˜åŒ–å¤±è´¥: {e}")
    
    async def _optimize_memory(self):
        """å†…å­˜ä¼˜åŒ–"""
        try:
            # 1. å¼ºåˆ¶åƒåœ¾å›æ”¶
            for i in range(3):
                gc.collect()
                await asyncio.sleep(0.1)
            
            # 2. æ¸…ç†Pythonå†…éƒ¨ç¼“å­˜
            sys.intern.__dict__.clear()
            
            # 3. ä¼˜åŒ–å†…å­˜åˆ†é…
            try:
                import ctypes
                libc = ctypes.CDLL("libc.so.6")
                libc.malloc_trim(0)  # é‡Šæ”¾æœªä½¿ç”¨çš„å†…å­˜
            except:
                pass
            
            logger.info("å†…å­˜ä¼˜åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"å†…å­˜ä¼˜åŒ–å¤±è´¥: {e}")
    
    async def _optimize_gpu(self):
        """GPUä¼˜åŒ–"""
        try:
            # 1. æ¸…ç†GPUå†…å­˜
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
            except:
                pass
            
            # 2. ä¼˜åŒ–GPUå†…å­˜åˆ†é…
            try:
                import cupy
                cupy.get_default_memory_pool().free_all_blocks()
            except:
                pass
            
            logger.info("GPUä¼˜åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"GPUä¼˜åŒ–å¤±è´¥: {e}")
    
    async def _optimize_response_time(self):
        """å“åº”æ—¶é—´ä¼˜åŒ–"""
        try:
            # 1. ä¼˜åŒ–æ•°æ®åº“è¿æ¥æ± 
            # å®é™…åº”è¯¥è°ƒç”¨å…·ä½“çš„æ•°æ®åº“ä¼˜åŒ–
            
            # 2. æ¸…ç†è¿‡æœŸè¿æ¥
            # å®é™…åº”è¯¥æ¸…ç†HTTPè¿æ¥æ± 
            
            # 3. é¢„çƒ­å…³é”®æ•°æ®
            # å®é™…åº”è¯¥é¢„åŠ è½½å¸¸ç”¨æ•°æ®
            
            logger.info("å“åº”æ—¶é—´ä¼˜åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"å“åº”æ—¶é—´ä¼˜åŒ–å¤±è´¥: {e}")
    
    async def _optimize_cache(self):
        """ç¼“å­˜ä¼˜åŒ–"""
        try:
            # 1. æ¸…ç†è¿‡æœŸç¼“å­˜
            # å®é™…åº”è¯¥è¿æ¥Redisç­‰ç¼“å­˜ç³»ç»Ÿ
            
            # 2. é¢„çƒ­å…³é”®ç¼“å­˜
            # å®é™…åº”è¯¥é¢„åŠ è½½çƒ­ç‚¹æ•°æ®
            
            # 3. è°ƒæ•´ç¼“å­˜ç­–ç•¥
            # å®é™…åº”è¯¥ä¼˜åŒ–ç¼“å­˜ç®—æ³•
            
            logger.info("ç¼“å­˜ä¼˜åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"ç¼“å­˜ä¼˜åŒ–å¤±è´¥: {e}")
    
    def _get_optimization_type(self, component: str) -> OptimizationType:
        """è·å–ä¼˜åŒ–ç±»å‹"""
        mapping = {
            "CPU": OptimizationType.CPU_OPTIMIZATION,
            "Memory": OptimizationType.MEMORY_OPTIMIZATION,
            "GPU": OptimizationType.GPU_OPTIMIZATION,
            "Response Time": OptimizationType.DATABASE_OPTIMIZATION,
            "Cache": OptimizationType.DATABASE_OPTIMIZATION
        }
        return mapping.get(component, OptimizationType.CPU_OPTIMIZATION)
    
    def _calculate_improvement(self, before: PerformanceMetrics, after: PerformanceMetrics, 
                              component: str) -> float:
        """è®¡ç®—æ”¹å–„ç¨‹åº¦"""
        try:
            if component == "CPU":
                if before.cpu_usage > 0:
                    return max(0, (before.cpu_usage - after.cpu_usage) / before.cpu_usage * 100)
            elif component == "Memory":
                if before.memory_usage > 0:
                    return max(0, (before.memory_usage - after.memory_usage) / before.memory_usage * 100)
            elif component == "GPU":
                if before.gpu_usage > 0:
                    return max(0, (before.gpu_usage - after.gpu_usage) / before.gpu_usage * 100)
            elif component == "Response Time":
                if before.response_time_ms > 0:
                    return max(0, (before.response_time_ms - after.response_time_ms) / before.response_time_ms * 100)
            elif component == "Cache":
                return max(0, (after.cache_hit_rate - before.cache_hit_rate) * 100)
            
            return 0.0
            
        except Exception as e:
            logger.error(f"è®¡ç®—æ”¹å–„ç¨‹åº¦å¤±è´¥: {e}")
            return 0.0
    
    def get_performance_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š"""
        if not self.metrics_history:
            return {"message": "æ²¡æœ‰æ€§èƒ½æ•°æ®"}
        
        latest_metrics = self.metrics_history[-1]
        recent_metrics = list(self.metrics_history)[-10:]  # æœ€è¿‘10ä¸ªæŒ‡æ ‡
        
        # è®¡ç®—å¹³å‡å€¼
        avg_cpu = np.mean([m.cpu_usage for m in recent_metrics])
        avg_memory = np.mean([m.memory_usage for m in recent_metrics])
        avg_gpu = np.mean([m.gpu_usage for m in recent_metrics])
        avg_response_time = np.mean([m.response_time_ms for m in recent_metrics])
        
        # åˆ†æç“¶é¢ˆ
        bottlenecks = self.analyze_bottlenecks(latest_metrics)
        
        # ä¼˜åŒ–å†å²ç»Ÿè®¡
        total_optimizations = len(self.optimization_history)
        successful_optimizations = sum(1 for opt in self.optimization_history if opt.success)
        
        return {
            'current_performance': {
                'cpu_usage': latest_metrics.cpu_usage,
                'memory_usage': latest_metrics.memory_usage,
                'gpu_usage': latest_metrics.gpu_usage,
                'response_time_ms': latest_metrics.response_time_ms,
                'cache_hit_rate': latest_metrics.cache_hit_rate,
                'throughput_ops': latest_metrics.throughput_ops
            },
            'average_performance': {
                'cpu_usage': avg_cpu,
                'memory_usage': avg_memory,
                'gpu_usage': avg_gpu,
                'response_time_ms': avg_response_time
            },
            'bottlenecks': [
                {
                    'component': b.component,
                    'severity': b.severity.value,
                    'current_usage': b.current_usage,
                    'threshold': b.threshold,
                    'impact_score': b.impact_score,
                    'recommendations': b.recommendations
                }
                for b in bottlenecks
            ],
            'optimization_summary': {
                'total_optimizations': total_optimizations,
                'successful_optimizations': successful_optimizations,
                'success_rate': successful_optimizations / total_optimizations if total_optimizations > 0 else 0,
                'recent_optimizations': [
                    {
                        'type': opt.optimization_type.value,
                        'improvement': opt.improvement_percentage,
                        'success': opt.success,
                        'timestamp': opt.timestamp
                    }
                    for opt in self.optimization_history[-5:]  # æœ€è¿‘5æ¬¡ä¼˜åŒ–
                ]
            },
            'system_health': self._assess_system_health(latest_metrics),
            'timestamp': time.time()
        }
    
    def _assess_system_health(self, metrics: PerformanceMetrics) -> str:
        """è¯„ä¼°ç³»ç»Ÿå¥åº·çŠ¶å†µ"""
        issues = 0
        
        if metrics.cpu_usage > 90:
            issues += 2
        elif metrics.cpu_usage > 80:
            issues += 1
        
        if metrics.memory_usage > 90:
            issues += 2
        elif metrics.memory_usage > 85:
            issues += 1
        
        if metrics.response_time_ms > 200:
            issues += 2
        elif metrics.response_time_ms > 100:
            issues += 1
        
        if metrics.cache_hit_rate < 0.7:
            issues += 1
        
        if issues >= 4:
            return "critical"
        elif issues >= 2:
            return "warning"
        elif issues >= 1:
            return "fair"
        else:
            return "excellent"
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring_active = False
        self.thread_pool.shutdown(wait=False)
        self.process_pool.shutdown(wait=False)
        logger.info("æ€§èƒ½ä¼˜åŒ–å™¨å·²åœæ­¢")


# å…¨å±€æ€§èƒ½ä¼˜åŒ–å™¨å®ä¾‹
performance_optimizer = PerformanceOptimizer()


async def main():
    """æµ‹è¯•ä¸»å‡½æ•°"""
    logger.info("å¯åŠ¨æ€§èƒ½ä¼˜åŒ–å™¨æµ‹è¯•...")
    
    try:
        # è¿è¡Œæ€§èƒ½ç›‘æ§
        await asyncio.sleep(30)
        
        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        report = performance_optimizer.get_performance_report()
        
        logger.info("æ€§èƒ½æŠ¥å‘Š:")
        logger.info(json.dumps(report, indent=2))
        
    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·...")
    finally:
        performance_optimizer.stop_monitoring()


if __name__ == "__main__":
    asyncio.run(main())
