"""
ğŸ’» ç¡¬ä»¶æ€§èƒ½å®æ—¶ç›‘æ§ç³»ç»Ÿ
ç”Ÿäº§çº§ç¡¬ä»¶èµ„æºç›‘æ§ã€ä¼˜åŒ–å’ŒåŠ¨æ€è°ƒèŠ‚ç³»ç»Ÿ
æ”¯æŒ20æ ¸CPU + RTX3060 + 128GBå†…å­˜ + 1TB NVMeçš„æé™æ€§èƒ½é‡Šæ”¾
"""

import asyncio
import psutil
import platform
import threading
import time
import json
import logging
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, asdict
from pathlib import Path
import subprocess
import os
import signal

try:
    import GPUtil
    import pynvml
    GPU_AVAILABLE = True
except ImportError:
    GPU_AVAILABLE = False

from loguru import logger


@dataclass
class HardwareMetrics:
    """ç¡¬ä»¶æŒ‡æ ‡æ•°æ®ç»“æ„"""
    timestamp: float
    cpu_usage_percent: float
    cpu_frequency_mhz: float
    cpu_temperature: float
    cpu_cores_usage: List[float]
    
    memory_usage_percent: float
    memory_used_gb: float
    memory_available_gb: float
    memory_cached_gb: float
    
    gpu_usage_percent: float
    gpu_memory_usage_percent: float
    gpu_memory_used_gb: float
    gpu_temperature: float
    gpu_power_usage: float
    
    disk_usage_percent: float
    disk_read_mb_s: float
    disk_write_mb_s: float
    disk_free_gb: float
    
    network_sent_mb_s: float
    network_recv_mb_s: float


@dataclass
class PerformanceTargets:
    """æ€§èƒ½ç›®æ ‡é…ç½®"""
    cpu_usage_target: Tuple[float, float] = (85.0, 90.0)  # ç›®æ ‡ä½¿ç”¨ç‡èŒƒå›´
    cpu_temp_max: float = 80.0  # CPUæœ€é«˜æ¸©åº¦
    cpu_temp_warning: float = 75.0  # CPUè­¦å‘Šæ¸©åº¦
    
    gpu_usage_target: Tuple[float, float] = (90.0, 95.0)  # GPUç›®æ ‡ä½¿ç”¨ç‡
    gpu_temp_max: float = 75.0  # GPUæœ€é«˜æ¸©åº¦
    gpu_temp_warning: float = 70.0  # GPUè­¦å‘Šæ¸©åº¦
    
    memory_usage_target: Tuple[float, float] = (80.0, 85.0)  # å†…å­˜ç›®æ ‡ä½¿ç”¨ç‡
    disk_usage_max: float = 80.0  # ç£ç›˜æœ€å¤§ä½¿ç”¨ç‡
    disk_usage_warning: float = 75.0  # ç£ç›˜è­¦å‘Šä½¿ç”¨ç‡


class HardwarePerformanceMonitor:
    """ç¡¬ä»¶æ€§èƒ½å®æ—¶ç›‘æ§å™¨"""
    
    def __init__(self, config_path: Optional[str] = None):
        self.config_path = config_path or "config/hardware_config.json"
        self.targets = PerformanceTargets()
        self.monitoring = False
        self.metrics_history: List[HardwareMetrics] = []
        self.max_history_size = 3600  # ä¿ç•™1å°æ—¶çš„å†å²æ•°æ®
        
        # ç¡¬ä»¶ä¿¡æ¯
        self.cpu_cores = psutil.cpu_count(logical=True)
        self.memory_total = psutil.virtual_memory().total
        self.gpu_available = GPU_AVAILABLE
        
        # æ€§èƒ½è°ƒèŠ‚å‚æ•°
        self.cpu_frequency_step = 100  # MHz
        self.gpu_power_step = 5  # %
        
        # åˆå§‹åŒ–GPUç›‘æ§
        if self.gpu_available:
            try:
                pynvml.nvmlInit()
                self.gpu_count = pynvml.nvmlDeviceGetCount()
                logger.info(f"GPUç›‘æ§åˆå§‹åŒ–æˆåŠŸï¼Œæ£€æµ‹åˆ° {self.gpu_count} ä¸ªGPU")
            except Exception as e:
                logger.error(f"GPUç›‘æ§åˆå§‹åŒ–å¤±è´¥: {e}")
                self.gpu_available = False
        
        # åŸºå‡†æ€§èƒ½æ•°æ®
        self.baseline_metrics: Optional[HardwareMetrics] = None
        self.performance_adjustments = 0
        
        logger.info("ç¡¬ä»¶æ€§èƒ½ç›‘æ§å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def start_monitoring(self, interval: float = 1.0):
        """å¯åŠ¨ç¡¬ä»¶ç›‘æ§"""
        self.monitoring = True
        logger.info(f"å¼€å§‹ç¡¬ä»¶æ€§èƒ½ç›‘æ§ï¼Œç›‘æ§é—´éš”: {interval}ç§’")
        
        # è·å–åŸºå‡†æ€§èƒ½
        await self._establish_baseline()
        
        while self.monitoring:
            try:
                # æ”¶é›†ç¡¬ä»¶æŒ‡æ ‡
                metrics = await self._collect_hardware_metrics()
                
                # å­˜å‚¨å†å²æ•°æ®
                self._store_metrics(metrics)
                
                # æ€§èƒ½åˆ†æå’Œè°ƒèŠ‚
                await self._analyze_and_adjust_performance(metrics)
                
                # æ£€æŸ¥è­¦å‘Šæ¡ä»¶
                await self._check_warning_conditions(metrics)
                
                # ç­‰å¾…ä¸‹æ¬¡ç›‘æ§
                await asyncio.sleep(interval)
                
            except Exception as e:
                logger.error(f"ç¡¬ä»¶ç›‘æ§å¾ªç¯å‡ºé”™: {e}")
                await asyncio.sleep(interval)
    
    async def _establish_baseline(self):
        """å»ºç«‹åŸºå‡†æ€§èƒ½æ•°æ®"""
        logger.info("å»ºç«‹ç¡¬ä»¶æ€§èƒ½åŸºå‡†...")
        
        # æ”¶é›†5æ¬¡æ•°æ®å–å¹³å‡å€¼
        baseline_samples = []
        for _ in range(5):
            metrics = await self._collect_hardware_metrics()
            baseline_samples.append(metrics)
            await asyncio.sleep(1)
        
        # è®¡ç®—åŸºå‡†å€¼
        self.baseline_metrics = self._calculate_average_metrics(baseline_samples)
        logger.info("ç¡¬ä»¶æ€§èƒ½åŸºå‡†å»ºç«‹å®Œæˆ")
    
    def _calculate_average_metrics(self, metrics_list: List[HardwareMetrics]) -> HardwareMetrics:
        """è®¡ç®—å¹³å‡æŒ‡æ ‡"""
        if not metrics_list:
            raise ValueError("æŒ‡æ ‡åˆ—è¡¨ä¸èƒ½ä¸ºç©º")
        
        # è®¡ç®—å„é¡¹æŒ‡æ ‡çš„å¹³å‡å€¼
        avg_metrics = HardwareMetrics(
            timestamp=time.time(),
            cpu_usage_percent=sum(m.cpu_usage_percent for m in metrics_list) / len(metrics_list),
            cpu_frequency_mhz=sum(m.cpu_frequency_mhz for m in metrics_list) / len(metrics_list),
            cpu_temperature=sum(m.cpu_temperature for m in metrics_list) / len(metrics_list),
            cpu_cores_usage=[
                sum(m.cpu_cores_usage[i] for m in metrics_list) / len(metrics_list)
                for i in range(len(metrics_list[0].cpu_cores_usage))
            ],
            memory_usage_percent=sum(m.memory_usage_percent for m in metrics_list) / len(metrics_list),
            memory_used_gb=sum(m.memory_used_gb for m in metrics_list) / len(metrics_list),
            memory_available_gb=sum(m.memory_available_gb for m in metrics_list) / len(metrics_list),
            memory_cached_gb=sum(m.memory_cached_gb for m in metrics_list) / len(metrics_list),
            gpu_usage_percent=sum(m.gpu_usage_percent for m in metrics_list) / len(metrics_list),
            gpu_memory_usage_percent=sum(m.gpu_memory_usage_percent for m in metrics_list) / len(metrics_list),
            gpu_memory_used_gb=sum(m.gpu_memory_used_gb for m in metrics_list) / len(metrics_list),
            gpu_temperature=sum(m.gpu_temperature for m in metrics_list) / len(metrics_list),
            gpu_power_usage=sum(m.gpu_power_usage for m in metrics_list) / len(metrics_list),
            disk_usage_percent=sum(m.disk_usage_percent for m in metrics_list) / len(metrics_list),
            disk_read_mb_s=sum(m.disk_read_mb_s for m in metrics_list) / len(metrics_list),
            disk_write_mb_s=sum(m.disk_write_mb_s for m in metrics_list) / len(metrics_list),
            disk_free_gb=sum(m.disk_free_gb for m in metrics_list) / len(metrics_list),
            network_sent_mb_s=sum(m.network_sent_mb_s for m in metrics_list) / len(metrics_list),
            network_recv_mb_s=sum(m.network_recv_mb_s for m in metrics_list) / len(metrics_list),
        )
        
        return avg_metrics
    
    async def _collect_hardware_metrics(self) -> HardwareMetrics:
        """æ”¶é›†ç¡¬ä»¶æŒ‡æ ‡"""
        timestamp = time.time()
        
        # CPUæŒ‡æ ‡
        cpu_percent = psutil.cpu_percent(interval=0.1)
        cpu_freq = psutil.cpu_freq()
        cpu_frequency = cpu_freq.current if cpu_freq else 0
        cpu_cores_usage = psutil.cpu_percent(interval=0.1, percpu=True)
        cpu_temperature = await self._get_cpu_temperature()
        
        # å†…å­˜æŒ‡æ ‡
        memory = psutil.virtual_memory()
        memory_usage_percent = memory.percent
        memory_used_gb = memory.used / (1024**3)
        memory_available_gb = memory.available / (1024**3)
        memory_cached_gb = getattr(memory, 'cached', 0) / (1024**3)
        
        # GPUæŒ‡æ ‡
        gpu_usage = 0
        gpu_memory_usage = 0
        gpu_memory_used = 0
        gpu_temperature = 0
        gpu_power = 0
        
        if self.gpu_available and self.gpu_count > 0:
            try:
                handle = pynvml.nvmlDeviceGetHandleByIndex(0)  # ä½¿ç”¨ç¬¬ä¸€ä¸ªGPU
                
                # GPUä½¿ç”¨ç‡
                utilization = pynvml.nvmlDeviceGetUtilizationRates(handle)
                gpu_usage = utilization.gpu
                
                # GPUå†…å­˜
                memory_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
                gpu_memory_usage = (memory_info.used / memory_info.total) * 100
                gpu_memory_used = memory_info.used / (1024**3)
                
                # GPUæ¸©åº¦
                try:
                    gpu_temperature = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)
                except:
                    gpu_temperature = 0
                
                # GPUåŠŸè€—
                try:
                    gpu_power = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # mW to W
                except:
                    gpu_power = 0
                    
            except Exception as e:
                logger.warning(f"è·å–GPUæŒ‡æ ‡å¤±è´¥: {e}")
        
        # ç£ç›˜æŒ‡æ ‡
        disk_usage = psutil.disk_usage('/')
        disk_usage_percent = disk_usage.percent
        disk_free_gb = disk_usage.free / (1024**3)
        
        # ç£ç›˜I/O
        disk_io = psutil.disk_io_counters()
        if hasattr(self, '_last_disk_io'):
            time_delta = timestamp - self._last_disk_timestamp
            disk_read_mb_s = (disk_io.read_bytes - self._last_disk_io.read_bytes) / (1024**2) / time_delta
            disk_write_mb_s = (disk_io.write_bytes - self._last_disk_io.write_bytes) / (1024**2) / time_delta
        else:
            disk_read_mb_s = 0
            disk_write_mb_s = 0
        
        self._last_disk_io = disk_io
        self._last_disk_timestamp = timestamp
        
        # ç½‘ç»œæŒ‡æ ‡
        network_io = psutil.net_io_counters()
        if hasattr(self, '_last_network_io'):
            time_delta = timestamp - self._last_network_timestamp
            network_sent_mb_s = (network_io.bytes_sent - self._last_network_io.bytes_sent) / (1024**2) / time_delta
            network_recv_mb_s = (network_io.bytes_recv - self._last_network_io.bytes_recv) / (1024**2) / time_delta
        else:
            network_sent_mb_s = 0
            network_recv_mb_s = 0
        
        self._last_network_io = network_io
        self._last_network_timestamp = timestamp
        
        return HardwareMetrics(
            timestamp=timestamp,
            cpu_usage_percent=cpu_percent,
            cpu_frequency_mhz=cpu_frequency,
            cpu_temperature=cpu_temperature,
            cpu_cores_usage=cpu_cores_usage,
            memory_usage_percent=memory_usage_percent,
            memory_used_gb=memory_used_gb,
            memory_available_gb=memory_available_gb,
            memory_cached_gb=memory_cached_gb,
            gpu_usage_percent=gpu_usage,
            gpu_memory_usage_percent=gpu_memory_usage,
            gpu_memory_used_gb=gpu_memory_used,
            gpu_temperature=gpu_temperature,
            gpu_power_usage=gpu_power,
            disk_usage_percent=disk_usage_percent,
            disk_read_mb_s=disk_read_mb_s,
            disk_write_mb_s=disk_write_mb_s,
            disk_free_gb=disk_free_gb,
            network_sent_mb_s=network_sent_mb_s,
            network_recv_mb_s=network_recv_mb_s,
        )
    
    async def _get_cpu_temperature(self) -> float:
        """è·å–CPUæ¸©åº¦"""
        try:
            # å°è¯•ä»sensorsè·å–æ¸©åº¦
            if hasattr(psutil, "sensors_temperatures"):
                temps = psutil.sensors_temperatures()
                if temps:
                    for name, entries in temps.items():
                        if 'coretemp' in name.lower() or 'cpu' in name.lower():
                            for entry in entries:
                                if entry.current:
                                    return entry.current
            
            # å°è¯•ä»ç³»ç»Ÿæ–‡ä»¶è¯»å–
            temp_files = [
                '/sys/class/thermal/thermal_zone0/temp',
                '/sys/class/thermal/thermal_zone1/temp',
            ]
            
            for temp_file in temp_files:
                if os.path.exists(temp_file):
                    with open(temp_file, 'r') as f:
                        temp = int(f.read().strip()) / 1000.0
                        if 20 < temp < 100:  # åˆç†çš„æ¸©åº¦èŒƒå›´
                            return temp
            
            return 0.0
            
        except Exception as e:
            logger.debug(f"è·å–CPUæ¸©åº¦å¤±è´¥: {e}")
            return 0.0
    
    def _store_metrics(self, metrics: HardwareMetrics):
        """å­˜å‚¨æŒ‡æ ‡å†å²æ•°æ®"""
        self.metrics_history.append(metrics)
        
        # é™åˆ¶å†å²æ•°æ®å¤§å°
        if len(self.metrics_history) > self.max_history_size:
            self.metrics_history = self.metrics_history[-self.max_history_size:]
    
    async def _analyze_and_adjust_performance(self, metrics: HardwareMetrics):
        """åˆ†ææ€§èƒ½å¹¶è¿›è¡ŒåŠ¨æ€è°ƒèŠ‚"""
        adjustments_made = []
        
        # CPUæ€§èƒ½è°ƒèŠ‚
        cpu_adjustment = await self._adjust_cpu_performance(metrics)
        if cpu_adjustment:
            adjustments_made.append(cpu_adjustment)
        
        # GPUæ€§èƒ½è°ƒèŠ‚
        gpu_adjustment = await self._adjust_gpu_performance(metrics)
        if gpu_adjustment:
            adjustments_made.append(gpu_adjustment)
        
        # å†…å­˜ä¼˜åŒ–
        memory_adjustment = await self._optimize_memory_usage(metrics)
        if memory_adjustment:
            adjustments_made.append(memory_adjustment)
        
        if adjustments_made:
            self.performance_adjustments += 1
            logger.info(f"æ€§èƒ½è°ƒèŠ‚ #{self.performance_adjustments}: {', '.join(adjustments_made)}")
    
    async def _adjust_cpu_performance(self, metrics: HardwareMetrics) -> Optional[str]:
        """è°ƒèŠ‚CPUæ€§èƒ½"""
        target_min, target_max = self.targets.cpu_usage_target
        
        # æ¸©åº¦ä¿æŠ¤ä¼˜å…ˆ
        if metrics.cpu_temperature > self.targets.cpu_temp_max:
            await self._reduce_cpu_frequency()
            return f"CPUæ¸©åº¦è¿‡é«˜({metrics.cpu_temperature:.1f}Â°C)ï¼Œé™ä½é¢‘ç‡"
        
        # ä½¿ç”¨ç‡è°ƒèŠ‚
        if metrics.cpu_usage_percent < target_min and metrics.cpu_temperature < self.targets.cpu_temp_warning:
            await self._increase_cpu_frequency()
            return f"CPUä½¿ç”¨ç‡åä½({metrics.cpu_usage_percent:.1f}%)ï¼Œæé«˜é¢‘ç‡"
        elif metrics.cpu_usage_percent > target_max:
            await self._reduce_cpu_frequency()
            return f"CPUä½¿ç”¨ç‡è¿‡é«˜({metrics.cpu_usage_percent:.1f}%)ï¼Œé™ä½é¢‘ç‡"
        
        return None
    
    async def _adjust_gpu_performance(self, metrics: HardwareMetrics) -> Optional[str]:
        """è°ƒèŠ‚GPUæ€§èƒ½"""
        if not self.gpu_available:
            return None
        
        target_min, target_max = self.targets.gpu_usage_target
        
        # æ¸©åº¦ä¿æŠ¤ä¼˜å…ˆ
        if metrics.gpu_temperature > self.targets.gpu_temp_max:
            await self._reduce_gpu_power_limit()
            return f"GPUæ¸©åº¦è¿‡é«˜({metrics.gpu_temperature:.1f}Â°C)ï¼Œé™ä½åŠŸè€—é™åˆ¶"
        
        # ä½¿ç”¨ç‡è°ƒèŠ‚
        if metrics.gpu_usage_percent < target_min and metrics.gpu_temperature < self.targets.gpu_temp_warning:
            await self._increase_gpu_power_limit()
            return f"GPUä½¿ç”¨ç‡åä½({metrics.gpu_usage_percent:.1f}%)ï¼Œæé«˜åŠŸè€—é™åˆ¶"
        elif metrics.gpu_usage_percent > target_max:
            await self._reduce_gpu_power_limit()
            return f"GPUä½¿ç”¨ç‡è¿‡é«˜({metrics.gpu_usage_percent:.1f}%)ï¼Œé™ä½åŠŸè€—é™åˆ¶"
        
        return None
    
    async def _optimize_memory_usage(self, metrics: HardwareMetrics) -> Optional[str]:
        """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        target_min, target_max = self.targets.memory_usage_target
        
        if metrics.memory_usage_percent > target_max:
            # è§¦å‘å†…å­˜æ¸…ç†
            await self._trigger_memory_cleanup()
            return f"å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜({metrics.memory_usage_percent:.1f}%)ï¼Œè§¦å‘æ¸…ç†"
        
        return None
    
    async def _reduce_cpu_frequency(self):
        """é™ä½CPUé¢‘ç‡"""
        try:
            # åœ¨Linuxç³»ç»Ÿä¸Šè°ƒèŠ‚CPUé¢‘ç‡
            if platform.system() == "Linux":
                # ä½¿ç”¨cpufreq-setå‘½ä»¤ï¼ˆéœ€è¦å®‰è£…cpufrequtilsï¼‰
                subprocess.run(['sudo', 'cpufreq-set', '-d', '1000000'], 
                             capture_output=True, check=False)
        except Exception as e:
            logger.debug(f"è°ƒèŠ‚CPUé¢‘ç‡å¤±è´¥: {e}")
    
    async def _increase_cpu_frequency(self):
        """æé«˜CPUé¢‘ç‡"""
        try:
            if platform.system() == "Linux":
                subprocess.run(['sudo', 'cpufreq-set', '-u', '4000000'], 
                             capture_output=True, check=False)
        except Exception as e:
            logger.debug(f"è°ƒèŠ‚CPUé¢‘ç‡å¤±è´¥: {e}")
    
    async def _reduce_gpu_power_limit(self):
        """é™ä½GPUåŠŸè€—é™åˆ¶"""
        try:
            if self.gpu_available:
                # ä½¿ç”¨nvidia-smiè°ƒèŠ‚åŠŸè€—é™åˆ¶
                subprocess.run(['nvidia-smi', '-pl', '150'], 
                             capture_output=True, check=False)
        except Exception as e:
            logger.debug(f"è°ƒèŠ‚GPUåŠŸè€—å¤±è´¥: {e}")
    
    async def _increase_gpu_power_limit(self):
        """æé«˜GPUåŠŸè€—é™åˆ¶"""
        try:
            if self.gpu_available:
                subprocess.run(['nvidia-smi', '-pl', '170'], 
                             capture_output=True, check=False)
        except Exception as e:
            logger.debug(f"è°ƒèŠ‚GPUåŠŸè€—å¤±è´¥: {e}")
    
    async def _trigger_memory_cleanup(self):
        """è§¦å‘å†…å­˜æ¸…ç†"""
        try:
            # æ¸…ç†ç³»ç»Ÿç¼“å­˜
            if platform.system() == "Linux":
                subprocess.run(['sudo', 'sync'], capture_output=True, check=False)
                subprocess.run(['sudo', 'echo', '1', '>', '/proc/sys/vm/drop_caches'], 
                             shell=True, capture_output=True, check=False)
        except Exception as e:
            logger.debug(f"å†…å­˜æ¸…ç†å¤±è´¥: {e}")
    
    async def _check_warning_conditions(self, metrics: HardwareMetrics):
        """æ£€æŸ¥è­¦å‘Šæ¡ä»¶"""
        warnings = []
        
        # CPUè­¦å‘Š
        if metrics.cpu_temperature > self.targets.cpu_temp_warning:
            warnings.append(f"CPUæ¸©åº¦è­¦å‘Š: {metrics.cpu_temperature:.1f}Â°C")
        
        # GPUè­¦å‘Š
        if metrics.gpu_temperature > self.targets.gpu_temp_warning:
            warnings.append(f"GPUæ¸©åº¦è­¦å‘Š: {metrics.gpu_temperature:.1f}Â°C")
        
        # å†…å­˜è­¦å‘Š
        if metrics.memory_usage_percent > self.targets.memory_usage_target[1]:
            warnings.append(f"å†…å­˜ä½¿ç”¨ç‡è­¦å‘Š: {metrics.memory_usage_percent:.1f}%")
        
        # ç£ç›˜è­¦å‘Š
        if metrics.disk_usage_percent > self.targets.disk_usage_warning:
            warnings.append(f"ç£ç›˜ä½¿ç”¨ç‡è­¦å‘Š: {metrics.disk_usage_percent:.1f}%")
        
        if warnings:
            logger.warning(f"ç¡¬ä»¶è­¦å‘Š: {'; '.join(warnings)}")
    
    def get_current_metrics(self) -> Optional[HardwareMetrics]:
        """è·å–å½“å‰æŒ‡æ ‡"""
        return self.metrics_history[-1] if self.metrics_history else None
    
    def get_metrics_history(self, minutes: int = 60) -> List[HardwareMetrics]:
        """è·å–æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„å†å²æŒ‡æ ‡"""
        cutoff_time = time.time() - (minutes * 60)
        return [m for m in self.metrics_history if m.timestamp >= cutoff_time]
    
    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        if not self.metrics_history:
            return {}
        
        recent_metrics = self.get_metrics_history(5)  # æœ€è¿‘5åˆ†é’Ÿ
        if not recent_metrics:
            return {}
        
        return {
            "monitoring_duration_hours": (time.time() - self.metrics_history[0].timestamp) / 3600,
            "total_adjustments": self.performance_adjustments,
            "current_metrics": asdict(self.metrics_history[-1]),
            "average_metrics_5min": asdict(self._calculate_average_metrics(recent_metrics)),
            "hardware_status": {
                "cpu_healthy": recent_metrics[-1].cpu_temperature < self.targets.cpu_temp_warning,
                "gpu_healthy": recent_metrics[-1].gpu_temperature < self.targets.gpu_temp_warning,
                "memory_healthy": recent_metrics[-1].memory_usage_percent < self.targets.memory_usage_target[1],
                "disk_healthy": recent_metrics[-1].disk_usage_percent < self.targets.disk_usage_warning,
            }
        }
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.monitoring = False
        logger.info("ç¡¬ä»¶æ€§èƒ½ç›‘æ§å·²åœæ­¢")
    
    def save_metrics_to_file(self, filepath: str):
        """ä¿å­˜æŒ‡æ ‡åˆ°æ–‡ä»¶"""
        try:
            metrics_data = [asdict(m) for m in self.metrics_history]
            with open(filepath, 'w') as f:
                json.dump(metrics_data, f, indent=2)
            logger.info(f"æŒ‡æ ‡æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
        except Exception as e:
            logger.error(f"ä¿å­˜æŒ‡æ ‡æ•°æ®å¤±è´¥: {e}")


# å…¨å±€ç¡¬ä»¶ç›‘æ§å®ä¾‹
hardware_monitor = HardwarePerformanceMonitor()


async def main():
    """æµ‹è¯•ä¸»å‡½æ•°"""
    logger.info("å¯åŠ¨ç¡¬ä»¶æ€§èƒ½ç›‘æ§æµ‹è¯•...")
    
    # å¯åŠ¨ç›‘æ§
    monitor_task = asyncio.create_task(hardware_monitor.start_monitoring(interval=2.0))
    
    try:
        # è¿è¡Œ30ç§’æµ‹è¯•
        await asyncio.sleep(30)
        
        # è·å–æ€§èƒ½æ‘˜è¦
        summary = hardware_monitor.get_performance_summary()
        logger.info(f"æ€§èƒ½æ‘˜è¦: {json.dumps(summary, indent=2)}")
        
    except KeyboardInterrupt:
        logger.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œåœæ­¢ç›‘æ§...")
    finally:
        hardware_monitor.stop_monitoring()
        monitor_task.cancel()


if __name__ == "__main__":
    asyncio.run(main())
