#!/usr/bin/env python3
"""
ğŸš€ CI/CDæµæ°´çº¿ - ç”Ÿäº§çº§æŒç»­é›†æˆéƒ¨ç½²ç³»ç»Ÿ
CI/CD Pipeline - Production-Grade Continuous Integration/Deployment System

ç”Ÿäº§çº§ç‰¹æ€§ï¼š
- è‡ªåŠ¨åŒ–æ„å»ºæµ‹è¯•
- å¤šç¯å¢ƒéƒ¨ç½²ç®¡ç†
- ä»£ç è´¨é‡æ£€æŸ¥
- è‡ªåŠ¨åŒ–å›æ»šæœºåˆ¶
- éƒ¨ç½²çŠ¶æ€ç›‘æ§
"""

import os
import subprocess
import json
import time
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import yaml

from ..monitoring.unified_logging_system import UnifiedLogger

class PipelineStage(Enum):
    """æµæ°´çº¿é˜¶æ®µ"""
    CHECKOUT = "checkout"
    BUILD = "build"
    TEST = "test"
    QUALITY_CHECK = "quality_check"
    PACKAGE = "package"
    DEPLOY_DEV = "deploy_dev"
    DEPLOY_STAGING = "deploy_staging"
    DEPLOY_PROD = "deploy_prod"

class PipelineStatus(Enum):
    """æµæ°´çº¿çŠ¶æ€"""
    PENDING = "pending"
    RUNNING = "running"
    SUCCESS = "success"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class PipelineRun:
    """æµæ°´çº¿è¿è¡Œè®°å½•"""
    run_id: str
    branch: str
    commit_hash: str
    trigger: str
    status: PipelineStatus
    stages: Dict[str, Dict]
    start_time: datetime
    end_time: Optional[datetime] = None
    duration: Optional[float] = None
    artifacts: List[str] = None

@dataclass
class DeploymentConfig:
    """éƒ¨ç½²é…ç½®"""
    environment: str
    namespace: str
    replicas: int
    resources: Dict[str, str]
    environment_vars: Dict[str, str]
    health_check: Dict[str, Any]

class CICDPipeline:
    """CI/CDæµæ°´çº¿ä¸»ç±»"""
    
    def __init__(self):
        self.logger = UnifiedLogger("CICDPipeline")
        
        # æµæ°´çº¿é…ç½®
        self.pipeline_config = self._load_pipeline_config()
        self.deployment_configs = self._load_deployment_configs()
        
        # è¿è¡Œè®°å½•
        self.pipeline_runs: Dict[str, PipelineRun] = {}
        self.active_runs = set()
        
        # ç›‘æ§çº¿ç¨‹
        self._monitoring = False
        self._monitor_thread = None
        
        self.logger.info("CI/CDæµæ°´çº¿åˆå§‹åŒ–å®Œæˆ")
    
    def _load_pipeline_config(self) -> Dict:
        """åŠ è½½æµæ°´çº¿é…ç½®"""
        default_config = {
            'stages': {
                'checkout': {
                    'enabled': True,
                    'timeout': 300,
                    'retry_count': 2
                },
                'build': {
                    'enabled': True,
                    'timeout': 1800,
                    'retry_count': 1,
                    'commands': [
                        'pip install -r requirements.txt',
                        'python -m pytest tests/unit/',
                        'python setup.py build'
                    ]
                },
                'test': {
                    'enabled': True,
                    'timeout': 1200,
                    'retry_count': 1,
                    'commands': [
                        'python -m pytest tests/integration/ -v',
                        'python -m pytest tests/system/ -v'
                    ]
                },
                'quality_check': {
                    'enabled': True,
                    'timeout': 600,
                    'retry_count': 1,
                    'commands': [
                        'flake8 src/',
                        'pylint src/',
                        'bandit -r src/',
                        'safety check'
                    ]
                },
                'package': {
                    'enabled': True,
                    'timeout': 900,
                    'retry_count': 1,
                    'commands': [
                        'docker build -t trading-system:${BUILD_NUMBER} .',
                        'docker tag trading-system:${BUILD_NUMBER} trading-system:latest'
                    ]
                }
            },
            'notifications': {
                'slack': {
                    'enabled': False,
                    'webhook_url': '',
                    'channel': '#deployments'
                },
                'email': {
                    'enabled': False,
                    'smtp_server': '',
                    'recipients': []
                }
            }
        }
        
        try:
            if os.path.exists('.ci/pipeline.yml'):
                with open('.ci/pipeline.yml', 'r') as f:
                    config = yaml.safe_load(f)
                    return {**default_config, **config}
        except Exception as e:
            self.logger.warning(f"åŠ è½½æµæ°´çº¿é…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
        
        return default_config
    
    def _load_deployment_configs(self) -> Dict[str, DeploymentConfig]:
        """åŠ è½½éƒ¨ç½²é…ç½®"""
        configs = {
            'development': DeploymentConfig(
                environment='development',
                namespace='trading-dev',
                replicas=1,
                resources={
                    'cpu': '500m',
                    'memory': '1Gi'
                },
                environment_vars={
                    'ENV': 'development',
                    'LOG_LEVEL': 'DEBUG',
                    'DATABASE_URL': 'postgresql://dev_user:dev_pass@postgres-dev:5432/trading_dev'
                },
                health_check={
                    'path': '/health',
                    'port': 5000,
                    'initial_delay': 30,
                    'period': 10
                }
            ),
            'staging': DeploymentConfig(
                environment='staging',
                namespace='trading-staging',
                replicas=2,
                resources={
                    'cpu': '1000m',
                    'memory': '2Gi'
                },
                environment_vars={
                    'ENV': 'staging',
                    'LOG_LEVEL': 'INFO',
                    'DATABASE_URL': 'postgresql://staging_user:staging_pass@postgres-staging:5432/trading_staging'
                },
                health_check={
                    'path': '/health',
                    'port': 5000,
                    'initial_delay': 60,
                    'period': 15
                }
            ),
            'production': DeploymentConfig(
                environment='production',
                namespace='trading-prod',
                replicas=3,
                resources={
                    'cpu': '2000m',
                    'memory': '4Gi'
                },
                environment_vars={
                    'ENV': 'production',
                    'LOG_LEVEL': 'WARNING',
                    'DATABASE_URL': 'postgresql://prod_user:prod_pass@postgres-prod:5432/trading_prod'
                },
                health_check={
                    'path': '/health',
                    'port': 5000,
                    'initial_delay': 120,
                    'period': 30
                }
            )
        }
        
        return configs
    
    def trigger_pipeline(self, branch: str, commit_hash: str, trigger: str = 'manual') -> str:
        """è§¦å‘æµæ°´çº¿"""
        try:
            run_id = f"run_{int(time.time() * 1000)}"
            
            pipeline_run = PipelineRun(
                run_id=run_id,
                branch=branch,
                commit_hash=commit_hash,
                trigger=trigger,
                status=PipelineStatus.PENDING,
                stages={},
                start_time=datetime.now(),
                artifacts=[]
            )
            
            self.pipeline_runs[run_id] = pipeline_run
            self.active_runs.add(run_id)
            
            # å¯åŠ¨æµæ°´çº¿æ‰§è¡Œçº¿ç¨‹
            pipeline_thread = threading.Thread(
                target=self._execute_pipeline,
                args=(run_id,),
                daemon=True
            )
            pipeline_thread.start()
            
            self.logger.info(f"æµæ°´çº¿å·²è§¦å‘: {run_id} ({branch}@{commit_hash[:8]})")
            return run_id
            
        except Exception as e:
            self.logger.error(f"è§¦å‘æµæ°´çº¿å¤±è´¥: {e}")
            return None
    
    def _execute_pipeline(self, run_id: str):
        """æ‰§è¡Œæµæ°´çº¿"""
        try:
            pipeline_run = self.pipeline_runs[run_id]
            pipeline_run.status = PipelineStatus.RUNNING
            
            self.logger.info(f"å¼€å§‹æ‰§è¡Œæµæ°´çº¿: {run_id}")
            
            # è®¾ç½®ç¯å¢ƒå˜é‡
            env_vars = os.environ.copy()
            env_vars.update({
                'BUILD_NUMBER': run_id,
                'GIT_BRANCH': pipeline_run.branch,
                'GIT_COMMIT': pipeline_run.commit_hash
            })
            
            # æŒ‰é¡ºåºæ‰§è¡Œå„ä¸ªé˜¶æ®µ
            stages = [
                PipelineStage.CHECKOUT,
                PipelineStage.BUILD,
                PipelineStage.TEST,
                PipelineStage.QUALITY_CHECK,
                PipelineStage.PACKAGE
            ]
            
            for stage in stages:
                stage_name = stage.value
                
                if not self.pipeline_config['stages'].get(stage_name, {}).get('enabled', True):
                    self.logger.info(f"è·³è¿‡é˜¶æ®µ: {stage_name}")
                    continue
                
                self.logger.info(f"æ‰§è¡Œé˜¶æ®µ: {stage_name}")
                
                stage_result = self._execute_stage(stage, pipeline_run, env_vars)
                pipeline_run.stages[stage_name] = stage_result
                
                if not stage_result['success']:
                    pipeline_run.status = PipelineStatus.FAILED
                    self.logger.error(f"é˜¶æ®µå¤±è´¥: {stage_name}")
                    break
            
            # å¦‚æœæ‰€æœ‰é˜¶æ®µæˆåŠŸï¼Œæ ¹æ®åˆ†æ”¯å†³å®šæ˜¯å¦éƒ¨ç½²
            if pipeline_run.status == PipelineStatus.RUNNING:
                if pipeline_run.branch == 'main':
                    # ä¸»åˆ†æ”¯è‡ªåŠ¨éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
                    deploy_result = self._deploy_to_environment('production', pipeline_run, env_vars)
                    pipeline_run.stages['deploy_prod'] = deploy_result
                elif pipeline_run.branch == 'develop':
                    # å¼€å‘åˆ†æ”¯è‡ªåŠ¨éƒ¨ç½²åˆ°å¼€å‘ç¯å¢ƒ
                    deploy_result = self._deploy_to_environment('development', pipeline_run, env_vars)
                    pipeline_run.stages['deploy_dev'] = deploy_result
                
                pipeline_run.status = PipelineStatus.SUCCESS
            
            # å®Œæˆæµæ°´çº¿
            pipeline_run.end_time = datetime.now()
            pipeline_run.duration = (pipeline_run.end_time - pipeline_run.start_time).total_seconds()
            
            self.active_runs.discard(run_id)
            
            self.logger.info(f"æµæ°´çº¿å®Œæˆ: {run_id} ({pipeline_run.status.value})")
            
            # å‘é€é€šçŸ¥
            self._send_notification(pipeline_run)
            
        except Exception as e:
            self.logger.error(f"æ‰§è¡Œæµæ°´çº¿å¤±è´¥ {run_id}: {e}")
            
            pipeline_run = self.pipeline_runs.get(run_id)
            if pipeline_run:
                pipeline_run.status = PipelineStatus.FAILED
                pipeline_run.end_time = datetime.now()
                self.active_runs.discard(run_id)
    
    def _execute_stage(self, stage: PipelineStage, pipeline_run: PipelineRun, env_vars: Dict) -> Dict:
        """æ‰§è¡Œå•ä¸ªé˜¶æ®µ"""
        stage_name = stage.value
        stage_config = self.pipeline_config['stages'].get(stage_name, {})
        
        stage_result = {
            'stage': stage_name,
            'success': False,
            'start_time': datetime.now(),
            'end_time': None,
            'duration': 0,
            'output': '',
            'error': '',
            'retry_count': 0
        }
        
        try:
            max_retries = stage_config.get('retry_count', 1)
            timeout = stage_config.get('timeout', 600)
            
            for attempt in range(max_retries + 1):
                try:
                    if stage == PipelineStage.CHECKOUT:
                        success, output, error = self._checkout_code(pipeline_run, timeout)
                    elif stage == PipelineStage.BUILD:
                        success, output, error = self._build_application(stage_config, env_vars, timeout)
                    elif stage == PipelineStage.TEST:
                        success, output, error = self._run_tests(stage_config, env_vars, timeout)
                    elif stage == PipelineStage.QUALITY_CHECK:
                        success, output, error = self._quality_check(stage_config, env_vars, timeout)
                    elif stage == PipelineStage.PACKAGE:
                        success, output, error = self._package_application(stage_config, env_vars, timeout)
                    else:
                        success, output, error = True, f"é˜¶æ®µ {stage_name} å·²è·³è¿‡", ""
                    
                    stage_result['output'] = output
                    stage_result['error'] = error
                    stage_result['retry_count'] = attempt
                    
                    if success:
                        stage_result['success'] = True
                        break
                    elif attempt < max_retries:
                        self.logger.warning(f"é˜¶æ®µå¤±è´¥ï¼Œé‡è¯• {attempt + 1}/{max_retries}: {stage_name}")
                        time.sleep(5)  # é‡è¯•å‰ç­‰å¾…5ç§’
                    
                except Exception as e:
                    error = str(e)
                    stage_result['error'] = error
                    
                    if attempt < max_retries:
                        self.logger.warning(f"é˜¶æ®µå¼‚å¸¸ï¼Œé‡è¯• {attempt + 1}/{max_retries}: {stage_name} - {error}")
                        time.sleep(5)
            
        except Exception as e:
            stage_result['error'] = str(e)
            self.logger.error(f"æ‰§è¡Œé˜¶æ®µå¼‚å¸¸ {stage_name}: {e}")
        
        finally:
            stage_result['end_time'] = datetime.now()
            stage_result['duration'] = (stage_result['end_time'] - stage_result['start_time']).total_seconds()
        
        return stage_result
    
    def _checkout_code(self, pipeline_run: PipelineRun, timeout: int) -> Tuple[bool, str, str]:
        """æ£€å‡ºä»£ç """
        try:
            commands = [
                f"git fetch origin {pipeline_run.branch}",
                f"git checkout {pipeline_run.commit_hash}",
                "git submodule update --init --recursive"
            ]
            
            output_lines = []
            for cmd in commands:
                result = subprocess.run(
                    cmd.split(),
                    capture_output=True,
                    text=True,
                    timeout=timeout
                )
                
                output_lines.append(f"$ {cmd}")
                output_lines.append(result.stdout)
                
                if result.returncode != 0:
                    return False, "\n".join(output_lines), result.stderr
            
            return True, "\n".join(output_lines), ""
            
        except subprocess.TimeoutExpired:
            return False, "", f"ä»£ç æ£€å‡ºè¶…æ—¶ ({timeout}ç§’)"
        except Exception as e:
            return False, "", str(e)
    
    def _build_application(self, stage_config: Dict, env_vars: Dict, timeout: int) -> Tuple[bool, str, str]:
        """æ„å»ºåº”ç”¨"""
        try:
            commands = stage_config.get('commands', [])
            output_lines = []
            
            for cmd in commands:
                # æ›¿æ¢ç¯å¢ƒå˜é‡
                for key, value in env_vars.items():
                    cmd = cmd.replace(f"${{{key}}}", value)
                
                result = subprocess.run(
                    cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=timeout,
                    env=env_vars
                )
                
                output_lines.append(f"$ {cmd}")
                output_lines.append(result.stdout)
                
                if result.returncode != 0:
                    return False, "\n".join(output_lines), result.stderr
            
            return True, "\n".join(output_lines), ""
            
        except subprocess.TimeoutExpired:
            return False, "", f"æ„å»ºè¶…æ—¶ ({timeout}ç§’)"
        except Exception as e:
            return False, "", str(e)
    
    def _run_tests(self, stage_config: Dict, env_vars: Dict, timeout: int) -> Tuple[bool, str, str]:
        """è¿è¡Œæµ‹è¯•"""
        try:
            commands = stage_config.get('commands', [])
            output_lines = []
            
            for cmd in commands:
                result = subprocess.run(
                    cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=timeout,
                    env=env_vars
                )
                
                output_lines.append(f"$ {cmd}")
                output_lines.append(result.stdout)
                
                if result.returncode != 0:
                    return False, "\n".join(output_lines), result.stderr
            
            return True, "\n".join(output_lines), ""
            
        except subprocess.TimeoutExpired:
            return False, "", f"æµ‹è¯•è¶…æ—¶ ({timeout}ç§’)"
        except Exception as e:
            return False, "", str(e)
    
    def _quality_check(self, stage_config: Dict, env_vars: Dict, timeout: int) -> Tuple[bool, str, str]:
        """ä»£ç è´¨é‡æ£€æŸ¥"""
        try:
            commands = stage_config.get('commands', [])
            output_lines = []
            
            for cmd in commands:
                result = subprocess.run(
                    cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=timeout,
                    env=env_vars
                )
                
                output_lines.append(f"$ {cmd}")
                output_lines.append(result.stdout)
                
                # è´¨é‡æ£€æŸ¥å…è®¸éƒ¨åˆ†å¤±è´¥ï¼Œä½†ä¼šè®°å½•è­¦å‘Š
                if result.returncode != 0:
                    self.logger.warning(f"è´¨é‡æ£€æŸ¥è­¦å‘Š: {cmd}")
                    output_lines.append(f"è­¦å‘Š: {result.stderr}")
            
            return True, "\n".join(output_lines), ""
            
        except subprocess.TimeoutExpired:
            return False, "", f"è´¨é‡æ£€æŸ¥è¶…æ—¶ ({timeout}ç§’)"
        except Exception as e:
            return False, "", str(e)
    
    def _package_application(self, stage_config: Dict, env_vars: Dict, timeout: int) -> Tuple[bool, str, str]:
        """æ‰“åŒ…åº”ç”¨"""
        try:
            commands = stage_config.get('commands', [])
            output_lines = []
            
            for cmd in commands:
                # æ›¿æ¢ç¯å¢ƒå˜é‡
                for key, value in env_vars.items():
                    cmd = cmd.replace(f"${{{key}}}", value)
                
                result = subprocess.run(
                    cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=timeout,
                    env=env_vars
                )
                
                output_lines.append(f"$ {cmd}")
                output_lines.append(result.stdout)
                
                if result.returncode != 0:
                    return False, "\n".join(output_lines), result.stderr
            
            return True, "\n".join(output_lines), ""
            
        except subprocess.TimeoutExpired:
            return False, "", f"æ‰“åŒ…è¶…æ—¶ ({timeout}ç§’)"
        except Exception as e:
            return False, "", str(e)
    
    def _deploy_to_environment(self, environment: str, pipeline_run: PipelineRun, env_vars: Dict) -> Dict:
        """éƒ¨ç½²åˆ°æŒ‡å®šç¯å¢ƒ"""
        deploy_result = {
            'environment': environment,
            'success': False,
            'start_time': datetime.now(),
            'end_time': None,
            'duration': 0,
            'output': '',
            'error': ''
        }
        
        try:
            config = self.deployment_configs.get(environment)
            if not config:
                deploy_result['error'] = f"ç¯å¢ƒé…ç½®ä¸å­˜åœ¨: {environment}"
                return deploy_result
            
            self.logger.info(f"å¼€å§‹éƒ¨ç½²åˆ° {environment} ç¯å¢ƒ")
            
            # åˆ›å»ºKuberneteséƒ¨ç½²é…ç½®
            k8s_config = self._create_k8s_config(config, pipeline_run, env_vars)
            
            # åº”ç”¨é…ç½®
            kubectl_commands = [
                f"kubectl apply -f - <<EOF\n{k8s_config}\nEOF",
                f"kubectl rollout status deployment/trading-system -n {config.namespace}",
                f"kubectl get pods -n {config.namespace}"
            ]
            
            output_lines = []
            for cmd in kubectl_commands:
                result = subprocess.run(
                    cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=600,
                    env=env_vars
                )
                
                output_lines.append(f"$ {cmd}")
                output_lines.append(result.stdout)
                
                if result.returncode != 0:
                    deploy_result['error'] = result.stderr
                    deploy_result['output'] = "\n".join(output_lines)
                    return deploy_result
            
            deploy_result['success'] = True
            deploy_result['output'] = "\n".join(output_lines)
            
            self.logger.info(f"éƒ¨ç½²æˆåŠŸ: {environment}")
            
        except Exception as e:
            deploy_result['error'] = str(e)
            self.logger.error(f"éƒ¨ç½²å¤±è´¥ {environment}: {e}")
        
        finally:
            deploy_result['end_time'] = datetime.now()
            deploy_result['duration'] = (deploy_result['end_time'] - deploy_result['start_time']).total_seconds()
        
        return deploy_result
    
    def _create_k8s_config(self, config: DeploymentConfig, pipeline_run: PipelineRun, env_vars: Dict) -> str:
        """åˆ›å»ºKubernetesé…ç½®"""
        k8s_config = f"""
apiVersion: apps/v1
kind: Deployment
metadata:
  name: trading-system
  namespace: {config.namespace}
  labels:
    app: trading-system
    version: {pipeline_run.commit_hash[:8]}
spec:
  replicas: {config.replicas}
  selector:
    matchLabels:
      app: trading-system
  template:
    metadata:
      labels:
        app: trading-system
        version: {pipeline_run.commit_hash[:8]}
    spec:
      containers:
      - name: trading-system
        image: trading-system:{env_vars.get('BUILD_NUMBER', 'latest')}
        ports:
        - containerPort: 5000
        env:
"""
        
        # æ·»åŠ ç¯å¢ƒå˜é‡
        for key, value in config.environment_vars.items():
            k8s_config += f"        - name: {key}\n          value: \"{value}\"\n"
        
        # æ·»åŠ èµ„æºé™åˆ¶
        k8s_config += f"""
        resources:
          limits:
            cpu: {config.resources['cpu']}
            memory: {config.resources['memory']}
          requests:
            cpu: {config.resources['cpu']}
            memory: {config.resources['memory']}
        livenessProbe:
          httpGet:
            path: {config.health_check['path']}
            port: {config.health_check['port']}
          initialDelaySeconds: {config.health_check['initial_delay']}
          periodSeconds: {config.health_check['period']}
        readinessProbe:
          httpGet:
            path: {config.health_check['path']}
            port: {config.health_check['port']}
          initialDelaySeconds: {config.health_check['initial_delay']}
          periodSeconds: {config.health_check['period']}
---
apiVersion: v1
kind: Service
metadata:
  name: trading-system-service
  namespace: {config.namespace}
spec:
  selector:
    app: trading-system
  ports:
  - port: 80
    targetPort: 5000
  type: ClusterIP
        """
        
        return k8s_config
    
    def _send_notification(self, pipeline_run: PipelineRun):
        """å‘é€é€šçŸ¥"""
        try:
            notification_config = self.pipeline_config.get('notifications', {})
            
            # Slacké€šçŸ¥
            if notification_config.get('slack', {}).get('enabled', False):
                self._send_slack_notification(pipeline_run, notification_config['slack'])
            
            # é‚®ä»¶é€šçŸ¥
            if notification_config.get('email', {}).get('enabled', False):
                self._send_email_notification(pipeline_run, notification_config['email'])
                
        except Exception as e:
            self.logger.error(f"å‘é€é€šçŸ¥å¤±è´¥: {e}")
    
    def _send_slack_notification(self, pipeline_run: PipelineRun, slack_config: Dict):
        """å‘é€Slacké€šçŸ¥"""
        # è¿™é‡Œå¯ä»¥å®ç°Slacké€šçŸ¥é€»è¾‘
        self.logger.info(f"å‘é€Slacké€šçŸ¥: {pipeline_run.run_id} - {pipeline_run.status.value}")
    
    def _send_email_notification(self, pipeline_run: PipelineRun, email_config: Dict):
        """å‘é€é‚®ä»¶é€šçŸ¥"""
        # è¿™é‡Œå¯ä»¥å®ç°é‚®ä»¶é€šçŸ¥é€»è¾‘
        self.logger.info(f"å‘é€é‚®ä»¶é€šçŸ¥: {pipeline_run.run_id} - {pipeline_run.status.value}")
    
    def get_pipeline_status(self, run_id: str) -> Optional[Dict]:
        """è·å–æµæ°´çº¿çŠ¶æ€"""
        pipeline_run = self.pipeline_runs.get(run_id)
        if pipeline_run:
            return asdict(pipeline_run)
        return None
    
    def get_recent_runs(self, limit: int = 10) -> List[Dict]:
        """è·å–æœ€è¿‘çš„æµæ°´çº¿è¿è¡Œè®°å½•"""
        sorted_runs = sorted(
            self.pipeline_runs.values(),
            key=lambda x: x.start_time,
            reverse=True
        )
        
        return [asdict(run) for run in sorted_runs[:limit]]
    
    def cancel_pipeline(self, run_id: str) -> bool:
        """å–æ¶ˆæµæ°´çº¿"""
        try:
            if run_id in self.active_runs:
                pipeline_run = self.pipeline_runs.get(run_id)
                if pipeline_run:
                    pipeline_run.status = PipelineStatus.CANCELLED
                    pipeline_run.end_time = datetime.now()
                    self.active_runs.discard(run_id)
                    
                    self.logger.info(f"æµæ°´çº¿å·²å–æ¶ˆ: {run_id}")
                    return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"å–æ¶ˆæµæ°´çº¿å¤±è´¥: {e}")
            return False
    
    def create_pipeline_config_files(self):
        """åˆ›å»ºæµæ°´çº¿é…ç½®æ–‡ä»¶"""
        try:
            # åˆ›å»º.ciç›®å½•
            os.makedirs('.ci', exist_ok=True)
            
            # åˆ›å»ºpipeline.yml
            with open('.ci/pipeline.yml', 'w') as f:
                yaml.dump(self.pipeline_config, f, default_flow_style=False)
            
            # åˆ›å»ºGitHub Actionså·¥ä½œæµ
            github_workflow = """
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run tests
      run: |
        python -m pytest tests/ -v
    
    - name: Code quality check
      run: |
        flake8 src/
        pylint src/
    
    - name: Build Docker image
      run: |
        docker build -t trading-system:${{ github.sha }} .
        docker tag trading-system:${{ github.sha }} trading-system:latest
    
    - name: Deploy to development
      if: github.ref == 'refs/heads/develop'
      run: |
        echo "Deploying to development environment"
    
    - name: Deploy to production
      if: github.ref == 'refs/heads/main'
      run: |
        echo "Deploying to production environment"
            """
            
            os.makedirs('.github/workflows', exist_ok=True)
            with open('.github/workflows/ci-cd.yml', 'w') as f:
                f.write(github_workflow)
            
            self.logger.info("æµæ°´çº¿é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºé…ç½®æ–‡ä»¶å¤±è´¥: {e}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # åˆ›å»ºCI/CDæµæ°´çº¿
    pipeline = CICDPipeline()
    
    try:
        # åˆ›å»ºé…ç½®æ–‡ä»¶
        pipeline.create_pipeline_config_files()
        
        # è§¦å‘æµæ°´çº¿
        run_id = pipeline.trigger_pipeline('main', 'abc123def456', 'manual')
        
        if run_id:
            print(f"æµæ°´çº¿å·²å¯åŠ¨: {run_id}")
            
            # ç­‰å¾…å®Œæˆ
            time.sleep(5)
            
            # è·å–çŠ¶æ€
            status = pipeline.get_pipeline_status(run_id)
            print(f"æµæ°´çº¿çŠ¶æ€: {status}")
        
    except Exception as e:
        print(f"æµ‹è¯•å¤±è´¥: {e}")
