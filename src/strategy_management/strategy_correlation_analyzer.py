"""
ğŸ“Š ç­–ç•¥ç›¸å…³æ€§åˆ†æå™¨
ç”Ÿäº§çº§ç­–ç•¥ç›¸å…³æ€§åˆ†æç³»ç»Ÿï¼Œå®ç°æ»šåŠ¨ç›¸å…³æ€§ã€åæ–¹å·®çŸ©é˜µã€å› å­åˆ†è§£ç­‰å®Œæ•´åˆ†æ
æ”¯æŒå®æ—¶ç›¸å…³æ€§ç›‘æ§ã€ç­–ç•¥èšç±»å’Œé£é™©åˆ†æ•£åº¦è¯„ä¼°
"""

import asyncio
import numpy as np
import pandas as pd
from typing import Dict, List, Optional, Any, Tuple, Union
from dataclasses import dataclass, field
from enum import Enum
import scipy.stats as stats
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster
from scipy.spatial.distance import squareform
from sklearn.decomposition import PCA, FactorAnalysis
from sklearn.preprocessing import StandardScaler
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

from loguru import logger
from src.core.config import settings


class CorrelationMethod(Enum):
    """ç›¸å…³æ€§è®¡ç®—æ–¹æ³•"""
    PEARSON = "pearson"          # çš®å°”é€Šç›¸å…³ç³»æ•°
    SPEARMAN = "spearman"        # æ–¯çš®å°”æ›¼ç­‰çº§ç›¸å…³
    KENDALL = "kendall"          # è‚¯å¾·å°”Ï„ç›¸å…³
    DISTANCE = "distance"        # è·ç¦»ç›¸å…³æ€§
    MUTUAL_INFO = "mutual_info"  # äº’ä¿¡æ¯
    COPULA = "copula"           # Copulaç›¸å…³æ€§


class ClusteringMethod(Enum):
    """èšç±»æ–¹æ³•"""
    HIERARCHICAL = "hierarchical"  # å±‚æ¬¡èšç±»
    KMEANS = "kmeans"             # Kå‡å€¼èšç±»
    DBSCAN = "dbscan"             # DBSCANèšç±»
    SPECTRAL = "spectral"         # è°±èšç±»


@dataclass
class CorrelationMetrics:
    """ç›¸å…³æ€§æŒ‡æ ‡"""
    correlation_matrix: np.ndarray           # ç›¸å…³æ€§çŸ©é˜µ
    average_correlation: float               # å¹³å‡ç›¸å…³æ€§
    max_correlation: float                   # æœ€å¤§ç›¸å…³æ€§
    min_correlation: float                   # æœ€å°ç›¸å…³æ€§
    correlation_stability: float             # ç›¸å…³æ€§ç¨³å®šæ€§
    diversification_ratio: float             # åˆ†æ•£åŒ–æ¯”ç‡
    effective_strategies: float              # æœ‰æ•ˆç­–ç•¥æ•°é‡
    correlation_clusters: Dict[int, List[str]]  # ç›¸å…³æ€§èšç±»
    eigenvalues: np.ndarray                  # ç‰¹å¾å€¼
    explained_variance_ratio: np.ndarray     # è§£é‡Šæ–¹å·®æ¯”
    factor_loadings: Optional[np.ndarray] = None  # å› å­è½½è·


@dataclass
class RollingCorrelationResult:
    """æ»šåŠ¨ç›¸å…³æ€§ç»“æœ"""
    timestamps: List[datetime]               # æ—¶é—´æˆ³
    correlations: np.ndarray                # æ»šåŠ¨ç›¸å…³æ€§çŸ©é˜µ
    average_correlations: List[float]        # å¹³å‡ç›¸å…³æ€§æ—¶é—´åºåˆ—
    correlation_trends: Dict[str, List[float]]  # ç›¸å…³æ€§è¶‹åŠ¿
    regime_changes: List[datetime]           # åˆ¶åº¦å˜åŒ–ç‚¹
    stability_scores: List[float]            # ç¨³å®šæ€§å¾—åˆ†


class StrategyCorrelationAnalyzer:
    """ç­–ç•¥ç›¸å…³æ€§åˆ†æå™¨"""
    
    def __init__(self):
        self.lookback_window = 252      # å›æœ›çª—å£252ä¸ªäº¤æ˜“æ—¥
        self.rolling_window = 60        # æ»šåŠ¨çª—å£60ä¸ªäº¤æ˜“æ—¥
        self.min_periods = 30           # æœ€å°è§‚æµ‹æœŸæ•°
        self.correlation_threshold = 0.7 # é«˜ç›¸å…³æ€§é˜ˆå€¼
        
        # åˆ†æå†å²è®°å½•
        self.analysis_history: List[Dict[str, Any]] = []
        
        logger.info("ç­–ç•¥ç›¸å…³æ€§åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def analyze_strategy_correlations(
        self,
        strategy_returns: pd.DataFrame,
        method: CorrelationMethod = CorrelationMethod.PEARSON,
        rolling_analysis: bool = True
    ) -> Tuple[CorrelationMetrics, Optional[RollingCorrelationResult]]:
        """
        åˆ†æç­–ç•¥ç›¸å…³æ€§
        
        Args:
            strategy_returns: ç­–ç•¥æ”¶ç›Šç‡æ•°æ®
            method: ç›¸å…³æ€§è®¡ç®—æ–¹æ³•
            rolling_analysis: æ˜¯å¦è¿›è¡Œæ»šåŠ¨åˆ†æ
        
        Returns:
            Tuple[CorrelationMetrics, RollingCorrelationResult]: ç›¸å…³æ€§æŒ‡æ ‡å’Œæ»šåŠ¨åˆ†æç»“æœ
        """
        try:
            # æ•°æ®é¢„å¤„ç†
            returns_clean = self._preprocess_returns(strategy_returns)
            
            # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
            correlation_matrix = await self._calculate_correlation_matrix(
                returns_clean, method
            )
            
            # è®¡ç®—ç›¸å…³æ€§æŒ‡æ ‡
            metrics = await self._calculate_correlation_metrics(
                correlation_matrix, returns_clean
            )
            
            # æ»šåŠ¨ç›¸å…³æ€§åˆ†æ
            rolling_result = None
            if rolling_analysis and len(returns_clean) >= self.rolling_window * 2:
                rolling_result = await self._rolling_correlation_analysis(
                    returns_clean, method
                )
            
            # è®°å½•åˆ†æå†å²
            self._record_analysis(method, metrics, rolling_result)
            
            logger.info(f"ç›¸å…³æ€§åˆ†æå®Œæˆ - å¹³å‡ç›¸å…³æ€§: {metrics.average_correlation:.3f}")
            return metrics, rolling_result
            
        except Exception as e:
            logger.error(f"ç›¸å…³æ€§åˆ†æå¤±è´¥: {e}")
            raise
    
    def _preprocess_returns(self, returns: pd.DataFrame) -> pd.DataFrame:
        """é¢„å¤„ç†æ”¶ç›Šç‡æ•°æ®"""
        # å»é™¤ç¼ºå¤±å€¼
        returns_clean = returns.dropna()
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
        if len(returns_clean) < self.min_periods:
            raise ValueError(f"æ•°æ®ä¸è¶³ï¼Œè‡³å°‘éœ€è¦{self.min_periods}ä¸ªè§‚æµ‹å€¼")
        
        # å»é™¤å¼‚å¸¸å€¼ (5å€æ ‡å‡†å·®)
        for col in returns_clean.columns:
            mean = returns_clean[col].mean()
            std = returns_clean[col].std()
            returns_clean[col] = returns_clean[col].clip(
                lower=mean - 5*std, upper=mean + 5*std
            )
        
        return returns_clean
    
    async def _calculate_correlation_matrix(
        self,
        returns: pd.DataFrame,
        method: CorrelationMethod
    ) -> np.ndarray:
        """è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ"""
        if method == CorrelationMethod.PEARSON:
            return returns.corr(method='pearson').values
        
        elif method == CorrelationMethod.SPEARMAN:
            return returns.corr(method='spearman').values
        
        elif method == CorrelationMethod.KENDALL:
            return returns.corr(method='kendall').values
        
        elif method == CorrelationMethod.DISTANCE:
            return await self._distance_correlation_matrix(returns)
        
        elif method == CorrelationMethod.MUTUAL_INFO:
            return await self._mutual_information_matrix(returns)
        
        elif method == CorrelationMethod.COPULA:
            return await self._copula_correlation_matrix(returns)
        
        else:
            return returns.corr(method='pearson').values
    
    async def _distance_correlation_matrix(self, returns: pd.DataFrame) -> np.ndarray:
        """è®¡ç®—è·ç¦»ç›¸å…³æ€§çŸ©é˜µ"""
        n_strategies = len(returns.columns)
        distance_corr_matrix = np.eye(n_strategies)
        
        for i in range(n_strategies):
            for j in range(i+1, n_strategies):
                x = returns.iloc[:, i].values
                y = returns.iloc[:, j].values
                
                # è®¡ç®—è·ç¦»ç›¸å…³æ€§
                dcorr = self._distance_correlation(x, y)
                distance_corr_matrix[i, j] = dcorr
                distance_corr_matrix[j, i] = dcorr
        
        return distance_corr_matrix
    
    def _distance_correlation(self, x: np.ndarray, y: np.ndarray) -> float:
        """è®¡ç®—è·ç¦»ç›¸å…³æ€§"""
        n = len(x)
        
        # è®¡ç®—è·ç¦»çŸ©é˜µ
        a = np.abs(x[:, np.newaxis] - x[np.newaxis, :])
        b = np.abs(y[:, np.newaxis] - y[np.newaxis, :])
        
        # ä¸­å¿ƒåŒ–è·ç¦»çŸ©é˜µ
        A = a - a.mean(axis=0) - a.mean(axis=1)[:, np.newaxis] + a.mean()
        B = b - b.mean(axis=0) - b.mean(axis=1)[:, np.newaxis] + b.mean()
        
        # è®¡ç®—è·ç¦»åæ–¹å·®å’Œæ–¹å·®
        dcov_xy = np.sqrt(np.mean(A * B))
        dcov_xx = np.sqrt(np.mean(A * A))
        dcov_yy = np.sqrt(np.mean(B * B))
        
        # è·ç¦»ç›¸å…³æ€§
        if dcov_xx > 0 and dcov_yy > 0:
            return dcov_xy / np.sqrt(dcov_xx * dcov_yy)
        else:
            return 0.0
    
    async def _mutual_information_matrix(self, returns: pd.DataFrame) -> np.ndarray:
        """è®¡ç®—äº’ä¿¡æ¯çŸ©é˜µ"""
        from sklearn.feature_selection import mutual_info_regression
        
        n_strategies = len(returns.columns)
        mi_matrix = np.eye(n_strategies)
        
        for i in range(n_strategies):
            for j in range(i+1, n_strategies):
                x = returns.iloc[:, i].values.reshape(-1, 1)
                y = returns.iloc[:, j].values
                
                # è®¡ç®—äº’ä¿¡æ¯
                mi = mutual_info_regression(x, y, random_state=42)[0]
                
                # æ ‡å‡†åŒ–åˆ°[-1, 1]èŒƒå›´
                mi_normalized = 2 * mi / (np.var(returns.iloc[:, i]) + np.var(returns.iloc[:, j])) - 1
                mi_normalized = np.clip(mi_normalized, -1, 1)
                
                mi_matrix[i, j] = mi_normalized
                mi_matrix[j, i] = mi_normalized
        
        return mi_matrix
    
    async def _copula_correlation_matrix(self, returns: pd.DataFrame) -> np.ndarray:
        """è®¡ç®—Copulaç›¸å…³æ€§çŸ©é˜µ"""
        from scipy.stats import rankdata
        
        # è½¬æ¢ä¸ºå‡åŒ€åˆ†å¸ƒ (ç»éªŒåˆ†å¸ƒå‡½æ•°)
        n_obs, n_strategies = returns.shape
        uniform_data = np.zeros_like(returns.values)
        
        for i in range(n_strategies):
            ranks = rankdata(returns.iloc[:, i])
            uniform_data[:, i] = ranks / (n_obs + 1)
        
        # è½¬æ¢ä¸ºæ ‡å‡†æ­£æ€åˆ†å¸ƒ
        from scipy.stats import norm
        normal_data = norm.ppf(uniform_data)
        
        # è®¡ç®—æ­£æ€Copulaç›¸å…³æ€§
        copula_corr = np.corrcoef(normal_data.T)
        
        return copula_corr
    
    async def _calculate_correlation_metrics(
        self,
        correlation_matrix: np.ndarray,
        returns: pd.DataFrame
    ) -> CorrelationMetrics:
        """è®¡ç®—ç›¸å…³æ€§æŒ‡æ ‡"""
        # å»é™¤å¯¹è§’çº¿å…ƒç´ 
        mask = ~np.eye(correlation_matrix.shape[0], dtype=bool)
        correlations = correlation_matrix[mask]
        
        # åŸºæœ¬ç»Ÿè®¡é‡
        average_correlation = np.mean(correlations)
        max_correlation = np.max(correlations)
        min_correlation = np.min(correlations)
        
        # ç›¸å…³æ€§ç¨³å®šæ€§ (æ ‡å‡†å·®çš„å€’æ•°)
        correlation_stability = 1 / (np.std(correlations) + 1e-8)
        
        # åˆ†æ•£åŒ–æ¯”ç‡
        weights = np.ones(len(returns.columns)) / len(returns.columns)
        portfolio_vol = np.sqrt(weights.T @ (returns.cov().values * 252) @ weights)
        individual_vols = np.sqrt(np.diag(returns.cov().values * 252))
        weighted_avg_vol = np.dot(weights, individual_vols)
        diversification_ratio = weighted_avg_vol / portfolio_vol
        
        # æœ‰æ•ˆç­–ç•¥æ•°é‡ (åŸºäºç›¸å…³æ€§)
        eigenvalues, _ = np.linalg.eigh(correlation_matrix)
        eigenvalues = eigenvalues[eigenvalues > 0]
        effective_strategies = np.exp(-np.sum(eigenvalues * np.log(eigenvalues + 1e-8)))
        
        # ç›¸å…³æ€§èšç±»
        correlation_clusters = await self._cluster_strategies(
            correlation_matrix, returns.columns.tolist()
        )
        
        # PCAåˆ†æ
        pca = PCA()
        pca.fit(returns.values)
        explained_variance_ratio = pca.explained_variance_ratio_
        
        # å› å­åˆ†æ
        try:
            n_factors = min(5, len(returns.columns) - 1)
            fa = FactorAnalysis(n_components=n_factors, random_state=42)
            fa.fit(returns.values)
            factor_loadings = fa.components_
        except:
            factor_loadings = None
        
        return CorrelationMetrics(
            correlation_matrix=correlation_matrix,
            average_correlation=average_correlation,
            max_correlation=max_correlation,
            min_correlation=min_correlation,
            correlation_stability=correlation_stability,
            diversification_ratio=diversification_ratio,
            effective_strategies=effective_strategies,
            correlation_clusters=correlation_clusters,
            eigenvalues=eigenvalues,
            explained_variance_ratio=explained_variance_ratio,
            factor_loadings=factor_loadings
        )
    
    async def _cluster_strategies(
        self,
        correlation_matrix: np.ndarray,
        strategy_names: List[str],
        method: ClusteringMethod = ClusteringMethod.HIERARCHICAL
    ) -> Dict[int, List[str]]:
        """ç­–ç•¥èšç±»"""
        if method == ClusteringMethod.HIERARCHICAL:
            # è½¬æ¢ç›¸å…³æ€§ä¸ºè·ç¦»
            distance_matrix = np.sqrt(0.5 * (1 - correlation_matrix))
            
            # å±‚æ¬¡èšç±»
            distance_vector = squareform(distance_matrix, checks=False)
            linkage_matrix = linkage(distance_vector, method='ward')
            
            # ç¡®å®šèšç±»æ•°é‡ (åŸºäºç›¸å…³æ€§é˜ˆå€¼)
            n_clusters = max(2, min(len(strategy_names) // 2, 5))
            cluster_labels = fcluster(linkage_matrix, n_clusters, criterion='maxclust')
            
            # ç»„ç»‡èšç±»ç»“æœ
            clusters = {}
            for i, label in enumerate(cluster_labels):
                if label not in clusters:
                    clusters[label] = []
                clusters[label].append(strategy_names[i])
            
            return clusters
        
        else:
            # å…¶ä»–èšç±»æ–¹æ³•çš„å®ç°
            from sklearn.cluster import KMeans, DBSCAN, SpectralClustering
            
            if method == ClusteringMethod.KMEANS:
                n_clusters = max(2, min(len(strategy_names) // 2, 5))
                kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                cluster_labels = kmeans.fit_predict(correlation_matrix)
            
            elif method == ClusteringMethod.DBSCAN:
                dbscan = DBSCAN(eps=0.3, min_samples=2)
                cluster_labels = dbscan.fit_predict(correlation_matrix)
            
            elif method == ClusteringMethod.SPECTRAL:
                n_clusters = max(2, min(len(strategy_names) // 2, 5))
                spectral = SpectralClustering(n_clusters=n_clusters, random_state=42)
                cluster_labels = spectral.fit_predict(correlation_matrix)
            
            # ç»„ç»‡èšç±»ç»“æœ
            clusters = {}
            for i, label in enumerate(cluster_labels):
                if label not in clusters:
                    clusters[label] = []
                clusters[label].append(strategy_names[i])
            
            return clusters
    
    async def _rolling_correlation_analysis(
        self,
        returns: pd.DataFrame,
        method: CorrelationMethod
    ) -> RollingCorrelationResult:
        """æ»šåŠ¨ç›¸å…³æ€§åˆ†æ"""
        timestamps = []
        correlations = []
        average_correlations = []
        
        # æ»šåŠ¨è®¡ç®—ç›¸å…³æ€§
        for i in range(self.rolling_window, len(returns)):
            window_data = returns.iloc[i-self.rolling_window:i]
            timestamp = returns.index[i]
            
            # è®¡ç®—çª—å£ç›¸å…³æ€§çŸ©é˜µ
            corr_matrix = await self._calculate_correlation_matrix(window_data, method)
            
            # è®¡ç®—å¹³å‡ç›¸å…³æ€§
            mask = ~np.eye(corr_matrix.shape[0], dtype=bool)
            avg_corr = np.mean(corr_matrix[mask])
            
            timestamps.append(timestamp)
            correlations.append(corr_matrix)
            average_correlations.append(avg_corr)
        
        correlations = np.array(correlations)
        
        # è®¡ç®—ç›¸å…³æ€§è¶‹åŠ¿
        correlation_trends = {}
        n_strategies = len(returns.columns)
        
        for i in range(n_strategies):
            for j in range(i+1, n_strategies):
                pair_name = f"{returns.columns[i]}-{returns.columns[j]}"
                correlation_trends[pair_name] = correlations[:, i, j].tolist()
        
        # æ£€æµ‹åˆ¶åº¦å˜åŒ–ç‚¹
        regime_changes = await self._detect_regime_changes(
            np.array(average_correlations), timestamps
        )
        
        # è®¡ç®—ç¨³å®šæ€§å¾—åˆ†
        stability_scores = await self._calculate_stability_scores(correlations)
        
        return RollingCorrelationResult(
            timestamps=timestamps,
            correlations=correlations,
            average_correlations=average_correlations,
            correlation_trends=correlation_trends,
            regime_changes=regime_changes,
            stability_scores=stability_scores
        )
    
    async def _detect_regime_changes(
        self,
        correlation_series: np.ndarray,
        timestamps: List[datetime]
    ) -> List[datetime]:
        """æ£€æµ‹ç›¸å…³æ€§åˆ¶åº¦å˜åŒ–ç‚¹"""
        from ruptures import Pelt
        
        try:
            # ä½¿ç”¨PELTç®—æ³•æ£€æµ‹å˜åŒ–ç‚¹
            algo = Pelt(model="rbf").fit(correlation_series.reshape(-1, 1))
            change_points = algo.predict(pen=10)
            
            # è½¬æ¢ä¸ºæ—¶é—´æˆ³
            regime_changes = []
            for cp in change_points[:-1]:  # æœ€åä¸€ä¸ªæ˜¯åºåˆ—é•¿åº¦
                if cp < len(timestamps):
                    regime_changes.append(timestamps[cp])
            
            return regime_changes
        
        except Exception as e:
            logger.warning(f"åˆ¶åº¦å˜åŒ–æ£€æµ‹å¤±è´¥: {e}")
            return []
    
    async def _calculate_stability_scores(
        self,
        correlations: np.ndarray
    ) -> List[float]:
        """è®¡ç®—ç›¸å…³æ€§ç¨³å®šæ€§å¾—åˆ†"""
        stability_scores = []
        window_size = 20  # 20æœŸçª—å£
        
        for i in range(window_size, len(correlations)):
            # è®¡ç®—çª—å£å†…ç›¸å…³æ€§çš„å˜å¼‚ç³»æ•°
            window_corrs = correlations[i-window_size:i]
            
            # è®¡ç®—æ¯å¯¹ç­–ç•¥ç›¸å…³æ€§çš„æ ‡å‡†å·®
            n_strategies = correlations.shape[1]
            pair_stds = []
            
            for j in range(n_strategies):
                for k in range(j+1, n_strategies):
                    pair_corrs = window_corrs[:, j, k]
                    pair_std = np.std(pair_corrs)
                    pair_stds.append(pair_std)
            
            # ç¨³å®šæ€§å¾—åˆ† = 1 / (å¹³å‡æ ‡å‡†å·® + å°å¸¸æ•°)
            avg_std = np.mean(pair_stds)
            stability_score = 1 / (avg_std + 0.01)
            stability_scores.append(stability_score)
        
        return stability_scores
    
    def _record_analysis(
        self,
        method: CorrelationMethod,
        metrics: CorrelationMetrics,
        rolling_result: Optional[RollingCorrelationResult]
    ):
        """è®°å½•åˆ†æå†å²"""
        record = {
            'timestamp': datetime.now(),
            'method': method.value,
            'average_correlation': metrics.average_correlation,
            'max_correlation': metrics.max_correlation,
            'min_correlation': metrics.min_correlation,
            'diversification_ratio': metrics.diversification_ratio,
            'effective_strategies': metrics.effective_strategies,
            'n_clusters': len(metrics.correlation_clusters),
            'has_rolling_analysis': rolling_result is not None
        }
        
        self.analysis_history.append(record)
        
        # ä¿æŒæœ€è¿‘50æ¬¡è®°å½•
        if len(self.analysis_history) > 50:
            self.analysis_history = self.analysis_history[-50:]
    
    async def get_correlation_heatmap_data(
        self,
        correlation_matrix: np.ndarray,
        strategy_names: List[str]
    ) -> Dict[str, Any]:
        """è·å–ç›¸å…³æ€§çƒ­åŠ›å›¾æ•°æ®"""
        return {
            'matrix': correlation_matrix.tolist(),
            'labels': strategy_names,
            'title': 'ç­–ç•¥ç›¸å…³æ€§çƒ­åŠ›å›¾',
            'colorscale': 'RdBu',
            'zmin': -1,
            'zmax': 1
        }
    
    async def get_cluster_analysis_report(
        self,
        metrics: CorrelationMetrics,
        strategy_names: List[str]
    ) -> Dict[str, Any]:
        """è·å–èšç±»åˆ†ææŠ¥å‘Š"""
        report = {
            'summary': {
                'n_strategies': len(strategy_names),
                'n_clusters': len(metrics.correlation_clusters),
                'average_correlation': metrics.average_correlation,
                'diversification_ratio': metrics.diversification_ratio,
                'effective_strategies': metrics.effective_strategies
            },
            'clusters': {},
            'high_correlation_pairs': [],
            'recommendations': []
        }
        
        # èšç±»è¯¦æƒ…
        for cluster_id, strategies in metrics.correlation_clusters.items():
            report['clusters'][f'Cluster_{cluster_id}'] = {
                'strategies': strategies,
                'size': len(strategies),
                'description': f'åŒ…å«{len(strategies)}ä¸ªç­–ç•¥çš„èšç±»'
            }
        
        # é«˜ç›¸å…³æ€§ç­–ç•¥å¯¹
        n_strategies = len(strategy_names)
        for i in range(n_strategies):
            for j in range(i+1, n_strategies):
                corr = metrics.correlation_matrix[i, j]
                if abs(corr) > self.correlation_threshold:
                    report['high_correlation_pairs'].append({
                        'strategy1': strategy_names[i],
                        'strategy2': strategy_names[j],
                        'correlation': corr,
                        'type': 'positive' if corr > 0 else 'negative'
                    })
        
        # å»ºè®®
        if metrics.average_correlation > 0.6:
            report['recommendations'].append("ç­–ç•¥é—´ç›¸å…³æ€§è¾ƒé«˜ï¼Œå»ºè®®å¢åŠ ç­–ç•¥å¤šæ ·æ€§")
        
        if metrics.diversification_ratio < 1.2:
            report['recommendations'].append("åˆ†æ•£åŒ–æ•ˆæœæœ‰é™ï¼Œå»ºè®®ä¼˜åŒ–ç­–ç•¥ç»„åˆ")
        
        if len(metrics.correlation_clusters) < 3:
            report['recommendations'].append("ç­–ç•¥èšç±»æ•°é‡è¾ƒå°‘ï¼Œå»ºè®®å¢åŠ ä¸åŒç±»å‹çš„ç­–ç•¥")
        
        return report
    
    async def monitor_correlation_changes(
        self,
        current_correlations: np.ndarray,
        historical_correlations: List[np.ndarray],
        threshold: float = 0.1
    ) -> Dict[str, Any]:
        """ç›‘æ§ç›¸å…³æ€§å˜åŒ–"""
        if not historical_correlations:
            return {'status': 'no_history', 'changes': []}
        
        # è®¡ç®—ä¸å†å²å¹³å‡çš„å·®å¼‚
        historical_avg = np.mean(historical_correlations, axis=0)
        correlation_changes = np.abs(current_correlations - historical_avg)
        
        # è¯†åˆ«æ˜¾è‘—å˜åŒ–
        significant_changes = []
        n_strategies = current_correlations.shape[0]
        
        for i in range(n_strategies):
            for j in range(i+1, n_strategies):
                change = correlation_changes[i, j]
                if change > threshold:
                    significant_changes.append({
                        'strategy_pair': (i, j),
                        'current_correlation': current_correlations[i, j],
                        'historical_correlation': historical_avg[i, j],
                        'change_magnitude': change,
                        'change_direction': 'increase' if current_correlations[i, j] > historical_avg[i, j] else 'decrease'
                    })
        
        return {
            'status': 'analyzed',
            'n_significant_changes': len(significant_changes),
            'changes': significant_changes,
            'overall_correlation_change': np.mean(correlation_changes),
            'max_change': np.max(correlation_changes)
        }
    
    async def get_analysis_history(self) -> List[Dict[str, Any]]:
        """è·å–åˆ†æå†å²"""
        return self.analysis_history.copy()


# å…¨å±€ç›¸å…³æ€§åˆ†æå™¨å®ä¾‹
correlation_analyzer = StrategyCorrelationAnalyzer()

